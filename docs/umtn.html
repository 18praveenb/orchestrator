<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>umtn</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="resources/styles.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body><span class="toc">
<a href="./2020-02-17 Meeting 1.html" class="toc_entry">2020-02-17 Meeting 1</a>&nbsp;&nbsp;&nbsp;&nbsp;
<a href="./2020-02-29 Meeting 2.html" class="toc_entry">2020-02-29 Meeting 2</a>&nbsp;&nbsp;&nbsp;&nbsp;
<a href="./csua.html" class="toc_entry">csua</a>&nbsp;&nbsp;&nbsp;&nbsp;
<a href="./index.html" class="toc_entry">index</a>&nbsp;&nbsp;&nbsp;&nbsp;
<a href="./pytorch.html" class="toc_entry">pytorch</a>&nbsp;&nbsp;&nbsp;&nbsp;
<a href="./seq2seq.html" class="toc_entry">seq2seq</a>&nbsp;&nbsp;&nbsp;&nbsp;
<a href="./umtn.html" class="toc_entry">umtn</a>&nbsp;&nbsp;&nbsp;&nbsp;
<a href="./website.html" class="toc_entry">website</a>&nbsp;&nbsp;&nbsp;&nbsp;
</span>
<h2 id="universal-music-translation-network">Universal Music Translation Network</h2>
<h3 id="wavenet-basics">WaveNet Basics</h3>
<ul>
<li>Model audio as a time series</li>
<li>Predict the probability distribution of the next point using the previous points and a conditioning signal</li>
<li>Uses stacked convolutions to incorporate information from recent and much earlier points</li>
<li>NVIDIA has created some <a href="https://github.com/NVIDIA/nv-wavenet">GPU optimized code</a> for WaveNet related things.</li>
</ul>
<p><img src="https://lh3.googleusercontent.com/Zy5xK_i2F8sNH5tFtRa0SjbLp_CU7QwzS2iB5nf2ijIf_OYm-Q5D0SgoW9SmfbDF97tNEF7CmxaL-o6oLC8sGIrJ5HxWNk79dL1r7Rc=w2048" class="invert" /></p>
<p>Learn more about WaveNet:</p>
<ul>
<li>DeepMind <a href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio">blog post</a></li>
<li><a href="https://arxiv.org/pdf/1609.03499.pdf">Paper</a></li>
</ul>
<h3 id="umtn-overview">UMTN Overview</h3>
<p><img src="https://github.com/facebookresearch/music-translation/blob/master/img/fig.png?raw=true" class="invert" /></p>
<ul>
<li>Inputs are audio files (e.g. WAV) which can be considered a <a href="https://en.wikipedia.org/wiki/Pulse-code_modulation">time series</a></li>
<li>Encoder network encodes inputs into a representation that, theoretically, doesn’t include any instrumentation details (“domain specific information”)</li>
<li>A decoder can convert the encoder output into an audio file with a specific instrumentation. Each instrumentation (“domain”) has its own decoder.</li>
<li>The whole network is really computationally expensive!</li>
</ul>
<h3 id="data-augmentation">Data Augmentation</h3>
<ul>
<li>Detune the audio beforehand, to prevent overfitting.</li>
</ul>
<h3 id="losses">Losses</h3>
<ul>
<li>Train a classifier to predict the domain from the encoded representation.</li>
<li>Remember, the encoder is supposed to remove domain specific information!</li>
<li>So, the loss for the encoder and decoders includes a reward (negative loss) for confusing the classifier!</li>
<li>The other component of the encoder/decoder loss is that inputting a file and decoding it to the same domain should yield the same file.</li>
<li>At runtime the decoder is conditioned on its previous output. But to help it learn at training time, it’s conditioned on the previous ground truth output instead. This is called <a href="https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c">teacher forcing</a>.</li>
</ul>
</body>
</html>