<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2020-02-17 Meeting 1</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="resources/styles.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body><a href="2020-02-17 Meeting 1.html">2020-02-17 Meeting 1</a><br />
<a href="Pytorch Tutorial.html">Pytorch Tutorial</a><br />
<a href="index.html">index</a><br />
<h1 id="week-1-meeting-217">Week 1 Meeting 2/17</h1>
<ul>
<li>No meeting next week (due to retreat)</li>
<li>Regular schedule TBD (when2meet!)</li>
</ul>
<h2 id="pytorch-40m">Pytorch (40m)</h2>
<ul>
<li><a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">Pytorch 60min blitz</a></li>
<li>Check the advice sections below for what to focus on in the tutorial.</li>
<li>Would recommend either running the Jupyter notebook or using Google Colab and setting the runtime to ‘Hardware accelerator: GPU’ if you want GPU access</li>
<li>Should have Colab and Jupyter links on each page of the tutorial</li>
</ul>
<h3 id="what-is-pytorch"><a href="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py">What is Pytorch?</a></h3>
<p>Make sure you know how to do the following: - How to construct empty, random, all-ones, and all-zeros tensors - How to specify tensor datatype - Create a tensor with the same shape as another tensor, but a different datatype - Look up tensor operations - Add, subtract and <a href="https://stackoverflow.com/questions/44524901/how-to-do-product-of-matrices-in-pytorch">multiply</a> tensors - Convert between Numpy arrays and tensors - Move tensors between CPU and GPU</p>
<h2 id="autograd"><a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py">Autograd</a></h2>
<ul>
<li>Useful takeaways from this tutorial:
<ul>
<li><code>with torch.no_grad()</code></li>
<li><code>requires_grad</code> determines whether the gradient is computed.</li>
</ul></li>
<li>Don’t know how important the other stuff is. Part 3 will go into how weight updates etc. is done in practice.</li>
</ul>
<h2 id="neural-networks"><a href="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/neural_networks_tutorial.ipynb#scrollTo=pFyfk2z9r48d">Neural Networks</a></h2>
<ul>
<li>Notice how they define the network as a class.</li>
<li>Dense layers are called “Linear”</li>
<li>What the network actually does is in “forward”
<ul>
<li>Layers that don’t need weights (e.g. max_pool) aren’t members of the class</li>
<li>E.g. <code>F.max_pool2d</code> is used in <code>forward</code> but not defined in <code>__init__</code></li>
</ul></li>
<li><code>.parameters()</code> gets weights</li>
<li>Using <code>zero_grad</code> is important at the start of each training loop. I copied the training loop from the end of the document, it’s worth remembering.</li>
</ul>
<pre><code>optimizer.zero_grad() # Zero gradients
output = net(input)
loss = criterion(output, target) # Compute loss
loss.backward() # Backprop
optimizer.step() # Update step</code></pre>
<h2 id="training-a-classifier"><a href="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb">Training a Classifier</a></h2>
<ul>
<li>Coming soon</li>
</ul>
<h2 id="universal-music-translation-network-40m">Universal Music Translation Network (40m)</h2>
<ul>
<li>Read paper</li>
<li>Look at GitHub</li>
<li>Results from CSUA</li>
</ul>
<h2 id="csua-account-setup-colab-40m">CSUA account setup &amp; Colab (40m)</h2>
<ul>
<li>Go to CSUA soda office</li>
<li>Set up CSUA accounts</li>
<li>Run Jupyter notebook on CSUA</li>
</ul>
<h2 id="seq2seq-tutorial-40m">Seq2Seq tutorial (40m)</h2>
<ul>
<li>https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html</li>
</ul>
<h2 id="tonenet-40m">ToneNet (40m)</h2>
<ul>
<li>https://towardsdatascience.com/tonenet-a-musical-style-transfer-c0a18903c910</li>
</ul>
<blockquote>
<h2 id="from-the-original-syllabus">From the original syllabus</h2>
<ol type="1">
<li>Week of 2/10
<ol type="1">
<li>Lecture: Introductions, overview of sequence-to-sequence problems and the UMTN</li>
<li>Workshop: Pytorch tutorial (maybe <a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html</a> though I didn’t like it as much. Might want to make some custom tutorial stuff).</li>
<li>Homework: None</li>
</ol></li>
<li>Week of 2/17
<ol type="1">
<li>Lecture
<ol type="1">
<li>Style transfer basics. VGG and CycleGAN style transfer on images.</li>
<li>Seq2Seq network and use in style transfer on text and images.</li>
</ol></li>
<li>Workshop
<ol type="1">
<li>Field trip to CSUA to get accounts.</li>
<li>How to log in to CSUA and run Jupyter notebooks.</li>
<li>Seq2Seq tutorial <a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html</a></li>
</ol></li>
<li>Homework: None</li>
</ol></li>
<li>Week of 2/24
<ol type="1">
<li>Reimplementing ToneNet (seq2seq for MIDI style transfer).</li>
<li>Working with raw audio: <a href="https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html">https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html</a> (torchaudio tutorial, will need to look over &gt;and see how useful this is beforehand though)</li>
<li>Homework: None</li>
</ol></li>
</ol>
</blockquote>
</body>
</html>