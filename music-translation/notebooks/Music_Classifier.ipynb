{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the data for this classifier:\n",
    "\n",
    "1. Download the Musicnet library\n",
    "2. Put the folder titled \"musicnet\" in the music-translation folder\n",
    "3. Create a folder titled \"music_classification_data\" in the \"musicnet\" folder\n",
    "4. Create two folders in \"music_classification_data\" titled \"test\" and \"train\"\n",
    "5. In the \"test\" and \"train\" folders, put folders with the wav files in each such that the folders are titled with the labels for the wav files (e.g. \"Beethoven_Accompanied_Violin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check current device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puts data and labels into 2d arrays, splits into train and test:\n",
    "\n",
    "Tutorial on pathlib libary: https://realpython.com/python-pathlib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels: ['Beethoven_Accompanied_Violin', 'Bach_Solo_Piano', 'Bach_Solo_Cello', 'Beethoven_Solo_Piano', 'Beethoven_String_Quartet', 'Cambini_Wind_Quintet'] \n",
      "\n",
      "test labels: ['Beethoven_Accompanied_Violin', 'Bach_Solo_Piano', 'Bach_Solo_Cello', 'Beethoven_Solo_Piano', 'Beethoven_String_Quartet', 'Cambini_Wind_Quintet'] \n",
      "\n",
      "6 16\n",
      "6 6\n"
     ]
    }
   ],
   "source": [
    "dataset = Path.cwd().parent.joinpath(\"musicnet\", \"music_classification_data\")\n",
    "\n",
    "train = dataset.joinpath(\"train\")\n",
    "test = dataset.joinpath(\"test\")\n",
    "\n",
    "train_labels = [p.stem for p in train.iterdir()]\n",
    "test_labels = [p.stem for p in test.iterdir()]\n",
    "\n",
    "train_labels.remove(\".DS_Store\")\n",
    "test_labels.remove(\".DS_Store\")\n",
    "\n",
    "print(\"train labels:\", train_labels, \"\\n\")\n",
    "print(\"test labels:\", test_labels, \"\\n\")\n",
    "\n",
    "train_wav = []\n",
    "test_wav = []\n",
    "\n",
    "for label in train_labels:\n",
    "    train_wav.append([wav for wav in train.joinpath(label).iterdir() if wav.name != \".DS_Store\"])\n",
    "    \n",
    "for label in test_labels:\n",
    "    test_wav.append([wav for wav in test.joinpath(label).iterdir() if wav.name != \".DS_Store\"])\n",
    "    \n",
    "print(len(train_wav), len(train_wav[0]))\n",
    "print(len(test_wav), len(test_wav[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puts data and labels into 1d arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 153\n",
      "50 50\n"
     ]
    }
   ],
   "source": [
    "train_y = []\n",
    "test_y = []\n",
    "\n",
    "unprocessed_train_x = []\n",
    "unprocessed_test_x = []\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    for j in range(len(train_wav[i])):\n",
    "        train_y.append(train_labels[i])\n",
    "        \n",
    "for i in range(len(test_labels)):\n",
    "    for j in range(len(test_wav[i])):\n",
    "        test_y.append(test_labels[i])\n",
    "        \n",
    "for arr in train_wav:\n",
    "    unprocessed_train_x.extend(arr)\n",
    "    \n",
    "for arr in test_wav:\n",
    "    unprocessed_test_x.extend(arr)\n",
    "        \n",
    "print(len(train_y), len(unprocessed_train_x))\n",
    "print(len(test_y), len(unprocessed_test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processed data, uses librosa to turn wav file into a tensor. Takes first 160,000 samples (~4s), and samples every 5 to get processed audio tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train wav files:\n",
      "10 / 153 processed\n",
      "20 / 153 processed\n",
      "30 / 153 processed\n",
      "40 / 153 processed\n",
      "50 / 153 processed\n",
      "60 / 153 processed\n",
      "70 / 153 processed\n",
      "80 / 153 processed\n",
      "90 / 153 processed\n",
      "100 / 153 processed\n",
      "110 / 153 processed\n",
      "120 / 153 processed\n",
      "130 / 153 processed\n",
      "140 / 153 processed\n",
      "150 / 153 processed\n",
      "\n",
      " Processing test wav files:\n",
      "10 / 50 processed\n",
      "20 / 50 processed\n",
      "30 / 50 processed\n",
      "40 / 50 processed\n",
      "50 / 50 processed\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "test_x = []\n",
    "\n",
    "train_progress_counter = 0\n",
    "test_progress_counter = 0\n",
    "\n",
    "print(\"Processing train wav files:\")\n",
    "\n",
    "for path in unprocessed_train_x:\n",
    "    data, rate = librosa.load(path, sr=16000, duration=10)\n",
    "    assert rate == 16000\n",
    "    sample_tensor = torch.tensor(data).float()\n",
    "    assert sample_tensor.size()  == torch.Size([160000])\n",
    "    downsampled_tensor = sample_tensor[::5]\n",
    "    train_progress_counter += 1\n",
    "    if train_progress_counter % 10 == 0:\n",
    "        print(train_progress_counter, \"/\", len(unprocessed_train_x), \"processed\")\n",
    "    train_x.append(downsampled_tensor)\n",
    "    \n",
    "print(\"\\n\", \"Processing test wav files:\")\n",
    "    \n",
    "for path in unprocessed_test_x:\n",
    "    data, rate = librosa.load(path, sr=16000, duration=10)\n",
    "    assert rate == 16000\n",
    "    sample_tensor = torch.tensor(data).float()\n",
    "    assert sample_tensor.size()  == torch.Size([160000])\n",
    "    downsampled_tensor = sample_tensor[::5]\n",
    "    test_progress_counter += 1\n",
    "    if test_progress_counter % 10 == 0:\n",
    "        print(test_progress_counter, \"/\", len(unprocessed_test_x), \"processed\")\n",
    "    test_x.append(downsampled_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save train_x, test_x, train_y, test_y to .pt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_x, \"train_x.pt\")\n",
    "torch.save(test_x, \"test_x.pt\")\n",
    "\n",
    "torch.save(train_y, \"train_y.pt\")\n",
    "torch.save(test_y, \"test_y.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retreive train_x, test_x, train_y, test_y from saved .pt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000])\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.load(\"train_x.pt\")\n",
    "# test_x = torch.load(\"test_x.pt\")\n",
    "# train_y = torch.load(\"train_y.pt\")\n",
    "# test_y = torch.load(\"test_y.pt\")\n",
    "\n",
    "print(train_x[0])\n",
    "# print(test_x[0])\n",
    "# print(train_y[0])\n",
    "# print(test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack train_x and train_y into train_data, stack test_x and test_y into test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y_class = []\n",
    "test_y_class = []\n",
    "\n",
    "dict = {'Beethoven_Accompanied_Violin':0, 'Bach_Solo_Piano':1, 'Bach_Solo_Cello':2, 'Beethoven_Solo_Piano':3, 'Beethoven_String_Quartet':4, 'Cambini_Wind_Quintet':5}\n",
    "\n",
    "for label in train_y:\n",
    "    train_y_class.append(torch.tensor(dict[label]))\n",
    "    \n",
    "for label in test_y:\n",
    "    test_y_class.append(torch.tensor(dict[label]))\n",
    "    \n",
    "train_data = list(zip(train_x, train_y_class))\n",
    "test_data = list(zip(test_x, test_y_class))\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make train_x so that it has labels + data, same w test_x\n",
    "\n",
    "\n",
    "# Skipping the batching for now\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu\n",
    "# train_loader = torch.utils.data.DataLoader(train_x, batch_size = 128, shuffle = True, **kwargs)\n",
    "# test_loader = torch.utils.data.DataLoader(test_x, batch_size = 128, shuffle = True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN modeled after the M5 network architecture described in https://arxiv.org/pdf/1610.00087.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(80,), stride=(4,))\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgPool): AvgPool1d(kernel_size=(30,), stride=(30,), padding=(0,))\n",
      "  (fc1): Linear(in_features=512, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(30) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer (using Adam) and scheduler, which lowers the learning rate from 0.01 to 0.0001 over the course of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for data, label in train_data:\n",
    "        # for batch_idx\n",
    "        optimizer.zero_grad()\n",
    "        data = data.requires_grad_() #set requires_grad to True for training\n",
    "        data = torch.unsqueeze(data, 0)\n",
    "        data = torch.unsqueeze(data, 0)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x6 \n",
    "        loss = F.nll_loss(output[0], torch.unsqueeze(label, 0)) #the loss functions expects a batchSizex6 input\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % log_interval == 0: #print training stats\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, label in test_data:\n",
    "        data = torch.unsqueeze(data, 0)\n",
    "        data = torch.unsqueeze(data, 0)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        print(pred, label)\n",
    "        correct += pred.eq(label).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_data),\n",
    "        100. * correct / len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3]]) tensor(0)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[4]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[2]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(1)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[1]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[3]]) tensor(1)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[3]]) tensor(4)\n",
      "\n",
      "Test set: Accuracy: 10/50 (20%)\n",
      "\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[4]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[2]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(1)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[1]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[3]]) tensor(1)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[3]]) tensor(4)\n",
      "\n",
      "Test set: Accuracy: 10/50 (20%)\n",
      "\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[4]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[2]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(1)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[1]]) tensor(4)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[4]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[1]]) tensor(1)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[3]]) tensor(1)\n",
      "tensor([[1]]) tensor(5)\n",
      "tensor([[3]]) tensor(4)\n",
      "\n",
      "Test set: Accuracy: 10/50 (20%)\n",
      "\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[1]]) tensor(3)\n",
      "tensor([[3]]) tensor(0)\n",
      "tensor([[4]]) tensor(2)\n",
      "tensor([[4]]) tensor(4)\n",
      "tensor([[4]]) tensor(1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9cbe6e7efc52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-67d2742cee99>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-bfcd127dd77a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_interval = 20\n",
    "for epoch in range(1, 41):\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "    scheduler.step()\n",
    "    train(model, epoch)\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
