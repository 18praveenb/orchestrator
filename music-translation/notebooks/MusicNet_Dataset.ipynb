{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Pytorch Dataset for the Music Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train_wav and test_wav lists of lists that hold the path to every wav file in MusicNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels: ['Beethoven_Accompanied_Violin', 'Bach_Solo_Piano', 'Bach_Solo_Cello', 'Beethoven_Solo_Piano', 'Beethoven_String_Quartet', 'Cambini_Wind_Quintet'] \n",
      "\n",
      "test labels: ['Beethoven_Accompanied_Violin', 'Bach_Solo_Piano', 'Bach_Solo_Cello', 'Beethoven_Solo_Piano', 'Beethoven_String_Quartet', 'Cambini_Wind_Quintet'] \n",
      "\n",
      "6 16\n",
      "6 6\n"
     ]
    }
   ],
   "source": [
    "dataset = Path.cwd().parent.joinpath(\"musicnet\", \"music_classification_data\")\n",
    "\n",
    "train = dataset.joinpath(\"train\")\n",
    "test = dataset.joinpath(\"test\")\n",
    "\n",
    "train_labels = [p.stem for p in train.iterdir()]\n",
    "test_labels = [p.stem for p in test.iterdir()]\n",
    "\n",
    "# Uncomment the code below if needed for your machine\n",
    "train_labels.remove(\".DS_Store\")\n",
    "test_labels.remove(\".DS_Store\")\n",
    "\n",
    "print(\"train labels:\", train_labels, \"\\n\")\n",
    "print(\"test labels:\", test_labels, \"\\n\")\n",
    "\n",
    "train_wav = []\n",
    "test_wav = []\n",
    "\n",
    "for label in train_labels:\n",
    "    train_wav.append([wav for wav in train.joinpath(label).iterdir() if wav.name != \".DS_Store\"])\n",
    "    \n",
    "for label in test_labels:\n",
    "    test_wav.append([wav for wav in test.joinpath(label).iterdir() if wav.name != \".DS_Store\"])\n",
    "    \n",
    "print(len(train_wav), len(train_wav[0]))\n",
    "print(len(test_wav), len(test_wav[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puts our test_wav and train_wav into 1d arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 153\n",
      "50 50\n"
     ]
    }
   ],
   "source": [
    "train_y = []\n",
    "test_y = []\n",
    "\n",
    "unprocessed_train_x = []\n",
    "unprocessed_test_x = []\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    for j in range(len(train_wav[i])):\n",
    "        train_y.append(train_labels[i])\n",
    "        \n",
    "for i in range(len(test_labels)):\n",
    "    for j in range(len(test_wav[i])):\n",
    "        test_y.append(test_labels[i])\n",
    "        \n",
    "for arr in train_wav:\n",
    "    unprocessed_train_x.extend(arr)\n",
    "    \n",
    "for arr in test_wav:\n",
    "    unprocessed_test_x.extend(arr)\n",
    "        \n",
    "print(len(train_y), len(unprocessed_train_x))\n",
    "print(len(test_y), len(unprocessed_test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicClassifierDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Music Classifier Dataset. Uses librosa to process wav files.\n",
    "    Takes first 160,000 samples (~4s), and samples every 5 to get processed audio tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, wavs, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: list of labels\n",
    "            wavs: list of paths to our wav files\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.wavs = wavs\n",
    "        self.dict = {'Beethoven_Accompanied_Violin':0, 'Bach_Solo_Piano':1, 'Bach_Solo_Cello':2, 'Beethoven_Solo_Piano':3, 'Beethoven_String_Quartet':4, 'Cambini_Wind_Quintet':5}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, rate = librosa.load(self.wavs[index], sr=16000, duration=10)\n",
    "        assert rate == 16000\n",
    "        sample_tensor = torch.tensor(data).float()\n",
    "        assert sample_tensor.size()  == torch.Size([160000])\n",
    "        downsampled_tensor = sample_tensor[::5]\n",
    "        \n",
    "        return downsampled_tensor, torch.tensor(self.dict[self.labels[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 153\n",
      "Test set size: 50\n"
     ]
    }
   ],
   "source": [
    "train_set = MusicClassifierDataset(unprocessed_train_x, train_y)\n",
    "test_set = MusicClassifierDataset(unprocessed_test_x, test_y)\n",
    "print(\"Train set size: \" + str(len(train_set)))\n",
    "print(\"Test set size: \" + str(len(test_set)))\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 8, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 8, shuffle = True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(80,), stride=(4,))\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgPool): AvgPool1d(kernel_size=(30,), stride=(30,), padding=(0,))\n",
      "  (fc1): Linear(in_features=512, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(30) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = torch.unsqueeze(data, 0)\n",
    "        data = data.permute(1, 0, 2)\n",
    "        data = data.requires_grad_() #set requires_grad to True for training\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x6 \n",
    "#         print(output[0].shape, target.shape)\n",
    "        loss = F.nll_loss(output[0], target) #the loss functions expects a batchSizex10 input\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0: #print training stats\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = torch.unsqueeze(data, 0)\n",
    "        data = data.permute(1, 0, 2)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/153 (0%)]\tLoss: 1.851535\n",
      "Train Epoch: 1 [40/153 (25%)]\tLoss: 2.108335\n",
      "Train Epoch: 1 [80/153 (50%)]\tLoss: 1.997277\n",
      "Train Epoch: 1 [120/153 (75%)]\tLoss: 0.981965\n",
      "\n",
      "Test set: Accuracy: 18/50 (36%)\n",
      "\n",
      "Train Epoch: 2 [0/153 (0%)]\tLoss: 1.778592\n",
      "Train Epoch: 2 [40/153 (25%)]\tLoss: 1.671328\n",
      "Train Epoch: 2 [80/153 (50%)]\tLoss: 0.999457\n",
      "Train Epoch: 2 [120/153 (75%)]\tLoss: 0.823397\n",
      "\n",
      "Test set: Accuracy: 18/50 (36%)\n",
      "\n",
      "Train Epoch: 3 [0/153 (0%)]\tLoss: 1.710012\n",
      "Train Epoch: 3 [40/153 (25%)]\tLoss: 1.924729\n",
      "Train Epoch: 3 [80/153 (50%)]\tLoss: 0.903946\n",
      "Train Epoch: 3 [120/153 (75%)]\tLoss: 1.557185\n",
      "\n",
      "Test set: Accuracy: 24/50 (48%)\n",
      "\n",
      "Train Epoch: 4 [0/153 (0%)]\tLoss: 1.250088\n",
      "Train Epoch: 4 [40/153 (25%)]\tLoss: 1.047618\n",
      "Train Epoch: 4 [80/153 (50%)]\tLoss: 1.512080\n",
      "Train Epoch: 4 [120/153 (75%)]\tLoss: 1.306583\n",
      "\n",
      "Test set: Accuracy: 28/50 (56%)\n",
      "\n",
      "Train Epoch: 5 [0/153 (0%)]\tLoss: 1.297790\n",
      "Train Epoch: 5 [40/153 (25%)]\tLoss: 1.591551\n",
      "Train Epoch: 5 [80/153 (50%)]\tLoss: 1.238361\n",
      "Train Epoch: 5 [120/153 (75%)]\tLoss: 1.034910\n",
      "\n",
      "Test set: Accuracy: 14/50 (28%)\n",
      "\n",
      "Train Epoch: 6 [0/153 (0%)]\tLoss: 1.255002\n",
      "Train Epoch: 6 [40/153 (25%)]\tLoss: 1.722382\n",
      "Train Epoch: 6 [80/153 (50%)]\tLoss: 1.695426\n",
      "Train Epoch: 6 [120/153 (75%)]\tLoss: 2.167588\n",
      "\n",
      "Test set: Accuracy: 21/50 (42%)\n",
      "\n",
      "Train Epoch: 7 [0/153 (0%)]\tLoss: 1.030070\n",
      "Train Epoch: 7 [40/153 (25%)]\tLoss: 0.963528\n",
      "Train Epoch: 7 [80/153 (50%)]\tLoss: 1.385067\n",
      "Train Epoch: 7 [120/153 (75%)]\tLoss: 1.165184\n",
      "\n",
      "Test set: Accuracy: 29/50 (58%)\n",
      "\n",
      "Train Epoch: 8 [0/153 (0%)]\tLoss: 0.985601\n",
      "Train Epoch: 8 [40/153 (25%)]\tLoss: 0.950212\n",
      "Train Epoch: 8 [80/153 (50%)]\tLoss: 0.871814\n",
      "Train Epoch: 8 [120/153 (75%)]\tLoss: 0.694355\n",
      "\n",
      "Test set: Accuracy: 22/50 (44%)\n",
      "\n",
      "Train Epoch: 9 [0/153 (0%)]\tLoss: 0.650542\n",
      "Train Epoch: 9 [40/153 (25%)]\tLoss: 0.813473\n",
      "Train Epoch: 9 [80/153 (50%)]\tLoss: 0.717692\n",
      "Train Epoch: 9 [120/153 (75%)]\tLoss: 1.702847\n",
      "\n",
      "Test set: Accuracy: 24/50 (48%)\n",
      "\n",
      "Train Epoch: 10 [0/153 (0%)]\tLoss: 1.417475\n",
      "Train Epoch: 10 [40/153 (25%)]\tLoss: 1.081701\n",
      "Train Epoch: 10 [80/153 (50%)]\tLoss: 1.012944\n",
      "Train Epoch: 10 [120/153 (75%)]\tLoss: 1.334437\n",
      "\n",
      "Test set: Accuracy: 30/50 (60%)\n",
      "\n",
      "Train Epoch: 11 [0/153 (0%)]\tLoss: 1.101339\n",
      "Train Epoch: 11 [40/153 (25%)]\tLoss: 2.680289\n",
      "Train Epoch: 11 [80/153 (50%)]\tLoss: 1.189414\n",
      "Train Epoch: 11 [120/153 (75%)]\tLoss: 1.504630\n",
      "\n",
      "Test set: Accuracy: 25/50 (50%)\n",
      "\n",
      "Train Epoch: 12 [0/153 (0%)]\tLoss: 0.451901\n",
      "Train Epoch: 12 [40/153 (25%)]\tLoss: 0.862514\n",
      "Train Epoch: 12 [80/153 (50%)]\tLoss: 0.621911\n",
      "Train Epoch: 12 [120/153 (75%)]\tLoss: 0.587947\n",
      "\n",
      "Test set: Accuracy: 32/50 (64%)\n",
      "\n",
      "Train Epoch: 13 [0/153 (0%)]\tLoss: 1.397856\n",
      "Train Epoch: 13 [40/153 (25%)]\tLoss: 1.049592\n",
      "Train Epoch: 13 [80/153 (50%)]\tLoss: 1.046585\n",
      "Train Epoch: 13 [120/153 (75%)]\tLoss: 0.689371\n",
      "\n",
      "Test set: Accuracy: 30/50 (60%)\n",
      "\n",
      "Train Epoch: 14 [0/153 (0%)]\tLoss: 1.386782\n",
      "Train Epoch: 14 [40/153 (25%)]\tLoss: 0.232994\n",
      "Train Epoch: 14 [80/153 (50%)]\tLoss: 0.665044\n",
      "Train Epoch: 14 [120/153 (75%)]\tLoss: 1.190251\n",
      "\n",
      "Test set: Accuracy: 27/50 (54%)\n",
      "\n",
      "Train Epoch: 15 [0/153 (0%)]\tLoss: 1.490088\n",
      "Train Epoch: 15 [40/153 (25%)]\tLoss: 1.154604\n",
      "Train Epoch: 15 [80/153 (50%)]\tLoss: 0.899153\n",
      "Train Epoch: 15 [120/153 (75%)]\tLoss: 1.029474\n",
      "\n",
      "Test set: Accuracy: 24/50 (48%)\n",
      "\n",
      "Train Epoch: 16 [0/153 (0%)]\tLoss: 0.552046\n",
      "Train Epoch: 16 [40/153 (25%)]\tLoss: 0.527277\n",
      "Train Epoch: 16 [80/153 (50%)]\tLoss: 1.365103\n",
      "Train Epoch: 16 [120/153 (75%)]\tLoss: 1.003729\n",
      "\n",
      "Test set: Accuracy: 26/50 (52%)\n",
      "\n",
      "Train Epoch: 17 [0/153 (0%)]\tLoss: 1.018901\n",
      "Train Epoch: 17 [40/153 (25%)]\tLoss: 0.842682\n",
      "Train Epoch: 17 [80/153 (50%)]\tLoss: 0.853364\n",
      "Train Epoch: 17 [120/153 (75%)]\tLoss: 0.768798\n",
      "\n",
      "Test set: Accuracy: 26/50 (52%)\n",
      "\n",
      "Train Epoch: 18 [0/153 (0%)]\tLoss: 0.226348\n",
      "Train Epoch: 18 [40/153 (25%)]\tLoss: 0.554445\n",
      "Train Epoch: 18 [80/153 (50%)]\tLoss: 0.555949\n",
      "Train Epoch: 18 [120/153 (75%)]\tLoss: 0.969671\n",
      "\n",
      "Test set: Accuracy: 38/50 (76%)\n",
      "\n",
      "Train Epoch: 19 [0/153 (0%)]\tLoss: 0.507285\n",
      "Train Epoch: 19 [40/153 (25%)]\tLoss: 0.451052\n",
      "Train Epoch: 19 [80/153 (50%)]\tLoss: 0.684161\n",
      "Train Epoch: 19 [120/153 (75%)]\tLoss: 0.669847\n",
      "\n",
      "Test set: Accuracy: 31/50 (62%)\n",
      "\n",
      "Train Epoch: 20 [0/153 (0%)]\tLoss: 2.205620\n",
      "Train Epoch: 20 [40/153 (25%)]\tLoss: 0.105326\n",
      "Train Epoch: 20 [80/153 (50%)]\tLoss: 0.429689\n",
      "Train Epoch: 20 [120/153 (75%)]\tLoss: 0.978820\n",
      "\n",
      "Test set: Accuracy: 34/50 (68%)\n",
      "\n",
      "Train Epoch: 21 [0/153 (0%)]\tLoss: 0.784416\n",
      "Train Epoch: 21 [40/153 (25%)]\tLoss: 0.926629\n",
      "Train Epoch: 21 [80/153 (50%)]\tLoss: 0.431019\n",
      "Train Epoch: 21 [120/153 (75%)]\tLoss: 0.128775\n",
      "\n",
      "Test set: Accuracy: 36/50 (72%)\n",
      "\n",
      "Train Epoch: 22 [0/153 (0%)]\tLoss: 1.001930\n",
      "Train Epoch: 22 [40/153 (25%)]\tLoss: 0.625154\n",
      "Train Epoch: 22 [80/153 (50%)]\tLoss: 0.604096\n",
      "Train Epoch: 22 [120/153 (75%)]\tLoss: 0.223231\n",
      "\n",
      "Test set: Accuracy: 37/50 (74%)\n",
      "\n",
      "Train Epoch: 23 [0/153 (0%)]\tLoss: 0.584144\n",
      "Train Epoch: 23 [40/153 (25%)]\tLoss: 1.177693\n",
      "Train Epoch: 23 [80/153 (50%)]\tLoss: 1.040630\n",
      "Train Epoch: 23 [120/153 (75%)]\tLoss: 0.459997\n",
      "\n",
      "Test set: Accuracy: 36/50 (72%)\n",
      "\n",
      "Train Epoch: 24 [0/153 (0%)]\tLoss: 0.444801\n",
      "Train Epoch: 24 [40/153 (25%)]\tLoss: 0.389419\n",
      "Train Epoch: 24 [80/153 (50%)]\tLoss: 0.196696\n",
      "Train Epoch: 24 [120/153 (75%)]\tLoss: 0.712010\n",
      "\n",
      "Test set: Accuracy: 30/50 (60%)\n",
      "\n",
      "Train Epoch: 25 [0/153 (0%)]\tLoss: 1.028099\n",
      "Train Epoch: 25 [40/153 (25%)]\tLoss: 0.447524\n",
      "Train Epoch: 25 [80/153 (50%)]\tLoss: 0.273799\n",
      "Train Epoch: 25 [120/153 (75%)]\tLoss: 1.010952\n",
      "\n",
      "Test set: Accuracy: 30/50 (60%)\n",
      "\n",
      "Train Epoch: 26 [0/153 (0%)]\tLoss: 0.451349\n",
      "Train Epoch: 26 [40/153 (25%)]\tLoss: 0.594693\n",
      "Train Epoch: 26 [80/153 (50%)]\tLoss: 0.146440\n",
      "Train Epoch: 26 [120/153 (75%)]\tLoss: 0.770301\n",
      "\n",
      "Test set: Accuracy: 31/50 (62%)\n",
      "\n",
      "Train Epoch: 27 [0/153 (0%)]\tLoss: 0.230192\n",
      "Train Epoch: 27 [40/153 (25%)]\tLoss: 0.193893\n",
      "Train Epoch: 27 [80/153 (50%)]\tLoss: 1.007833\n",
      "Train Epoch: 27 [120/153 (75%)]\tLoss: 0.296067\n",
      "\n",
      "Test set: Accuracy: 34/50 (68%)\n",
      "\n",
      "Train Epoch: 28 [0/153 (0%)]\tLoss: 0.115859\n",
      "Train Epoch: 28 [40/153 (25%)]\tLoss: 0.379678\n",
      "Train Epoch: 28 [80/153 (50%)]\tLoss: 0.565177\n",
      "Train Epoch: 28 [120/153 (75%)]\tLoss: 0.328998\n",
      "\n",
      "Test set: Accuracy: 32/50 (64%)\n",
      "\n",
      "Train Epoch: 29 [0/153 (0%)]\tLoss: 0.382241\n",
      "Train Epoch: 29 [40/153 (25%)]\tLoss: 0.510997\n",
      "Train Epoch: 29 [80/153 (50%)]\tLoss: 0.377117\n",
      "Train Epoch: 29 [120/153 (75%)]\tLoss: 0.292118\n",
      "\n",
      "Test set: Accuracy: 35/50 (70%)\n",
      "\n",
      "Train Epoch: 30 [0/153 (0%)]\tLoss: 0.500931\n",
      "Train Epoch: 30 [40/153 (25%)]\tLoss: 0.582218\n",
      "Train Epoch: 30 [80/153 (50%)]\tLoss: 0.858421\n",
      "Train Epoch: 30 [120/153 (75%)]\tLoss: 0.722539\n",
      "\n",
      "Test set: Accuracy: 34/50 (68%)\n",
      "\n",
      "First round of training complete. Setting learn rate to 0.001.\n",
      "Train Epoch: 31 [0/153 (0%)]\tLoss: 0.344862\n",
      "Train Epoch: 31 [40/153 (25%)]\tLoss: 0.339116\n",
      "Train Epoch: 31 [80/153 (50%)]\tLoss: 0.287706\n",
      "Train Epoch: 31 [120/153 (75%)]\tLoss: 0.224354\n",
      "\n",
      "Test set: Accuracy: 35/50 (70%)\n",
      "\n",
      "Train Epoch: 32 [0/153 (0%)]\tLoss: 0.661274\n",
      "Train Epoch: 32 [40/153 (25%)]\tLoss: 0.279420\n",
      "Train Epoch: 32 [80/153 (50%)]\tLoss: 0.137576\n",
      "Train Epoch: 32 [120/153 (75%)]\tLoss: 0.382644\n",
      "\n",
      "Test set: Accuracy: 31/50 (62%)\n",
      "\n",
      "Train Epoch: 33 [0/153 (0%)]\tLoss: 0.420545\n",
      "Train Epoch: 33 [40/153 (25%)]\tLoss: 0.350386\n",
      "Train Epoch: 33 [80/153 (50%)]\tLoss: 0.256853\n",
      "Train Epoch: 33 [120/153 (75%)]\tLoss: 0.395397\n",
      "\n",
      "Test set: Accuracy: 29/50 (58%)\n",
      "\n",
      "Train Epoch: 34 [0/153 (0%)]\tLoss: 0.544304\n",
      "Train Epoch: 34 [40/153 (25%)]\tLoss: 0.242364\n",
      "Train Epoch: 34 [80/153 (50%)]\tLoss: 0.249408\n",
      "Train Epoch: 34 [120/153 (75%)]\tLoss: 0.103402\n",
      "\n",
      "Test set: Accuracy: 36/50 (72%)\n",
      "\n",
      "Train Epoch: 35 [0/153 (0%)]\tLoss: 0.531358\n",
      "Train Epoch: 35 [40/153 (25%)]\tLoss: 0.185442\n",
      "Train Epoch: 35 [80/153 (50%)]\tLoss: 0.252120\n",
      "Train Epoch: 35 [120/153 (75%)]\tLoss: 0.295190\n",
      "\n",
      "Test set: Accuracy: 35/50 (70%)\n",
      "\n",
      "Train Epoch: 36 [0/153 (0%)]\tLoss: 0.548731\n",
      "Train Epoch: 36 [40/153 (25%)]\tLoss: 0.485279\n",
      "Train Epoch: 36 [80/153 (50%)]\tLoss: 1.013837\n",
      "Train Epoch: 36 [120/153 (75%)]\tLoss: 0.365010\n",
      "\n",
      "Test set: Accuracy: 30/50 (60%)\n",
      "\n",
      "Train Epoch: 37 [0/153 (0%)]\tLoss: 0.164524\n",
      "Train Epoch: 37 [40/153 (25%)]\tLoss: 0.563538\n",
      "Train Epoch: 37 [80/153 (50%)]\tLoss: 0.204963\n",
      "Train Epoch: 37 [120/153 (75%)]\tLoss: 0.358076\n",
      "\n",
      "Test set: Accuracy: 33/50 (66%)\n",
      "\n",
      "Train Epoch: 38 [0/153 (0%)]\tLoss: 0.543747\n",
      "Train Epoch: 38 [40/153 (25%)]\tLoss: 0.535257\n",
      "Train Epoch: 38 [80/153 (50%)]\tLoss: 0.241783\n",
      "Train Epoch: 38 [120/153 (75%)]\tLoss: 0.250634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 34/50 (68%)\n",
      "\n",
      "Train Epoch: 39 [0/153 (0%)]\tLoss: 0.176240\n",
      "Train Epoch: 39 [40/153 (25%)]\tLoss: 0.184824\n",
      "Train Epoch: 39 [80/153 (50%)]\tLoss: 0.306993\n",
      "Train Epoch: 39 [120/153 (75%)]\tLoss: 0.111392\n",
      "\n",
      "Test set: Accuracy: 33/50 (66%)\n",
      "\n",
      "Train Epoch: 40 [0/153 (0%)]\tLoss: 0.265724\n",
      "Train Epoch: 40 [40/153 (25%)]\tLoss: 0.299129\n",
      "Train Epoch: 40 [80/153 (50%)]\tLoss: 0.206660\n",
      "Train Epoch: 40 [120/153 (75%)]\tLoss: 0.311195\n",
      "\n",
      "Test set: Accuracy: 32/50 (64%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_interval = 5\n",
    "for epoch in range(1, 41):\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "    scheduler.step()\n",
    "    train(model, epoch)\n",
    "    test(model, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([128, 1, 80])\n",
      "conv1.bias \t torch.Size([128])\n",
      "bn1.weight \t torch.Size([128])\n",
      "bn1.bias \t torch.Size([128])\n",
      "bn1.running_mean \t torch.Size([128])\n",
      "bn1.running_var \t torch.Size([128])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "conv2.weight \t torch.Size([128, 128, 3])\n",
      "conv2.bias \t torch.Size([128])\n",
      "bn2.weight \t torch.Size([128])\n",
      "bn2.bias \t torch.Size([128])\n",
      "bn2.running_mean \t torch.Size([128])\n",
      "bn2.running_var \t torch.Size([128])\n",
      "bn2.num_batches_tracked \t torch.Size([])\n",
      "conv3.weight \t torch.Size([256, 128, 3])\n",
      "conv3.bias \t torch.Size([256])\n",
      "bn3.weight \t torch.Size([256])\n",
      "bn3.bias \t torch.Size([256])\n",
      "bn3.running_mean \t torch.Size([256])\n",
      "bn3.running_var \t torch.Size([256])\n",
      "bn3.num_batches_tracked \t torch.Size([])\n",
      "conv4.weight \t torch.Size([512, 256, 3])\n",
      "conv4.bias \t torch.Size([512])\n",
      "bn4.weight \t torch.Size([512])\n",
      "bn4.bias \t torch.Size([512])\n",
      "bn4.running_mean \t torch.Size([512])\n",
      "bn4.running_var \t torch.Size([512])\n",
      "bn4.num_batches_tracked \t torch.Size([])\n",
      "fc1.weight \t torch.Size([6, 512])\n",
      "fc1.bias \t torch.Size([6])\n",
      "Optimizer's state_dict:\n",
      "state \t {121150054224: {'step': 800, 'exp_avg': tensor([[[ 2.3700e-04,  2.0224e-04, -1.0459e-04,  ..., -2.6606e-05,\n",
      "          -2.8124e-04,  3.2228e-06]],\n",
      "\n",
      "        [[-8.8660e-04, -8.7713e-04, -3.5965e-04,  ..., -7.5834e-04,\n",
      "          -1.2369e-04,  4.5401e-04]],\n",
      "\n",
      "        [[-3.2079e-04, -9.8097e-04, -1.1254e-03,  ..., -5.6436e-04,\n",
      "           1.8636e-04,  5.9057e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1134e-04, -2.9345e-04,  1.2063e-04,  ...,  3.6446e-04,\n",
      "          -1.7274e-04, -3.9380e-04]],\n",
      "\n",
      "        [[-2.9563e-04, -1.3035e-04,  1.2053e-04,  ...,  4.3407e-04,\n",
      "           3.8068e-04,  1.8877e-04]],\n",
      "\n",
      "        [[-4.1012e-04, -1.9084e-04, -1.6714e-04,  ..., -2.7127e-04,\n",
      "          -3.6998e-05,  5.5191e-05]]]), 'exp_avg_sq': tensor([[[6.5722e-06, 8.3704e-06, 5.3223e-06,  ..., 6.7734e-06,\n",
      "          5.4993e-06, 8.9153e-06]],\n",
      "\n",
      "        [[3.3145e-06, 2.8713e-06, 3.1767e-06,  ..., 3.7607e-06,\n",
      "          3.6682e-06, 3.4652e-06]],\n",
      "\n",
      "        [[4.2402e-06, 5.0633e-06, 3.4682e-06,  ..., 4.4724e-06,\n",
      "          4.6743e-06, 4.4936e-06]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.8845e-06, 4.6009e-06, 3.4993e-06,  ..., 4.8449e-06,\n",
      "          5.5918e-06, 4.8020e-06]],\n",
      "\n",
      "        [[2.5551e-06, 2.6018e-06, 2.3325e-06,  ..., 2.2123e-06,\n",
      "          2.4751e-06, 2.8435e-06]],\n",
      "\n",
      "        [[3.7567e-06, 2.3011e-06, 3.3863e-06,  ..., 2.7278e-06,\n",
      "          3.8506e-06, 3.9586e-06]]])}, 121150447696: {'step': 800, 'exp_avg': tensor([-7.5258e-06,  7.1927e-06, -1.4126e-05,  2.3696e-06, -6.5687e-07,\n",
      "         2.6281e-06,  3.6867e-07,  2.3663e-05, -1.6080e-06,  7.1106e-06,\n",
      "        -8.3216e-06,  3.8215e-06,  3.4363e-07, -8.8848e-08,  1.0434e-05,\n",
      "        -1.5329e-06,  4.2444e-06,  1.6596e-05,  1.9810e-06,  1.8640e-06,\n",
      "         8.7516e-06,  1.7309e-06,  2.2080e-06, -5.7252e-06,  1.5584e-06,\n",
      "        -5.4642e-06, -3.6449e-06, -2.1340e-06, -2.3440e-06, -1.3745e-05,\n",
      "        -2.5474e-06, -1.0853e-05, -3.2755e-06, -4.5307e-06, -4.7740e-06,\n",
      "         8.2626e-07, -6.3182e-06, -1.7306e-06, -3.8619e-06,  4.9530e-06,\n",
      "         2.5870e-06,  6.0339e-07,  1.6055e-06,  8.7000e-07,  6.1991e-07,\n",
      "         4.2772e-06,  1.8912e-06, -5.3200e-07,  2.1672e-06,  5.3580e-06,\n",
      "        -1.2498e-05, -1.3765e-05, -4.6684e-06,  4.3252e-07,  8.5063e-06,\n",
      "        -1.0564e-06, -2.4066e-06, -7.8450e-06, -1.0568e-05,  7.0280e-06,\n",
      "        -9.7758e-07,  4.1320e-06,  9.9483e-07,  8.2587e-07, -5.6584e-06,\n",
      "        -1.3767e-06,  3.9211e-06, -9.3487e-06,  2.1410e-06,  2.1911e-06,\n",
      "         3.5864e-06,  6.9762e-06, -5.8472e-07,  4.3650e-06, -1.5936e-06,\n",
      "         6.8422e-06,  3.3863e-06, -2.8718e-07,  1.7206e-06,  4.2455e-07,\n",
      "        -1.2896e-05, -4.4343e-07,  4.8075e-06,  1.0979e-06, -1.0156e-06,\n",
      "        -1.6748e-06, -4.2577e-06, -1.3450e-06, -1.2772e-06, -4.8709e-06,\n",
      "        -6.0821e-06,  1.1365e-06, -6.2606e-07,  9.0554e-06, -7.2902e-06,\n",
      "        -5.6222e-05, -1.3254e-06, -1.0886e-05, -3.0302e-07, -1.2669e-05,\n",
      "         3.3641e-06, -3.1930e-07,  1.9170e-06, -1.5581e-06,  6.3417e-07,\n",
      "         6.1889e-06,  2.0082e-06,  2.2989e-06,  1.6394e-06, -4.2576e-06,\n",
      "         6.4060e-06,  3.1482e-06,  2.5091e-06, -4.0179e-06,  8.0001e-06,\n",
      "         1.5895e-06,  1.3844e-05, -1.7763e-05,  4.8339e-07, -1.3875e-07,\n",
      "         3.4425e-06, -6.1075e-06,  1.2892e-05, -1.0351e-06, -8.7210e-06,\n",
      "         1.8533e-06,  3.5229e-06,  1.5316e-06]), 'exp_avg_sq': tensor([1.7493e-10, 5.7011e-10, 1.5757e-09, 1.0043e-10, 4.2385e-11, 1.1355e-10,\n",
      "        3.9135e-11, 1.0069e-09, 1.0065e-10, 3.7865e-10, 3.2550e-10, 6.0109e-11,\n",
      "        4.1679e-10, 1.3281e-11, 5.7093e-10, 9.6269e-11, 1.4175e-10, 1.0611e-09,\n",
      "        1.4629e-10, 1.0405e-10, 2.7749e-10, 1.9356e-10, 1.6926e-10, 1.3574e-10,\n",
      "        4.7233e-10, 1.5561e-10, 6.3391e-10, 1.7026e-10, 2.7114e-10, 3.1176e-10,\n",
      "        2.3790e-10, 8.0443e-10, 4.3199e-10, 1.9646e-10, 8.1159e-10, 3.9455e-10,\n",
      "        2.2149e-09, 3.4769e-10, 1.0484e-10, 5.4967e-11, 6.1514e-11, 9.0474e-11,\n",
      "        5.0885e-11, 6.8440e-11, 8.3659e-11, 8.4490e-11, 1.8180e-10, 1.1429e-10,\n",
      "        1.3491e-10, 3.1467e-10, 1.1451e-09, 4.6818e-10, 4.3362e-10, 3.4398e-11,\n",
      "        1.6633e-10, 1.3032e-10, 1.1561e-10, 2.2490e-10, 3.5690e-10, 1.5889e-10,\n",
      "        8.5735e-11, 4.2405e-11, 2.5127e-11, 1.2196e-10, 1.0328e-10, 3.5439e-10,\n",
      "        1.1922e-09, 2.8836e-10, 1.2952e-09, 4.9589e-10, 1.8544e-10, 1.4755e-10,\n",
      "        2.7016e-11, 2.9457e-10, 8.5679e-10, 3.2166e-10, 1.2387e-10, 4.4169e-11,\n",
      "        3.5907e-11, 4.7488e-11, 1.9691e-09, 1.9870e-10, 1.5166e-10, 3.5050e-10,\n",
      "        9.7237e-11, 1.1006e-10, 1.8013e-10, 5.0619e-11, 8.0469e-11, 3.6947e-10,\n",
      "        1.4809e-10, 8.6162e-11, 4.2013e-10, 1.9042e-10, 3.5630e-10, 9.1330e-09,\n",
      "        2.1075e-11, 1.7248e-10, 6.2470e-11, 2.2285e-09, 3.2770e-10, 1.4034e-10,\n",
      "        5.3415e-11, 8.9352e-10, 1.6564e-10, 1.8156e-09, 5.4070e-11, 2.1628e-10,\n",
      "        1.1629e-10, 1.5350e-10, 3.2009e-10, 2.5427e-10, 1.9142e-10, 3.3292e-10,\n",
      "        1.5960e-10, 1.2947e-10, 3.8109e-10, 4.5984e-09, 3.3830e-11, 7.6988e-11,\n",
      "        7.8281e-11, 2.3776e-10, 4.3042e-10, 3.0742e-10, 6.1246e-10, 2.0494e-10,\n",
      "        2.7243e-10, 7.8509e-11])}, 121150447776: {'step': 800, 'exp_avg': tensor([ 5.9589e-04, -2.0394e-03, -1.1730e-03, -1.3560e-03, -1.7332e-04,\n",
      "         7.9972e-05, -7.4432e-05, -7.2240e-04,  3.7344e-04,  9.4194e-04,\n",
      "         9.2946e-05,  2.8032e-05,  1.1846e-03, -2.3015e-04,  1.5406e-03,\n",
      "        -4.0298e-04, -3.3646e-04,  6.7286e-04,  1.1734e-03, -9.7776e-04,\n",
      "        -2.2743e-03,  1.8715e-04, -8.1981e-04, -1.3069e-04,  7.5547e-04,\n",
      "        -1.6620e-03, -1.3411e-03, -1.1844e-04, -6.5432e-04, -4.4631e-04,\n",
      "        -2.3501e-04,  1.9545e-03, -7.3427e-04, -4.7111e-04, -9.0430e-04,\n",
      "        -1.5926e-03,  1.1966e-04,  7.0844e-04,  4.1356e-04,  4.1503e-04,\n",
      "        -1.3973e-04,  1.2932e-04,  3.5204e-04,  3.7476e-04, -2.4222e-04,\n",
      "        -1.0801e-04, -5.1055e-04,  1.4912e-03, -2.1306e-04, -8.4093e-04,\n",
      "         3.4410e-03, -5.4737e-04,  6.0216e-04,  1.0437e-04,  6.6898e-04,\n",
      "         1.0776e-03, -4.3444e-04, -1.0539e-04,  4.6664e-04, -3.9306e-04,\n",
      "         1.3063e-04,  4.2128e-04, -6.1161e-05, -3.6216e-04, -5.1929e-04,\n",
      "         8.1412e-05, -7.2439e-04,  4.1974e-04,  1.1277e-03, -9.3529e-04,\n",
      "         2.0607e-04, -3.8214e-04, -1.6689e-04,  3.9525e-04,  6.9071e-04,\n",
      "        -1.3349e-04, -2.3166e-04, -3.4869e-04, -9.2687e-05,  2.4195e-05,\n",
      "         6.1419e-04, -1.6721e-03, -8.2064e-04, -1.6067e-04, -4.4846e-04,\n",
      "        -8.0001e-04, -3.9266e-04,  1.1256e-03,  1.3758e-04, -1.8015e-04,\n",
      "        -2.4404e-03, -1.1221e-05,  2.3230e-04,  5.8764e-04,  3.4320e-05,\n",
      "        -2.6745e-03,  5.6585e-05, -2.1471e-03,  4.7654e-04,  2.3324e-03,\n",
      "         1.4761e-03, -8.0164e-04,  3.1364e-04,  3.0885e-03, -2.2704e-04,\n",
      "        -8.3912e-05, -2.9096e-04,  4.5887e-04, -4.8195e-05,  4.1117e-04,\n",
      "         8.9665e-04,  6.5818e-04,  1.6248e-03,  1.0736e-03,  5.6245e-04,\n",
      "         8.5912e-04,  2.9975e-04, -3.9945e-04, -2.5871e-04,  1.0503e-03,\n",
      "        -5.5403e-04,  1.0115e-03, -1.8134e-03,  2.0174e-03,  8.6639e-04,\n",
      "         6.6503e-04,  7.2899e-04, -1.7055e-04]), 'exp_avg_sq': tensor([3.6425e-05, 4.7391e-05, 4.5555e-05, 1.9628e-05, 1.3318e-05, 8.6067e-06,\n",
      "        9.7906e-06, 5.5974e-05, 8.8579e-06, 1.1166e-05, 1.5580e-05, 1.9645e-05,\n",
      "        2.7162e-05, 3.0097e-06, 4.4584e-05, 1.4989e-05, 5.7184e-06, 5.1698e-05,\n",
      "        2.7605e-05, 2.4110e-05, 3.7474e-05, 7.8969e-06, 3.9901e-05, 8.5270e-06,\n",
      "        4.2374e-05, 5.7932e-05, 2.1589e-05, 3.0598e-05, 3.6920e-05, 3.3569e-05,\n",
      "        1.3829e-05, 8.7106e-05, 4.2638e-05, 3.2088e-05, 5.6654e-05, 2.4117e-05,\n",
      "        3.9160e-05, 4.8461e-05, 1.4920e-05, 2.5670e-05, 7.9509e-06, 1.0077e-05,\n",
      "        2.8175e-05, 1.2005e-05, 2.9978e-06, 1.6636e-05, 2.2416e-05, 1.4363e-05,\n",
      "        6.0239e-05, 1.3258e-05, 1.2281e-04, 4.1944e-05, 2.7360e-05, 8.0541e-06,\n",
      "        3.1472e-05, 1.6785e-05, 1.4051e-05, 3.5805e-05, 1.0132e-05, 4.0753e-05,\n",
      "        2.2805e-05, 6.0798e-06, 4.5567e-06, 1.2814e-05, 1.1289e-05, 8.7459e-06,\n",
      "        3.0483e-05, 5.0733e-05, 4.2152e-05, 2.0787e-05, 2.1820e-05, 2.5101e-05,\n",
      "        1.5107e-05, 2.7642e-05, 4.6569e-05, 2.6348e-05, 2.6892e-06, 1.4692e-05,\n",
      "        1.0484e-05, 7.5291e-06, 3.7882e-05, 3.4355e-05, 2.8539e-05, 2.1168e-05,\n",
      "        4.3784e-05, 2.5127e-05, 4.5175e-06, 3.1521e-05, 4.4546e-06, 3.3387e-05,\n",
      "        2.7222e-05, 2.3625e-05, 7.6636e-06, 2.4941e-05, 1.7110e-05, 6.4178e-05,\n",
      "        8.6493e-06, 2.3694e-05, 8.2515e-06, 9.3565e-05, 9.3741e-05, 1.1531e-05,\n",
      "        4.7379e-06, 6.3449e-05, 1.4777e-05, 1.8991e-05, 7.2993e-06, 1.5332e-05,\n",
      "        1.1086e-05, 1.9192e-05, 2.3237e-05, 8.1691e-05, 3.5592e-05, 1.4796e-05,\n",
      "        2.4325e-05, 2.4057e-05, 3.1992e-05, 1.9038e-04, 1.4524e-05, 1.4588e-05,\n",
      "        5.1417e-06, 1.7052e-05, 6.8091e-05, 1.0824e-04, 7.4560e-06, 3.1777e-05,\n",
      "        1.0327e-05, 2.4302e-05])}, 121150447856: {'step': 800, 'exp_avg': tensor([-1.8089e-04,  3.7669e-04,  1.6707e-03, -1.4257e-04, -2.2390e-05,\n",
      "         5.1821e-05, -6.8613e-05, -8.9216e-04, -3.0741e-05, -1.2685e-05,\n",
      "        -3.4410e-04, -1.4159e-05,  1.8612e-04, -2.3336e-05,  5.4295e-04,\n",
      "        -8.2182e-05,  2.4943e-05, -8.5095e-04,  2.5755e-05, -1.2705e-04,\n",
      "         1.5119e-05,  8.3066e-05,  2.5855e-04,  1.0835e-04,  5.4743e-04,\n",
      "        -7.2733e-04, -4.6102e-05,  1.6033e-04,  1.2531e-04,  7.5020e-05,\n",
      "         1.9602e-05,  1.4959e-04, -2.6956e-04, -5.0454e-04, -3.5787e-04,\n",
      "         5.2791e-05, -5.7173e-04, -5.4593e-04,  7.7909e-07, -3.0141e-05,\n",
      "         5.0289e-05,  6.6568e-05,  1.0146e-04,  1.3557e-04,  5.5718e-04,\n",
      "         2.8958e-04,  9.6679e-05,  8.6813e-05, -1.2686e-04, -3.8520e-04,\n",
      "         4.0964e-04,  3.2930e-05,  3.7880e-04,  3.5638e-06,  1.8068e-04,\n",
      "        -2.8450e-04,  1.1091e-04, -8.3660e-05, -6.1912e-05, -1.0188e-04,\n",
      "        -1.9388e-04, -2.1883e-05, -1.4938e-04, -4.0473e-05,  6.3701e-05,\n",
      "        -3.2529e-04,  2.8129e-03, -4.1685e-05, -9.2772e-04,  1.2493e-04,\n",
      "         2.5690e-04, -7.7088e-05, -7.0801e-05, -7.0971e-05,  4.8624e-04,\n",
      "         1.3443e-04,  1.1196e-05, -4.3097e-05,  3.1269e-06,  2.1906e-05,\n",
      "         2.4129e-04,  1.3286e-05,  1.3105e-04, -1.5787e-04, -1.2698e-03,\n",
      "         5.5001e-05, -2.8538e-05,  6.2314e-05, -7.3346e-06,  2.7329e-04,\n",
      "         1.2539e-04, -4.5549e-05,  5.1435e-04,  5.6159e-05,  4.7025e-05,\n",
      "         4.1836e-04, -1.6824e-05,  1.6460e-04,  7.4705e-05,  1.4176e-03,\n",
      "        -1.7104e-04, -2.0611e-05, -1.0941e-04,  7.8541e-04, -1.4381e-04,\n",
      "        -4.9665e-04,  1.1391e-05, -3.8590e-05,  1.5514e-05,  8.0462e-06,\n",
      "         4.0702e-05, -2.1226e-06,  2.8976e-04,  2.0385e-04, -1.3614e-04,\n",
      "         8.6378e-05,  3.8539e-04,  2.9632e-03, -1.7757e-05, -9.3991e-05,\n",
      "         6.0643e-07, -2.2475e-04, -2.3297e-04,  1.2054e-05, -7.6250e-05,\n",
      "        -1.8251e-04, -6.7947e-05, -3.9326e-05]), 'exp_avg_sq': tensor([3.4802e-08, 4.5859e-07, 2.3839e-05, 5.4515e-07, 1.6603e-07, 3.4929e-07,\n",
      "        7.5954e-08, 1.0053e-06, 2.0394e-07, 5.7176e-08, 4.5988e-07, 3.1539e-08,\n",
      "        9.2780e-06, 2.2397e-08, 9.8450e-07, 1.9835e-07, 7.1560e-08, 6.3761e-07,\n",
      "        5.4288e-07, 2.6104e-07, 5.8368e-08, 5.8948e-07, 3.7710e-07, 1.3147e-06,\n",
      "        2.1096e-06, 6.3591e-05, 1.6911e-06, 7.1603e-07, 3.1213e-07, 9.5644e-07,\n",
      "        1.9649e-05, 4.2368e-06, 1.4517e-07, 6.0657e-07, 1.0041e-06, 6.6279e-07,\n",
      "        1.2189e-06, 1.8274e-06, 4.3242e-07, 3.3437e-08, 5.0716e-08, 1.9818e-07,\n",
      "        9.7333e-06, 3.8042e-07, 4.0386e-06, 2.4203e-07, 9.1555e-08, 4.1471e-07,\n",
      "        1.9214e-05, 1.5830e-06, 1.8253e-06, 2.9094e-07, 5.0271e-07, 1.1348e-07,\n",
      "        1.0901e-07, 3.7662e-07, 8.9919e-07, 1.7888e-07, 1.3319e-06, 5.2026e-08,\n",
      "        5.7264e-07, 7.7614e-07, 6.8286e-08, 2.3842e-07, 5.4411e-07, 6.0171e-07,\n",
      "        4.7152e-05, 1.9891e-06, 2.3690e-06, 1.0453e-06, 4.4242e-06, 2.8452e-07,\n",
      "        2.7815e-08, 9.7537e-08, 3.8180e-06, 3.7910e-08, 4.4936e-08, 5.1247e-08,\n",
      "        3.1384e-08, 6.9665e-07, 4.7393e-06, 4.1000e-07, 5.8055e-07, 2.9472e-07,\n",
      "        3.0241e-05, 9.4470e-08, 3.3459e-07, 5.4207e-07, 4.2369e-07, 5.1035e-07,\n",
      "        2.1197e-07, 3.0293e-08, 3.8680e-06, 5.7100e-08, 3.2249e-07, 3.3198e-06,\n",
      "        4.6942e-08, 5.1781e-07, 2.1065e-07, 2.4439e-05, 9.8376e-07, 1.8167e-06,\n",
      "        2.2537e-07, 9.9362e-07, 3.9273e-07, 6.2189e-07, 1.7256e-07, 4.7857e-07,\n",
      "        2.1849e-07, 6.3581e-07, 2.0708e-06, 2.4648e-05, 4.4935e-06, 6.1694e-06,\n",
      "        2.8311e-07, 3.9907e-06, 9.4532e-07, 6.0046e-05, 7.4429e-08, 4.3466e-07,\n",
      "        4.5531e-07, 8.3077e-07, 1.6561e-07, 1.7519e-06, 2.7539e-07, 1.0163e-06,\n",
      "        5.7051e-07, 1.2178e-06])}, 121150448096: {'step': 800, 'exp_avg': tensor([[[-1.4666e-05,  4.1359e-06,  1.8221e-06],\n",
      "         [-2.1974e-05, -4.0515e-05, -3.1906e-05],\n",
      "         [-1.5353e-05,  6.8917e-06, -2.9137e-05],\n",
      "         ...,\n",
      "         [ 1.1923e-05, -2.4022e-05,  7.0285e-06],\n",
      "         [-4.2392e-05, -2.7162e-05, -2.2812e-05],\n",
      "         [ 1.9471e-05,  2.6720e-05,  1.3053e-05]],\n",
      "\n",
      "        [[-2.8102e-05, -1.8993e-05, -2.3378e-05],\n",
      "         [-3.4463e-05, -1.0735e-05,  8.9908e-06],\n",
      "         [-2.2664e-05,  2.4658e-06, -4.3140e-05],\n",
      "         ...,\n",
      "         [ 9.8413e-06,  2.3415e-05,  2.1658e-05],\n",
      "         [ 7.9475e-06,  6.0594e-05,  5.2856e-05],\n",
      "         [-3.1059e-05,  1.8903e-05,  7.5425e-06]],\n",
      "\n",
      "        [[ 1.4591e-04,  1.5789e-04,  1.8722e-04],\n",
      "         [ 1.3781e-04,  1.1212e-04,  1.3635e-04],\n",
      "         [ 9.8758e-05,  1.3681e-04,  1.4622e-04],\n",
      "         ...,\n",
      "         [-1.6643e-05, -1.8968e-05,  2.1490e-05],\n",
      "         [-1.9691e-05,  6.2152e-05,  2.8782e-05],\n",
      "         [ 1.0450e-04,  1.0668e-04,  1.4065e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.6115e-04,  7.0846e-04,  7.9003e-04],\n",
      "         [ 2.2290e-04,  2.7366e-04,  3.6150e-04],\n",
      "         [ 2.5580e-04,  1.5696e-04,  2.0908e-04],\n",
      "         ...,\n",
      "         [-8.3445e-05, -2.3694e-04, -2.1787e-04],\n",
      "         [-1.6652e-04, -1.1275e-04, -3.1407e-04],\n",
      "         [ 4.3841e-04,  3.7457e-04,  3.7282e-04]],\n",
      "\n",
      "        [[-3.1571e-05,  1.3829e-05,  1.1187e-05],\n",
      "         [-9.1921e-06,  9.7079e-06,  9.6844e-06],\n",
      "         [-4.4410e-06,  1.9036e-05, -1.2132e-05],\n",
      "         ...,\n",
      "         [ 4.1021e-06,  1.8279e-05,  2.6321e-05],\n",
      "         [ 1.1322e-05,  4.4413e-05,  1.0383e-05],\n",
      "         [-2.2701e-05,  9.7797e-06, -7.6377e-06]],\n",
      "\n",
      "        [[ 2.6202e-05,  3.1239e-05,  2.6477e-05],\n",
      "         [ 1.6543e-05,  1.9272e-05,  1.6263e-05],\n",
      "         [-2.4694e-05, -2.2947e-05, -1.8743e-05],\n",
      "         ...,\n",
      "         [ 2.8545e-06, -9.8605e-06,  7.4464e-07],\n",
      "         [-1.4989e-05, -1.0823e-05, -7.9617e-06],\n",
      "         [ 1.3423e-05,  1.4864e-05,  1.6136e-05]]]), 'exp_avg_sq': tensor([[[4.8254e-07, 5.0339e-07, 5.8252e-07],\n",
      "         [2.1102e-07, 2.7059e-07, 1.5279e-07],\n",
      "         [1.2671e-07, 1.6619e-07, 1.4075e-07],\n",
      "         ...,\n",
      "         [1.9085e-07, 1.5926e-07, 1.7267e-07],\n",
      "         [1.3382e-07, 1.3335e-07, 1.9764e-07],\n",
      "         [3.3579e-07, 3.0210e-07, 3.2255e-07]],\n",
      "\n",
      "        [[2.8409e-08, 2.6608e-08, 2.5328e-08],\n",
      "         [3.1383e-08, 2.1615e-08, 1.1315e-07],\n",
      "         [4.0466e-08, 2.8077e-08, 3.4884e-08],\n",
      "         ...,\n",
      "         [5.8531e-08, 3.4248e-08, 4.4448e-08],\n",
      "         [6.1338e-08, 3.0788e-08, 6.3780e-08],\n",
      "         [3.2499e-08, 1.8785e-08, 2.7943e-08]],\n",
      "\n",
      "        [[1.8795e-07, 1.6867e-07, 1.6106e-07],\n",
      "         [1.8811e-07, 1.5480e-07, 1.8824e-07],\n",
      "         [9.1310e-08, 8.1324e-08, 7.3267e-08],\n",
      "         ...,\n",
      "         [9.9867e-08, 1.8870e-07, 1.2818e-07],\n",
      "         [1.3201e-07, 1.4428e-07, 2.7980e-07],\n",
      "         [2.4082e-07, 1.3031e-07, 2.1984e-07]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.0006e-07, 8.6140e-07, 9.4189e-07],\n",
      "         [6.5999e-07, 5.8322e-07, 7.6408e-07],\n",
      "         [9.3986e-07, 9.8590e-07, 1.0137e-06],\n",
      "         ...,\n",
      "         [9.1563e-07, 1.0159e-06, 9.0920e-07],\n",
      "         [6.3224e-07, 7.1637e-07, 6.5325e-07],\n",
      "         [4.2675e-07, 5.3287e-07, 4.5078e-07]],\n",
      "\n",
      "        [[3.6754e-08, 2.5581e-08, 2.0364e-08],\n",
      "         [1.0166e-08, 1.8835e-08, 1.1085e-08],\n",
      "         [2.6147e-08, 2.2266e-08, 2.5667e-08],\n",
      "         ...,\n",
      "         [2.5569e-08, 2.2267e-08, 3.1902e-08],\n",
      "         [1.7477e-08, 1.7560e-08, 1.8181e-08],\n",
      "         [5.2994e-08, 2.0592e-08, 4.5774e-08]],\n",
      "\n",
      "        [[2.9038e-07, 1.2091e-07, 1.2343e-07],\n",
      "         [1.9731e-08, 6.0709e-08, 4.0480e-08],\n",
      "         [2.3655e-07, 5.0298e-08, 7.3272e-08],\n",
      "         ...,\n",
      "         [1.2251e-07, 7.7378e-08, 2.6238e-08],\n",
      "         [1.0847e-07, 9.4451e-08, 4.6565e-08],\n",
      "         [8.2711e-08, 5.5042e-08, 4.9458e-08]]])}, 121150448176: {'step': 800, 'exp_avg': tensor([ 5.9631e-09,  1.0030e-09, -4.9879e-09, -3.8125e-09, -3.9288e-09,\n",
      "         1.0124e-09, -1.9660e-08,  1.4235e-12,  5.2628e-10,  1.6628e-09,\n",
      "        -2.9784e-10,  2.1995e-10, -2.2204e-08,  6.0587e-09, -7.6486e-09,\n",
      "        -1.6836e-09,  1.0092e-08, -1.1417e-08,  3.9051e-09,  6.6654e-09,\n",
      "         1.2908e-08,  2.4827e-08,  1.6096e-09,  3.3993e-08,  5.1638e-11,\n",
      "         8.4368e-11, -3.4574e-09, -1.9592e-09,  1.0557e-08,  2.7239e-09,\n",
      "        -2.4376e-09, -1.8339e-09,  1.8041e-10,  3.0976e-11,  9.8122e-11,\n",
      "         7.9616e-10, -1.3626e-09,  6.2347e-09,  2.1385e-08, -1.4499e-09,\n",
      "        -3.8130e-09, -9.9431e-11, -2.5115e-08, -1.5994e-10, -7.7761e-09,\n",
      "        -3.2573e-10,  5.6879e-09, -1.3504e-08,  1.2440e-09, -4.5741e-11,\n",
      "        -5.8500e-09,  5.5489e-09,  1.8595e-08,  3.3693e-09, -3.9301e-09,\n",
      "        -4.2893e-09,  1.3174e-09, -1.3168e-09, -5.9150e-09,  2.8941e-09,\n",
      "        -3.2924e-09,  1.1843e-08, -2.1855e-08,  3.6350e-09,  4.6577e-09,\n",
      "        -2.4448e-08, -1.2003e-08,  4.0611e-09,  1.7215e-08,  2.9475e-09,\n",
      "        -1.1462e-08,  3.9400e-08, -4.5030e-10,  1.8972e-08,  4.4133e-11,\n",
      "        -1.0106e-08, -6.6413e-11,  8.6766e-09,  6.7926e-08, -3.4655e-08,\n",
      "        -1.9375e-10,  1.1822e-10,  1.8578e-09, -7.6952e-09, -5.6504e-09,\n",
      "         1.2478e-08,  1.7733e-09, -3.1892e-09,  6.3510e-10, -2.1747e-09,\n",
      "         3.5233e-09, -4.8486e-09,  9.2862e-09, -5.1690e-09,  4.6490e-10,\n",
      "        -5.0869e-08, -3.0285e-09, -1.1500e-07,  7.8944e-10,  2.7305e-08,\n",
      "        -1.5995e-08, -1.2915e-09, -7.9911e-10, -1.9010e-08,  1.1067e-09,\n",
      "         2.4943e-08, -3.6751e-08,  1.3177e-09,  4.3411e-08,  9.4697e-10,\n",
      "         1.1426e-08, -1.3890e-09,  2.7962e-09, -6.6133e-10, -9.9746e-09,\n",
      "        -3.8909e-09,  1.3822e-11,  7.0278e-09,  1.2527e-08,  3.1151e-10,\n",
      "        -1.9753e-08, -1.0101e-08,  1.2151e-11,  1.7300e-09, -3.3468e-11,\n",
      "         1.2817e-08,  6.3993e-10,  1.1744e-09]), 'exp_avg_sq': tensor([3.5783e-15, 1.6176e-15, 3.1667e-15, 3.4166e-14, 1.4329e-15, 1.3935e-14,\n",
      "        2.0667e-14, 1.3679e-15, 3.6932e-14, 2.8242e-14, 3.6892e-15, 7.0029e-15,\n",
      "        1.3905e-14, 2.2722e-14, 2.9060e-14, 2.6166e-14, 2.1016e-14, 2.2945e-15,\n",
      "        7.1481e-15, 2.4331e-14, 2.2448e-14, 2.9668e-14, 3.2757e-15, 6.0399e-15,\n",
      "        6.8346e-16, 2.5778e-15, 3.1359e-14, 7.3608e-15, 1.6249e-15, 2.3219e-14,\n",
      "        2.3095e-14, 1.1609e-15, 6.1913e-15, 2.1129e-14, 3.5442e-14, 1.6087e-15,\n",
      "        1.7641e-15, 1.6363e-15, 1.0540e-14, 8.5646e-15, 4.4185e-14, 1.9623e-14,\n",
      "        1.6194e-14, 3.3025e-14, 2.0473e-15, 1.6739e-14, 8.0163e-15, 2.1431e-14,\n",
      "        1.4975e-15, 3.7949e-14, 4.3598e-14, 1.7558e-14, 1.0790e-14, 7.9094e-15,\n",
      "        1.1079e-14, 8.8245e-15, 3.9382e-15, 1.1241e-14, 3.5076e-14, 9.7173e-15,\n",
      "        6.7579e-16, 3.5970e-15, 3.6537e-14, 2.3241e-14, 4.0847e-14, 3.5568e-14,\n",
      "        1.1242e-15, 1.7994e-14, 8.2084e-15, 3.6515e-14, 2.9633e-14, 2.4309e-14,\n",
      "        1.4095e-14, 1.3075e-14, 1.1404e-14, 4.4850e-15, 3.9666e-14, 3.7630e-14,\n",
      "        2.3478e-14, 3.0133e-15, 4.2148e-15, 2.1298e-15, 1.4119e-15, 8.0694e-15,\n",
      "        1.9584e-15, 2.7782e-14, 2.1952e-14, 1.7320e-15, 1.7735e-15, 6.5648e-15,\n",
      "        1.3224e-15, 1.1994e-14, 3.7208e-14, 1.8225e-15, 3.5520e-15, 2.7599e-14,\n",
      "        2.6998e-14, 1.3586e-14, 4.0585e-16, 3.6797e-14, 3.5829e-14, 9.8684e-15,\n",
      "        2.5233e-14, 1.3890e-14, 3.8021e-15, 3.4066e-14, 1.1818e-14, 1.4165e-14,\n",
      "        2.1003e-14, 4.2044e-14, 1.9534e-14, 1.2059e-14, 2.0138e-14, 8.2607e-16,\n",
      "        5.0040e-15, 1.4975e-15, 3.8162e-14, 1.6471e-14, 4.8387e-14, 2.1388e-14,\n",
      "        9.3118e-15, 1.4389e-14, 2.3761e-15, 2.4138e-14, 2.5727e-14, 2.9119e-15,\n",
      "        3.5729e-14, 4.8250e-15])}, 121150448256: {'step': 800, 'exp_avg': tensor([ 1.0965e-03, -3.2177e-04, -5.7352e-04,  1.1085e-03, -1.5771e-04,\n",
      "        -3.5590e-05, -1.7161e-03, -1.2630e-05,  7.1681e-04,  7.6325e-04,\n",
      "         1.3208e-04,  1.3539e-04,  7.1430e-04,  3.9602e-04, -2.6222e-04,\n",
      "        -2.5121e-04, -1.6768e-06,  3.0148e-04, -3.1356e-04, -1.3316e-03,\n",
      "        -1.4233e-03,  7.8498e-04, -2.3742e-04, -2.7311e-04, -1.3633e-05,\n",
      "        -7.4058e-04,  9.2501e-05,  4.4327e-04,  2.9984e-04,  3.9160e-05,\n",
      "         8.4411e-04,  8.3578e-04, -6.7955e-05, -2.8351e-04, -4.2639e-04,\n",
      "        -6.1380e-05,  2.3018e-04,  7.9479e-04,  1.7879e-06,  9.2200e-04,\n",
      "        -7.2873e-04,  1.0364e-04, -3.2110e-03,  4.0685e-05,  4.7885e-04,\n",
      "        -3.6895e-04,  8.5140e-05,  9.4311e-04,  1.0714e-03, -1.9206e-04,\n",
      "         5.7338e-06,  7.5871e-04, -1.1085e-04, -2.8125e-03, -1.7537e-04,\n",
      "        -1.2025e-04,  5.1698e-04,  2.9617e-04,  3.6626e-04,  7.1743e-04,\n",
      "         8.5750e-04,  8.6091e-04, -2.0485e-03,  2.6231e-04,  1.6850e-03,\n",
      "         2.4561e-03,  1.0823e-03, -3.6130e-06, -1.6995e-04, -9.5803e-04,\n",
      "         4.6173e-04,  4.9838e-04,  3.4329e-04, -3.8723e-03, -2.7918e-04,\n",
      "         3.9185e-05,  8.7343e-04,  3.1593e-04,  2.7369e-03, -2.9998e-03,\n",
      "         2.4896e-04,  1.6756e-04, -3.6909e-04,  3.4253e-03, -1.1519e-04,\n",
      "         5.9711e-04, -9.4841e-04,  7.4138e-04, -5.0044e-04,  5.7677e-04,\n",
      "         1.1243e-03,  6.3754e-05,  1.2924e-03, -3.6134e-05,  1.1989e-04,\n",
      "         6.8510e-05,  8.7445e-04,  1.7037e-04, -2.2763e-04,  5.3398e-03,\n",
      "         5.3264e-04,  9.6128e-04,  1.3615e-04,  1.8448e-04,  8.8280e-04,\n",
      "         8.9044e-05,  2.4175e-03,  5.4333e-04, -1.4005e-03,  1.1149e-03,\n",
      "        -5.2257e-04, -5.8997e-05, -1.1231e-04, -5.1936e-04,  7.8389e-04,\n",
      "        -1.4830e-04, -9.1258e-05,  3.7931e-04,  1.6383e-03, -2.9511e-04,\n",
      "         1.5413e-03, -1.3805e-03, -1.3410e-04,  5.6189e-04, -1.3792e-04,\n",
      "        -2.6457e-03, -5.4829e-06,  6.4064e-04]), 'exp_avg_sq': tensor([2.7529e-05, 1.8024e-05, 2.3162e-05, 2.2496e-05, 1.9680e-05, 1.4985e-05,\n",
      "        8.6612e-05, 5.7566e-06, 3.5948e-05, 1.3352e-04, 1.6212e-05, 6.5701e-06,\n",
      "        3.1889e-05, 1.1796e-05, 7.5786e-06, 2.8444e-05, 6.8508e-06, 2.8960e-05,\n",
      "        5.2793e-05, 1.9502e-04, 1.1824e-04, 2.9723e-05, 8.8910e-06, 3.6573e-05,\n",
      "        1.2610e-05, 1.8571e-05, 1.9003e-05, 2.2077e-05, 4.0535e-05, 8.0677e-06,\n",
      "        2.3308e-05, 3.6527e-05, 1.5462e-05, 6.7137e-06, 1.1068e-05, 1.5853e-05,\n",
      "        1.1429e-05, 2.7418e-05, 1.2208e-05, 1.8427e-05, 8.0928e-05, 1.0856e-05,\n",
      "        4.0503e-05, 4.9399e-06, 1.3002e-05, 1.5993e-05, 1.6974e-05, 2.0764e-05,\n",
      "        1.9969e-05, 7.8554e-06, 3.0063e-05, 7.4552e-05, 1.1091e-04, 7.9041e-05,\n",
      "        7.8081e-06, 2.0934e-04, 1.4163e-05, 3.1299e-05, 8.9785e-06, 3.0190e-05,\n",
      "        1.7849e-05, 3.0535e-05, 7.9754e-05, 8.0165e-06, 1.7148e-05, 5.6804e-05,\n",
      "        1.9376e-05, 6.9795e-06, 2.7649e-05, 5.3416e-05, 9.4524e-05, 2.8312e-05,\n",
      "        7.9611e-06, 1.5222e-04, 2.6157e-05, 8.5254e-06, 1.7045e-05, 8.8378e-05,\n",
      "        5.5936e-05, 5.6289e-05, 3.1114e-05, 8.9546e-06, 1.3074e-05, 1.1415e-04,\n",
      "        2.9302e-05, 2.1608e-05, 1.5518e-05, 1.5270e-05, 9.6430e-06, 5.8236e-05,\n",
      "        1.4578e-05, 1.8553e-05, 9.0159e-05, 6.3780e-06, 7.2659e-05, 5.5605e-05,\n",
      "        2.3453e-05, 1.3217e-04, 4.3364e-05, 1.3724e-04, 2.7884e-05, 1.8504e-05,\n",
      "        5.9381e-06, 7.2407e-05, 2.0101e-05, 3.0623e-05, 1.3246e-04, 8.6804e-05,\n",
      "        2.8349e-05, 3.5641e-05, 2.1984e-05, 7.3901e-06, 4.6667e-05, 2.4173e-05,\n",
      "        1.7782e-05, 8.8944e-06, 6.4119e-06, 1.2640e-05, 3.7151e-05, 1.5867e-05,\n",
      "        1.3080e-05, 8.4724e-05, 8.1030e-06, 2.5454e-05, 8.8226e-06, 1.2144e-04,\n",
      "        2.8712e-05, 2.0779e-05])}, 121150448016: {'step': 800, 'exp_avg': tensor([ 1.8662e-03,  2.2487e-04, -2.2401e-04,  1.3477e-03,  5.1711e-04,\n",
      "         3.6826e-05, -1.6767e-03, -2.0068e-05,  1.3577e-03, -1.9599e-03,\n",
      "         1.4673e-04, -1.7971e-05,  1.5143e-03,  4.6376e-04, -1.5095e-04,\n",
      "         5.4697e-04,  6.5652e-04,  1.0864e-03, -5.9694e-04, -1.2993e-04,\n",
      "        -1.5164e-03,  1.6553e-03, -1.1301e-04,  2.5152e-04,  1.4611e-04,\n",
      "        -1.0273e-04,  7.8210e-05, -3.3179e-04,  3.8367e-04,  4.0505e-04,\n",
      "         1.0902e-03, -4.5026e-04,  2.5605e-04, -1.0527e-04, -1.2462e-04,\n",
      "         1.6862e-04,  3.3660e-04,  3.7451e-04,  8.4267e-04,  1.2584e-03,\n",
      "        -3.2627e-04,  2.4841e-04, -2.6009e-04,  2.0473e-04,  7.7308e-04,\n",
      "         5.8939e-05,  1.0489e-03,  1.8874e-03,  1.2457e-03, -4.4802e-05,\n",
      "        -3.8155e-04, -3.7293e-04, -4.7132e-04, -1.1971e-03, -9.9949e-05,\n",
      "        -2.5816e-03,  6.6186e-04,  4.1632e-04,  1.2190e-03,  1.6352e-03,\n",
      "         1.3430e-03, -4.4785e-05, -1.4884e-03,  4.1000e-04,  1.5710e-03,\n",
      "         1.9319e-03,  1.8397e-03,  5.6518e-05,  3.3371e-04, -7.9085e-05,\n",
      "        -2.3781e-04,  1.0899e-03,  5.3513e-05, -2.9582e-03, -6.4863e-04,\n",
      "         4.4678e-04,  1.1651e-03,  5.2709e-04,  2.5164e-03, -2.3573e-03,\n",
      "        -2.2080e-04, -1.4450e-05,  1.3516e-04,  1.0638e-03,  3.5621e-04,\n",
      "         1.4549e-03, -8.5557e-05,  1.0607e-03, -5.3779e-04, -1.4948e-03,\n",
      "         1.7374e-03,  1.5675e-04, -1.3591e-03,  1.6963e-04, -1.4725e-03,\n",
      "         4.2134e-06,  1.3275e-03,  2.7075e-03,  3.8122e-04,  1.9103e-03,\n",
      "         8.0212e-04,  1.3694e-03,  4.8515e-05,  3.8591e-04,  1.1264e-03,\n",
      "         3.9581e-04,  1.0256e-03, -2.1165e-03, -1.6690e-03,  7.0872e-04,\n",
      "        -9.9785e-05,  2.2556e-04,  5.9667e-04,  2.1595e-04,  7.9426e-04,\n",
      "        -7.9140e-05, -3.0491e-05,  5.8862e-04,  1.0187e-03,  1.0627e-04,\n",
      "         1.8480e-03, -6.5843e-05, -7.2784e-05, -9.9578e-04, -1.3882e-05,\n",
      "         7.4047e-04,  2.4476e-04, -1.6518e-04]), 'exp_avg_sq': tensor([2.4562e-05, 3.3869e-06, 1.0935e-05, 4.4563e-05, 1.3070e-05, 1.1103e-05,\n",
      "        5.5403e-05, 1.3493e-06, 1.8604e-05, 8.6615e-05, 3.6918e-05, 1.9306e-06,\n",
      "        7.3062e-05, 1.2146e-05, 1.6149e-05, 6.2977e-05, 1.4045e-05, 2.2047e-05,\n",
      "        1.6306e-05, 1.0663e-04, 4.9295e-05, 6.6773e-05, 1.8572e-05, 6.2106e-05,\n",
      "        5.0917e-06, 3.7863e-06, 4.1556e-05, 1.3087e-05, 1.1148e-05, 1.6679e-05,\n",
      "        4.3429e-05, 1.9053e-05, 6.8133e-06, 1.2578e-06, 2.0844e-06, 1.2676e-05,\n",
      "        2.2090e-05, 2.3621e-05, 2.9478e-05, 2.1775e-05, 4.8327e-05, 4.6127e-06,\n",
      "        1.4293e-05, 1.0331e-05, 2.5408e-05, 4.9313e-06, 4.1641e-05, 2.6843e-05,\n",
      "        3.9828e-05, 1.4193e-06, 1.4128e-05, 4.0899e-05, 9.5692e-05, 3.7375e-05,\n",
      "        1.6902e-05, 6.8860e-05, 2.9455e-05, 1.0643e-05, 1.9479e-05, 2.3461e-05,\n",
      "        1.9121e-05, 3.1976e-05, 1.5587e-04, 1.4628e-05, 2.3511e-05, 5.2565e-05,\n",
      "        2.1633e-05, 1.3698e-05, 5.0567e-05, 1.6055e-05, 3.8699e-05, 6.2279e-05,\n",
      "        4.0880e-06, 2.1934e-04, 6.0852e-05, 1.7046e-05, 1.6152e-05, 3.8068e-05,\n",
      "        7.9103e-05, 9.6187e-05, 1.0609e-05, 3.7004e-06, 2.5548e-05, 4.7615e-05,\n",
      "        6.6130e-05, 2.5905e-05, 5.0462e-06, 2.7904e-05, 2.0142e-05, 4.6072e-05,\n",
      "        2.1425e-05, 4.2046e-05, 5.1836e-05, 1.3182e-05, 6.6757e-05, 4.7952e-05,\n",
      "        1.9067e-05, 3.2739e-05, 5.0641e-05, 3.3404e-05, 5.0569e-05, 4.1169e-05,\n",
      "        1.9897e-06, 6.4927e-05, 1.1849e-05, 5.4392e-05, 1.2357e-05, 7.3993e-05,\n",
      "        5.2720e-05, 1.3095e-05, 5.4355e-05, 1.4499e-05, 3.7197e-05, 5.6318e-06,\n",
      "        1.3697e-05, 2.0179e-05, 1.1376e-06, 2.4361e-05, 3.7002e-05, 4.3889e-06,\n",
      "        2.2006e-05, 6.9473e-05, 2.0921e-06, 3.1722e-05, 2.4305e-06, 4.9597e-05,\n",
      "        6.3908e-06, 9.2000e-06])}, 121150448576: {'step': 800, 'exp_avg': tensor([[[-5.0911e-05, -7.4629e-05, -1.1800e-04],\n",
      "         [ 4.4725e-05, -6.0286e-06, -3.4735e-05],\n",
      "         [ 2.7485e-04,  1.8061e-04,  1.6608e-04],\n",
      "         ...,\n",
      "         [ 8.2418e-05,  3.4428e-05, -1.5257e-04],\n",
      "         [ 5.7477e-05, -9.4509e-06, -4.6119e-05],\n",
      "         [ 5.1636e-05, -5.8504e-05, -8.5019e-05]],\n",
      "\n",
      "        [[-1.4532e-06, -5.6015e-07, -3.5694e-06],\n",
      "         [ 2.4250e-05,  2.2376e-05,  2.3202e-05],\n",
      "         [-7.2388e-06, -9.4356e-06, -1.0111e-05],\n",
      "         ...,\n",
      "         [ 8.5274e-06,  8.9683e-06, -1.1954e-05],\n",
      "         [ 3.3624e-05,  2.7606e-05,  2.8103e-05],\n",
      "         [ 4.1621e-05,  2.6146e-05,  3.2043e-05]],\n",
      "\n",
      "        [[-2.2737e-05, -3.9906e-05, -5.6877e-05],\n",
      "         [ 4.7900e-06,  1.7338e-05,  3.2706e-06],\n",
      "         [ 2.1201e-04,  1.4609e-04,  1.4810e-04],\n",
      "         ...,\n",
      "         [-1.5850e-05, -7.1390e-06, -9.3946e-05],\n",
      "         [ 2.2598e-05,  2.8369e-05,  1.1024e-05],\n",
      "         [ 4.8116e-05,  3.7895e-05,  2.8667e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7087e-05,  1.9129e-05,  1.8023e-05],\n",
      "         [ 1.5613e-05,  2.4079e-05,  2.0702e-05],\n",
      "         [-1.5832e-05, -1.2881e-05, -1.2257e-05],\n",
      "         ...,\n",
      "         [-6.8652e-06,  1.5127e-05,  1.7963e-05],\n",
      "         [ 1.2276e-05,  2.2115e-05,  2.5668e-05],\n",
      "         [-6.8115e-06,  9.0385e-06,  9.2894e-06]],\n",
      "\n",
      "        [[ 1.2689e-05,  1.0037e-05,  8.9784e-06],\n",
      "         [-5.9970e-06, -8.4222e-06, -8.7506e-06],\n",
      "         [ 1.5962e-05,  1.5242e-05,  1.6120e-05],\n",
      "         ...,\n",
      "         [-2.3463e-05, -2.3692e-05, -4.2993e-05],\n",
      "         [-1.2015e-06, -3.1015e-06, -4.8639e-06],\n",
      "         [-8.6119e-07, -9.2424e-06, -1.0991e-05]],\n",
      "\n",
      "        [[-4.2629e-05, -3.7574e-05, -2.3727e-05],\n",
      "         [-1.5228e-05, -2.0959e-05, -1.9158e-05],\n",
      "         [-1.9333e-06, -1.2985e-05, -6.2415e-06],\n",
      "         ...,\n",
      "         [ 1.1869e-04,  9.2537e-05,  6.1421e-05],\n",
      "         [-1.7380e-05, -2.0433e-05, -2.1997e-05],\n",
      "         [ 2.2876e-05, -1.5784e-06, -1.5167e-05]]]), 'exp_avg_sq': tensor([[[2.9473e-07, 3.8257e-07, 3.9650e-07],\n",
      "         [2.2501e-07, 2.5928e-07, 3.3025e-07],\n",
      "         [8.3035e-07, 8.8506e-07, 9.4783e-07],\n",
      "         ...,\n",
      "         [4.8180e-06, 5.1632e-06, 5.8249e-06],\n",
      "         [2.7378e-07, 3.4820e-07, 4.0926e-07],\n",
      "         [1.0398e-06, 1.2187e-06, 1.3880e-06]],\n",
      "\n",
      "        [[1.6081e-07, 1.2323e-07, 9.0339e-08],\n",
      "         [6.6568e-08, 7.4009e-08, 6.5480e-08],\n",
      "         [1.0131e-07, 1.2567e-07, 1.1630e-07],\n",
      "         ...,\n",
      "         [2.4241e-07, 2.5230e-07, 2.3692e-07],\n",
      "         [5.0948e-08, 5.4752e-08, 5.9425e-08],\n",
      "         [3.1844e-08, 8.0158e-08, 3.5708e-08]],\n",
      "\n",
      "        [[7.2226e-08, 8.7787e-08, 7.5053e-08],\n",
      "         [5.2261e-08, 6.5211e-08, 1.0472e-07],\n",
      "         [3.1538e-07, 3.2004e-07, 3.2415e-07],\n",
      "         ...,\n",
      "         [1.9472e-06, 2.1332e-06, 2.6461e-06],\n",
      "         [6.2549e-08, 8.9039e-08, 1.2303e-07],\n",
      "         [3.1856e-07, 3.9630e-07, 4.7106e-07]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.5640e-07, 1.7598e-07, 2.0314e-07],\n",
      "         [3.7538e-08, 4.0011e-08, 3.8277e-08],\n",
      "         [4.5949e-07, 2.6195e-07, 4.1777e-07],\n",
      "         ...,\n",
      "         [3.4688e-07, 4.2821e-07, 3.7003e-07],\n",
      "         [3.6278e-08, 4.1843e-08, 4.3317e-08],\n",
      "         [6.0192e-07, 5.5146e-07, 4.5225e-07]],\n",
      "\n",
      "        [[8.0323e-08, 1.0252e-07, 1.0410e-07],\n",
      "         [2.4021e-08, 2.7394e-08, 3.2673e-08],\n",
      "         [5.0499e-08, 6.9720e-08, 5.4910e-08],\n",
      "         ...,\n",
      "         [2.2551e-07, 2.7491e-07, 2.5482e-07],\n",
      "         [2.1570e-08, 2.3936e-08, 2.2340e-08],\n",
      "         [4.4375e-08, 6.9364e-08, 4.1815e-08]],\n",
      "\n",
      "        [[1.5630e-07, 1.3476e-07, 1.6588e-07],\n",
      "         [3.7856e-08, 3.2675e-08, 4.5358e-08],\n",
      "         [5.5740e-08, 4.4686e-08, 5.7045e-08],\n",
      "         ...,\n",
      "         [5.3015e-07, 5.3264e-07, 5.6798e-07],\n",
      "         [2.7871e-08, 2.5505e-08, 3.0322e-08],\n",
      "         [7.1275e-08, 7.0013e-08, 7.4694e-08]]])}, 121150448656: {'step': 800, 'exp_avg': tensor([-7.1615e-09, -1.3962e-10,  2.1800e-09, -4.5802e-11,  7.8010e-10,\n",
      "         5.7393e-10,  3.4494e-09, -4.1646e-10, -4.6556e-10,  2.6990e-09,\n",
      "        -2.5149e-09, -4.3063e-12,  7.6129e-10, -1.1591e-09,  4.6171e-09,\n",
      "        -1.0710e-09, -3.8833e-11, -4.4745e-10,  1.9026e-10, -3.7060e-10,\n",
      "         1.2701e-09, -2.0002e-09, -3.2265e-09,  5.3593e-11,  3.2971e-10,\n",
      "        -2.6298e-10,  4.4346e-10, -8.2101e-10,  1.4053e-09, -1.6294e-09,\n",
      "         3.3850e-10, -1.0147e-09, -1.6494e-09, -4.7751e-09,  2.4631e-10,\n",
      "         1.3754e-10,  1.9843e-09,  1.6286e-09, -8.7327e-10,  5.8298e-09,\n",
      "        -4.5766e-09,  3.6159e-09, -7.7246e-10, -4.3301e-09, -5.2264e-10,\n",
      "        -7.5449e-10,  1.4347e-10,  1.3196e-09,  1.3251e-09, -8.4566e-10,\n",
      "         3.3050e-09,  1.8411e-10, -2.8231e-09, -3.7287e-09, -6.0883e-11,\n",
      "         3.4422e-10,  1.1479e-10, -3.1563e-09, -7.6737e-10,  4.2865e-10,\n",
      "         8.8815e-10, -1.3577e-09, -9.2452e-10, -1.3856e-09, -1.4276e-10,\n",
      "         1.6232e-09,  1.7000e-10, -1.5240e-09,  1.0655e-09,  2.9338e-09,\n",
      "         2.2917e-09,  3.3064e-10,  2.0668e-09,  3.0914e-10,  5.5995e-09,\n",
      "        -2.7430e-10,  5.5409e-10,  4.0135e-10,  3.9768e-09,  1.9775e-10,\n",
      "        -4.7750e-11, -3.3435e-09, -4.6349e-10, -6.5863e-09,  5.8319e-10,\n",
      "        -2.0736e-09,  1.5483e-12, -1.5646e-09,  7.4143e-10, -1.0111e-10,\n",
      "        -1.2424e-11,  9.1031e-10,  2.3236e-09, -1.8809e-09, -2.7844e-10,\n",
      "        -1.7349e-11,  1.3111e-09, -1.4643e-10, -4.7582e-10,  2.7062e-09,\n",
      "        -4.1887e-10, -3.6870e-11,  1.6433e-11, -2.6257e-11,  1.6051e-09,\n",
      "        -2.8021e-10, -4.6529e-11, -2.1023e-09,  1.7663e-09, -1.0754e-09,\n",
      "        -1.0984e-09,  1.6381e-10, -4.2541e-10,  3.0604e-09,  6.6429e-10,\n",
      "         2.6199e-10,  8.2372e-10, -1.7857e-09, -1.1434e-09, -2.4169e-10,\n",
      "         4.0955e-10,  1.2860e-09, -2.1724e-09, -5.5610e-10,  2.1273e-10,\n",
      "        -2.2339e-10,  1.0490e-09,  6.9121e-11,  1.4198e-10, -5.2806e-11,\n",
      "        -1.6981e-10, -2.3085e-09,  1.0002e-10, -1.6953e-09,  8.7103e-10,\n",
      "         8.0416e-11,  1.0731e-10, -1.5061e-09,  1.3234e-09, -1.6106e-09,\n",
      "         2.3138e-10,  5.0450e-11, -2.7676e-10, -3.2493e-10, -6.7301e-11,\n",
      "        -6.1930e-10,  2.0268e-09,  2.4822e-10,  9.2237e-11,  1.2553e-10,\n",
      "        -2.0215e-09, -6.3696e-10, -3.1759e-09, -2.3754e-09, -1.9935e-10,\n",
      "        -1.5040e-10, -6.3066e-10, -1.5272e-09,  6.7435e-10, -3.1997e-09,\n",
      "        -1.3369e-10, -3.6639e-10,  4.1784e-09, -3.7196e-10,  2.1821e-09,\n",
      "        -4.7318e-09,  9.1292e-11, -2.3937e-09,  2.1241e-10, -2.5304e-10,\n",
      "        -2.7146e-10,  1.1487e-10, -6.2692e-09,  3.1188e-09,  3.2367e-10,\n",
      "        -1.9777e-10,  2.0161e-09, -8.9991e-10, -1.1856e-10, -7.7732e-11,\n",
      "        -1.1538e-09,  5.5627e-10,  1.5290e-09, -2.7600e-09,  2.4320e-09,\n",
      "         1.0844e-10,  9.8128e-11,  3.3114e-10, -1.3866e-10, -1.1150e-09,\n",
      "         1.4713e-09, -1.0814e-09,  1.7748e-09, -8.5234e-10,  8.3851e-10,\n",
      "        -8.9295e-10,  2.3330e-09,  1.5690e-09,  2.1203e-10, -1.0014e-10,\n",
      "         1.4215e-09,  4.1733e-10,  2.6828e-10,  4.5441e-10,  1.6681e-10,\n",
      "         2.7325e-09, -3.1077e-10,  3.7982e-10,  1.1643e-10, -7.1747e-10,\n",
      "         5.7712e-09,  1.6753e-09, -3.3376e-09,  1.4117e-11, -9.9559e-10,\n",
      "        -8.8309e-10,  2.4366e-10, -1.4923e-09,  5.7015e-10,  5.3754e-10,\n",
      "        -2.1982e-09,  1.6815e-10,  1.6594e-09, -6.3004e-11,  9.1652e-10,\n",
      "        -2.4626e-10, -2.2972e-09,  7.4411e-10,  1.2089e-09,  6.9598e-10,\n",
      "         2.2961e-10,  6.7114e-10,  6.5775e-10,  2.3258e-09,  4.7905e-10,\n",
      "        -2.9447e-09,  1.7989e-09,  1.4495e-09,  2.8013e-10, -5.4143e-10,\n",
      "        -3.8608e-10, -4.8240e-10, -6.9111e-10, -4.8559e-10, -2.8512e-09,\n",
      "        -7.8368e-10, -2.3969e-10,  8.7152e-09, -1.8390e-09,  4.2416e-09,\n",
      "         3.9693e-09,  1.3654e-09, -5.1056e-11,  9.1999e-11,  8.7199e-10,\n",
      "         4.1818e-09]), 'exp_avg_sq': tensor([9.1931e-16, 2.8399e-14, 3.6381e-14, 2.0224e-14, 1.3839e-14, 2.2658e-15,\n",
      "        2.5445e-14, 2.5529e-14, 1.1533e-14, 4.1282e-14, 1.3576e-14, 1.7677e-14,\n",
      "        2.7231e-14, 9.2455e-15, 3.5057e-15, 5.8538e-15, 4.5592e-15, 7.5355e-16,\n",
      "        9.2364e-15, 3.7284e-14, 1.4703e-14, 7.5881e-15, 3.8940e-14, 1.7524e-14,\n",
      "        1.4958e-14, 8.5889e-16, 9.9849e-15, 4.2169e-14, 1.7685e-14, 2.0465e-14,\n",
      "        3.1547e-15, 5.6848e-15, 1.5756e-14, 1.2348e-15, 7.4309e-15, 1.1928e-14,\n",
      "        1.4413e-14, 8.4305e-16, 3.9265e-14, 3.9527e-14, 1.0508e-15, 2.2655e-14,\n",
      "        1.4087e-15, 2.5254e-15, 1.1121e-14, 1.0400e-14, 3.6292e-15, 6.6930e-15,\n",
      "        2.5565e-15, 1.2673e-15, 3.6636e-14, 4.0530e-14, 1.5326e-14, 1.1630e-14,\n",
      "        2.9442e-14, 4.6836e-15, 6.6189e-16, 2.3587e-15, 6.2264e-15, 8.5201e-16,\n",
      "        7.6864e-16, 5.1801e-15, 7.1040e-16, 1.2589e-14, 1.2313e-15, 1.4205e-15,\n",
      "        2.6664e-14, 2.3357e-14, 6.2651e-16, 3.7362e-14, 2.6322e-14, 2.2295e-15,\n",
      "        1.2517e-15, 7.8988e-16, 1.4308e-15, 4.3622e-14, 1.4725e-15, 1.8484e-15,\n",
      "        2.7661e-14, 2.3885e-14, 1.2453e-14, 1.2450e-15, 2.6889e-14, 3.0923e-14,\n",
      "        1.5519e-14, 1.1813e-14, 3.1575e-14, 2.4350e-14, 2.8970e-14, 4.5011e-15,\n",
      "        5.7584e-16, 6.0974e-15, 1.0774e-14, 2.6147e-14, 2.1497e-14, 1.8029e-15,\n",
      "        2.9651e-15, 9.9822e-16, 1.1538e-14, 1.7898e-14, 7.6045e-15, 2.1935e-15,\n",
      "        1.9992e-15, 1.3455e-14, 1.7848e-15, 1.1435e-14, 2.2852e-14, 4.1560e-15,\n",
      "        2.3196e-14, 2.8180e-14, 3.4167e-14, 1.0577e-15, 1.5705e-14, 2.3504e-14,\n",
      "        6.3439e-15, 1.1402e-14, 1.5058e-14, 3.6110e-14, 8.4697e-16, 7.4400e-15,\n",
      "        2.8026e-15, 2.4792e-15, 8.0915e-16, 7.5617e-16, 2.0971e-14, 5.0120e-15,\n",
      "        3.8705e-15, 1.2024e-15, 1.4227e-14, 1.0771e-15, 1.0582e-15, 1.1688e-14,\n",
      "        4.6613e-15, 2.3321e-14, 1.1378e-14, 1.5150e-14, 1.3334e-14, 3.6368e-14,\n",
      "        1.6608e-15, 3.2141e-14, 2.3233e-14, 1.2359e-15, 3.1275e-14, 7.4128e-15,\n",
      "        2.7552e-14, 1.6824e-14, 3.5045e-14, 3.4326e-14, 1.2862e-15, 1.8039e-14,\n",
      "        3.7173e-14, 6.6504e-15, 3.3989e-14, 8.7082e-15, 1.8125e-14, 1.6784e-14,\n",
      "        1.2052e-14, 1.6296e-15, 1.0718e-15, 2.5922e-14, 1.1312e-14, 3.4367e-14,\n",
      "        1.7761e-15, 1.4353e-14, 1.3437e-14, 2.3550e-14, 3.3528e-15, 4.3043e-14,\n",
      "        3.2923e-14, 1.7317e-15, 7.6437e-15, 8.6557e-16, 2.4214e-14, 3.7780e-14,\n",
      "        8.8985e-16, 3.0153e-14, 1.0629e-15, 1.6031e-14, 1.7268e-15, 4.0576e-14,\n",
      "        3.6121e-14, 2.2461e-14, 1.1969e-15, 1.5083e-14, 6.5259e-15, 1.0565e-14,\n",
      "        4.6842e-15, 4.1180e-15, 3.4162e-14, 3.4337e-14, 4.5546e-15, 2.6128e-15,\n",
      "        2.2342e-14, 3.3148e-14, 3.3982e-15, 2.0939e-14, 3.5802e-14, 3.0142e-14,\n",
      "        1.1652e-14, 4.1932e-14, 7.5620e-15, 1.3717e-14, 1.8144e-14, 6.4195e-15,\n",
      "        7.8980e-16, 4.3127e-14, 1.9273e-15, 1.4441e-14, 3.1113e-15, 2.3020e-14,\n",
      "        2.4778e-14, 2.0437e-14, 2.6970e-15, 1.6892e-15, 3.4736e-14, 2.3797e-14,\n",
      "        9.3426e-15, 2.5088e-14, 1.4980e-14, 3.7943e-14, 1.3193e-14, 1.2121e-14,\n",
      "        2.0228e-14, 1.9134e-14, 1.5234e-15, 1.6472e-14, 2.9232e-14, 4.3142e-15,\n",
      "        4.2079e-15, 3.9087e-14, 9.0017e-16, 9.1734e-16, 1.9892e-15, 1.2770e-14,\n",
      "        3.2887e-14, 1.1968e-14, 1.1885e-15, 3.3135e-14, 1.3776e-14, 6.4024e-15,\n",
      "        2.6401e-14, 4.6957e-15, 1.5845e-14, 5.4744e-16, 1.1141e-14, 1.0288e-14,\n",
      "        2.8979e-14, 2.2397e-15, 1.0259e-14, 3.4877e-14, 8.2710e-16, 3.9033e-14,\n",
      "        1.4230e-15, 1.9903e-14, 4.3402e-15, 1.7126e-14])}, 121150448736: {'step': 800, 'exp_avg': tensor([-7.2284e-04,  4.6844e-04, -2.9287e-04,  3.3731e-04,  4.2731e-06,\n",
      "         1.8993e-04, -5.2294e-04,  1.2796e-04,  8.2939e-05,  8.0518e-04,\n",
      "        -3.0794e-04,  9.3658e-06,  4.3433e-04,  4.8906e-07, -5.8268e-04,\n",
      "         2.7584e-04, -1.5514e-04,  8.1486e-05, -7.9995e-05, -2.6323e-05,\n",
      "         7.8054e-04, -2.6279e-04, -1.0720e-04,  1.9366e-04,  4.7323e-05,\n",
      "        -3.9217e-04, -6.5465e-05,  3.6507e-04, -8.9025e-05,  2.2359e-04,\n",
      "        -1.3379e-04, -3.4139e-04,  4.2237e-04, -6.4758e-04,  3.9069e-05,\n",
      "        -4.7934e-04, -1.9008e-04,  3.8773e-04,  4.6040e-04,  4.3055e-04,\n",
      "        -6.0506e-04, -3.7225e-04, -1.8744e-04,  9.0662e-05,  7.5860e-04,\n",
      "         1.0905e-04,  2.7244e-04,  2.5423e-04, -8.4528e-04, -1.4193e-04,\n",
      "        -2.5806e-04,  3.4638e-04, -2.2125e-04, -7.0397e-04,  9.1653e-05,\n",
      "         2.2395e-04,  9.1208e-06,  2.5070e-04,  6.2917e-05,  3.3911e-04,\n",
      "         3.6363e-04,  3.4095e-04,  3.8126e-04, -2.5361e-04, -6.9043e-05,\n",
      "        -1.4705e-04,  7.8596e-04,  1.1894e-04,  1.9935e-04, -4.6305e-06,\n",
      "        -1.9213e-04,  8.1079e-05,  5.6774e-04,  2.0862e-04,  2.9192e-04,\n",
      "         3.4811e-04,  3.5505e-04,  2.9601e-04,  1.2211e-03,  2.3250e-04,\n",
      "         3.5938e-05, -3.0173e-04,  5.0404e-04,  2.1333e-05, -2.8168e-04,\n",
      "        -3.2120e-04,  5.1010e-05, -6.9187e-04,  6.7762e-05,  5.1533e-04,\n",
      "         1.6848e-04, -4.0710e-04,  1.6410e-06,  1.6193e-06,  9.9795e-05,\n",
      "         6.9853e-05, -1.8196e-04, -4.9388e-05,  5.1822e-04, -4.4019e-04,\n",
      "        -2.1898e-04,  1.7243e-05,  6.2022e-05,  4.0462e-04, -2.5660e-04,\n",
      "         8.4559e-05,  9.9337e-04,  2.3417e-04, -1.5571e-04,  3.1855e-04,\n",
      "        -2.3811e-04,  1.9841e-04,  1.0213e-04,  6.3252e-05,  2.2235e-03,\n",
      "        -4.4976e-05,  1.5252e-03,  4.5404e-04,  1.7455e-04, -1.2284e-04,\n",
      "         2.2588e-04,  7.3809e-05,  1.1240e-03, -4.7293e-05, -1.0901e-04,\n",
      "        -8.4513e-04,  3.3632e-04,  2.5051e-04,  7.5529e-05, -2.1097e-04,\n",
      "         1.2872e-03, -2.7002e-04,  9.5253e-05, -5.6378e-06,  1.1752e-04,\n",
      "        -2.4762e-04,  1.0032e-04,  3.1846e-03, -7.6147e-05,  3.8861e-05,\n",
      "        -1.6641e-05,  3.0324e-04,  2.1029e-05, -5.2707e-05,  6.0534e-05,\n",
      "         2.7536e-04,  4.1575e-04,  2.7697e-04,  2.1956e-05,  1.3776e-04,\n",
      "         6.9733e-04, -1.0196e-04, -8.3781e-04, -8.8217e-05, -1.7785e-04,\n",
      "         2.3641e-04, -4.2960e-05, -1.7676e-04,  3.9269e-04,  3.3731e-04,\n",
      "        -6.7390e-05,  1.8068e-04, -5.4264e-05, -2.9760e-05, -4.0304e-04,\n",
      "         4.0246e-04,  1.9438e-04,  6.7080e-05,  2.6924e-04, -7.6414e-05,\n",
      "         8.4969e-04,  7.1481e-04, -2.7557e-06,  5.7709e-04,  4.9516e-04,\n",
      "        -1.5460e-04,  3.6492e-04,  1.6889e-04,  6.3458e-05, -1.5860e-05,\n",
      "         3.2655e-04, -8.6508e-05, -2.1461e-04,  1.4058e-04, -4.1892e-04,\n",
      "        -4.3621e-05,  6.6543e-04, -6.1217e-05,  6.5600e-05, -6.1525e-04,\n",
      "        -2.5294e-04,  4.6709e-04, -3.4243e-04,  1.5191e-03,  1.3923e-04,\n",
      "        -4.1821e-04,  7.9098e-04,  4.4922e-04,  2.0314e-04,  9.7665e-04,\n",
      "         4.0856e-04, -1.3507e-04,  1.5415e-04,  1.6694e-04, -6.7119e-05,\n",
      "         2.0800e-04,  9.6676e-05, -2.9049e-04,  7.3612e-04,  2.0636e-04,\n",
      "         1.0505e-04,  1.1565e-04, -2.6056e-04, -1.1377e-03,  3.1613e-04,\n",
      "         5.0145e-04,  5.3740e-04,  9.8074e-05, -9.6383e-05, -1.2395e-04,\n",
      "        -5.5822e-05,  7.2148e-05,  5.1206e-05,  4.1454e-04, -5.7804e-05,\n",
      "        -6.1957e-04,  1.7145e-04, -1.4795e-04,  2.8698e-04,  1.8894e-04,\n",
      "         6.0110e-05,  6.7273e-04,  3.9824e-05,  4.6867e-04,  1.6250e-04,\n",
      "         3.5406e-04, -4.3718e-06, -1.0252e-05,  5.8670e-05, -7.9142e-05,\n",
      "         2.4379e-04,  1.3158e-04, -8.2418e-05, -6.7414e-07,  7.2736e-06,\n",
      "         2.0636e-03,  3.1134e-04, -7.5578e-04,  3.2965e-04, -2.2908e-04,\n",
      "         2.3914e-04,  3.4394e-04,  3.3898e-05,  7.1592e-05, -3.0857e-04,\n",
      "        -3.6516e-04]), 'exp_avg_sq': tensor([1.2043e-05, 2.0042e-05, 9.0900e-06, 7.4419e-06, 3.8028e-07, 1.1106e-05,\n",
      "        2.8749e-06, 1.2220e-05, 6.5756e-06, 4.3360e-05, 7.4207e-05, 1.5345e-06,\n",
      "        1.1156e-05, 1.0273e-05, 2.0758e-05, 1.8986e-05, 1.8003e-05, 6.3419e-07,\n",
      "        3.8319e-07, 1.6801e-05, 1.7764e-05, 5.6062e-06, 9.3791e-06, 1.5412e-05,\n",
      "        1.3173e-05, 1.0601e-05, 1.7205e-05, 4.4648e-06, 2.2270e-05, 6.9530e-06,\n",
      "        1.4046e-05, 1.9007e-05, 3.8814e-06, 1.4372e-05, 6.0464e-07, 4.8407e-06,\n",
      "        3.8047e-06, 7.5026e-06, 9.2951e-06, 7.8121e-06, 1.6675e-06, 2.1094e-05,\n",
      "        1.3676e-06, 2.3847e-05, 1.7001e-05, 8.9128e-06, 1.4123e-05, 5.7618e-06,\n",
      "        8.5944e-05, 3.0517e-07, 2.7948e-06, 1.1357e-05, 5.7822e-06, 1.5716e-06,\n",
      "        5.2988e-07, 1.1223e-05, 6.2052e-06, 8.3060e-06, 1.6633e-06, 6.9712e-06,\n",
      "        6.6284e-06, 1.2434e-05, 7.8199e-06, 2.3267e-05, 7.4551e-07, 1.0609e-05,\n",
      "        5.0018e-06, 1.4834e-06, 1.0975e-05, 5.4629e-06, 2.2413e-06, 1.5620e-05,\n",
      "        3.3728e-06, 1.6572e-06, 1.9317e-05, 6.3378e-06, 8.3755e-06, 3.5180e-06,\n",
      "        2.5246e-05, 1.2353e-05, 1.6118e-07, 5.5820e-06, 1.6075e-05, 2.2347e-05,\n",
      "        4.5611e-05, 1.4223e-06, 1.4138e-05, 7.9040e-06, 5.9943e-06, 9.4498e-06,\n",
      "        3.4553e-06, 8.4471e-06, 7.3591e-06, 2.1179e-05, 2.4976e-05, 1.2168e-06,\n",
      "        1.8207e-05, 3.2252e-06, 8.2579e-06, 1.5757e-06, 1.7972e-05, 1.2299e-05,\n",
      "        4.1100e-06, 6.3316e-06, 6.3314e-06, 1.2780e-05, 2.8864e-05, 3.6816e-06,\n",
      "        2.1187e-06, 8.0117e-06, 7.4985e-06, 1.8405e-05, 5.7477e-06, 7.3086e-06,\n",
      "        8.0941e-05, 1.5928e-07, 3.2098e-05, 3.8614e-05, 1.1048e-05, 1.4386e-05,\n",
      "        3.9746e-06, 1.6827e-05, 3.3032e-05, 1.9137e-05, 3.9528e-06, 7.6879e-06,\n",
      "        1.4074e-05, 1.0119e-05, 1.3002e-05, 5.2744e-06, 3.1048e-05, 2.8005e-06,\n",
      "        4.9377e-07, 6.9546e-06, 2.7815e-06, 1.2526e-06, 1.5961e-05, 1.0923e-04,\n",
      "        5.0116e-06, 1.9944e-06, 2.1560e-05, 4.9989e-06, 1.6846e-05, 1.4602e-05,\n",
      "        8.9453e-06, 2.2664e-06, 2.2894e-05, 3.4951e-05, 3.1649e-06, 8.8475e-06,\n",
      "        2.6229e-05, 2.8826e-07, 3.0074e-05, 1.8698e-05, 3.8478e-06, 2.2915e-05,\n",
      "        4.8074e-07, 1.8241e-05, 4.4466e-06, 1.2045e-05, 7.7979e-06, 1.5670e-06,\n",
      "        1.5999e-05, 1.9309e-05, 2.0871e-06, 1.5686e-05, 3.3803e-06, 9.4845e-06,\n",
      "        2.4248e-05, 9.7041e-06, 1.0206e-05, 1.1307e-05, 2.8102e-06, 2.8402e-05,\n",
      "        1.1281e-05, 4.7760e-06, 5.1933e-06, 5.8806e-06, 6.2700e-06, 1.0319e-06,\n",
      "        8.5298e-06, 6.1267e-07, 5.6343e-05, 8.0094e-06, 2.2340e-06, 3.0557e-07,\n",
      "        7.6137e-06, 1.8647e-05, 3.2755e-07, 7.5303e-06, 1.8647e-05, 2.9784e-05,\n",
      "        2.1496e-05, 3.2200e-05, 1.6962e-05, 8.5800e-06, 6.9545e-06, 1.0280e-05,\n",
      "        1.4827e-05, 3.0792e-05, 8.8848e-06, 2.4315e-06, 2.0359e-05, 6.9729e-06,\n",
      "        1.1421e-05, 1.4257e-05, 2.3838e-06, 3.4108e-06, 6.3259e-06, 6.9244e-06,\n",
      "        2.5318e-06, 6.1531e-07, 2.0073e-05, 3.9058e-06, 6.2678e-06, 8.6965e-06,\n",
      "        2.4344e-05, 2.5369e-06, 1.4083e-05, 6.9355e-06, 8.2188e-06, 2.0734e-06,\n",
      "        5.3604e-06, 5.8770e-06, 7.7610e-07, 1.8517e-06, 1.2483e-05, 1.4851e-05,\n",
      "        1.3125e-05, 6.3166e-06, 1.0878e-05, 5.4834e-06, 6.3849e-07, 4.9676e-05,\n",
      "        6.6989e-06, 5.2677e-06, 5.2267e-07, 1.4310e-06, 8.7251e-06, 1.4973e-05,\n",
      "        1.2545e-05, 8.6802e-07, 6.8485e-06, 7.9244e-07, 4.9889e-06, 5.1367e-05,\n",
      "        1.1916e-05, 3.6779e-06, 3.5850e-06, 1.6314e-06, 1.2122e-05, 6.5175e-06,\n",
      "        1.1940e-05, 1.6511e-05, 4.9601e-06, 3.7452e-06])}, 121150448816: {'step': 800, 'exp_avg': tensor([-1.2416e-05, -1.2978e-04,  2.5690e-04,  3.4437e-04, -1.9867e-07,\n",
      "         3.3175e-04, -4.5146e-05, -1.5903e-06,  3.0447e-04, -2.4181e-04,\n",
      "         1.3213e-04,  2.6462e-05,  9.5294e-05,  7.5369e-05, -2.0471e-04,\n",
      "        -3.3780e-04, -1.9070e-04,  1.2974e-04, -2.1792e-04, -7.8263e-05,\n",
      "        -6.7534e-04,  6.1054e-05, -4.9260e-05,  7.2439e-06,  9.5805e-05,\n",
      "        -8.0327e-05, -3.6235e-04,  1.2398e-04, -1.2982e-04,  1.7516e-04,\n",
      "         1.2277e-05, -2.8548e-04, -8.9752e-05,  1.9795e-04, -1.7137e-04,\n",
      "        -1.4662e-04,  4.4475e-05,  3.0242e-04,  3.0003e-04,  2.6818e-04,\n",
      "        -1.4973e-04, -2.3373e-04, -1.6766e-05,  4.9055e-04,  7.5607e-04,\n",
      "         4.0744e-04, -7.8980e-05,  5.4504e-04, -1.6145e-04,  2.4704e-05,\n",
      "         1.8652e-04,  1.6965e-04,  1.9497e-04, -3.0308e-04, -3.7526e-07,\n",
      "         4.5964e-04, -5.6324e-05,  2.6430e-04,  1.1134e-04,  5.8234e-04,\n",
      "         7.0335e-04, -3.3361e-04,  2.4511e-04, -2.4267e-04,  1.4310e-05,\n",
      "         2.1517e-04,  2.6832e-04,  9.9456e-06,  3.0976e-04,  4.2668e-05,\n",
      "        -2.0989e-05,  3.9620e-05, -2.0919e-04,  8.7635e-05,  4.4240e-04,\n",
      "        -6.5550e-05,  4.4843e-04, -5.0512e-05,  3.2532e-04, -9.5323e-05,\n",
      "        -4.0307e-05,  1.3823e-04, -1.0220e-04, -1.5223e-04, -2.1699e-04,\n",
      "         7.4930e-05, -7.4864e-05, -1.4934e-05,  3.7282e-04, -1.7616e-04,\n",
      "         9.9249e-05, -1.4261e-04,  3.1373e-04, -1.6192e-04, -3.0313e-04,\n",
      "         1.7464e-05,  1.4855e-04,  1.7978e-04, -4.1247e-04,  8.2572e-05,\n",
      "        -8.1371e-05, -3.1848e-04, -1.2973e-04,  1.1586e-04, -3.4340e-04,\n",
      "         3.5164e-04, -1.8169e-04,  1.2749e-04,  1.5036e-04,  3.8737e-04,\n",
      "         5.0077e-05, -1.5090e-04,  3.6022e-04, -2.6658e-04,  9.7556e-04,\n",
      "        -4.9392e-05,  7.1064e-04,  4.0902e-04,  2.8866e-04,  5.6634e-05,\n",
      "         1.6133e-04,  1.5308e-04, -8.0996e-04,  1.8998e-04, -2.0674e-04,\n",
      "        -7.5836e-04,  2.9421e-04, -1.0299e-04, -1.8546e-04,  6.9307e-05,\n",
      "         2.1424e-04, -1.4713e-05,  1.9396e-05,  2.8300e-04, -6.5805e-06,\n",
      "        -1.8618e-04, -2.5224e-04,  1.3135e-03,  4.3809e-05,  8.8632e-05,\n",
      "         1.2983e-04, -7.9595e-05, -2.5694e-04, -1.8491e-04, -9.1874e-05,\n",
      "         3.0135e-05,  4.2338e-04,  2.2245e-04,  1.2149e-04,  3.8576e-04,\n",
      "        -1.8791e-04, -1.5631e-05, -3.9659e-04,  1.3911e-04, -1.8443e-04,\n",
      "        -6.2912e-05, -8.7060e-06,  2.8385e-06,  3.3631e-04, -4.8651e-04,\n",
      "        -2.4455e-04,  2.1487e-04,  4.3679e-04, -4.3445e-04, -1.8136e-04,\n",
      "         5.4871e-04,  1.7904e-05,  3.6100e-04,  1.5401e-04, -2.1950e-04,\n",
      "        -6.5045e-04, -1.2262e-05, -1.6737e-04,  9.7373e-04,  1.5597e-04,\n",
      "        -4.8297e-05,  4.5397e-04,  2.0023e-04,  9.0340e-05,  1.0921e-04,\n",
      "         4.8058e-04,  1.2183e-04, -2.3560e-04,  2.4935e-04, -2.7992e-04,\n",
      "        -8.9849e-06, -1.6208e-05, -4.2962e-04,  3.0044e-05, -1.3866e-04,\n",
      "        -2.6684e-04,  4.5090e-04, -1.3735e-04,  5.2625e-04, -2.1906e-04,\n",
      "        -7.1747e-08,  7.5745e-04,  3.5141e-04, -1.9217e-04, -6.2770e-04,\n",
      "         5.0670e-04, -1.1797e-04, -1.7852e-04, -3.6331e-06, -2.8591e-04,\n",
      "         5.3474e-04, -6.3135e-05, -7.7944e-05,  1.5625e-05, -2.8782e-05,\n",
      "         7.2157e-05,  1.0356e-04, -8.2599e-06, -5.6542e-04,  4.8898e-04,\n",
      "         4.6076e-04, -3.7968e-04, -3.7202e-05, -3.4829e-04,  3.5214e-04,\n",
      "         3.0536e-05, -6.2542e-05,  2.6891e-04,  1.8129e-04, -4.6847e-05,\n",
      "        -3.0578e-04,  4.7732e-04, -6.1948e-05,  5.2346e-04,  2.6099e-04,\n",
      "         3.9758e-04, -3.1828e-04,  8.5525e-05, -2.8832e-04,  4.0915e-04,\n",
      "         1.9063e-04, -7.4083e-05, -4.9897e-05,  4.1854e-04, -4.2484e-04,\n",
      "        -7.5864e-05,  1.4723e-04, -7.0979e-05,  2.4501e-04,  2.7497e-04,\n",
      "         4.3260e-04, -1.8854e-05, -4.2274e-04,  1.1421e-04, -4.9614e-06,\n",
      "         2.6942e-04,  4.8830e-04, -1.8113e-04, -1.8009e-04, -3.8992e-04,\n",
      "        -1.1143e-04]), 'exp_avg_sq': tensor([3.7032e-06, 4.9476e-06, 5.7321e-06, 2.9850e-06, 6.5454e-07, 7.2843e-06,\n",
      "        2.7703e-06, 2.1289e-06, 3.5186e-06, 9.0825e-06, 1.7108e-05, 2.1634e-06,\n",
      "        5.6475e-06, 3.3049e-06, 8.1901e-06, 5.3944e-06, 4.7334e-06, 1.3571e-06,\n",
      "        8.3144e-07, 2.3237e-06, 8.0544e-06, 6.5870e-06, 5.6785e-06, 2.4403e-06,\n",
      "        3.3560e-06, 2.5402e-06, 3.8080e-06, 3.3132e-06, 7.1345e-06, 2.3267e-06,\n",
      "        3.9407e-06, 9.5975e-06, 2.4136e-06, 1.3541e-05, 1.0729e-06, 6.3561e-06,\n",
      "        3.1038e-06, 6.4313e-06, 4.9378e-06, 4.6916e-06, 2.8351e-06, 9.3000e-06,\n",
      "        2.2282e-06, 1.2816e-05, 1.8377e-05, 7.5030e-06, 2.0636e-06, 5.6775e-06,\n",
      "        2.3948e-05, 7.2941e-07, 2.9333e-06, 2.5423e-06, 6.6015e-06, 2.5532e-06,\n",
      "        1.0721e-06, 8.6290e-06, 1.3083e-06, 6.9213e-06, 1.8739e-06, 7.1083e-06,\n",
      "        2.6263e-06, 5.2894e-06, 4.5805e-06, 1.2487e-05, 1.3664e-06, 7.3498e-06,\n",
      "        2.2487e-06, 2.1578e-06, 4.3467e-06, 2.7924e-06, 2.6867e-06, 4.4350e-06,\n",
      "        2.3920e-06, 1.7775e-06, 1.2713e-05, 2.8760e-06, 7.9071e-06, 1.8574e-06,\n",
      "        4.5197e-06, 2.2760e-06, 3.4022e-07, 5.9549e-06, 3.9985e-06, 6.8038e-06,\n",
      "        1.4073e-05, 1.9631e-06, 1.9537e-06, 4.8864e-06, 3.8435e-06, 3.3524e-06,\n",
      "        1.5755e-06, 2.7673e-06, 6.2878e-06, 6.4125e-06, 6.0420e-06, 8.2726e-07,\n",
      "        6.6967e-06, 2.9156e-06, 4.5404e-06, 2.3525e-06, 4.1890e-06, 3.0849e-06,\n",
      "        1.0822e-06, 3.2835e-06, 4.4539e-06, 7.0622e-06, 8.0120e-06, 2.7092e-06,\n",
      "        3.1801e-06, 7.1621e-06, 8.4274e-06, 2.8703e-06, 6.5875e-06, 5.5828e-06,\n",
      "        1.9862e-05, 3.2390e-07, 9.0802e-06, 8.0922e-06, 9.0239e-06, 4.1611e-06,\n",
      "        3.1370e-06, 8.5064e-06, 1.1807e-05, 6.2296e-06, 1.4502e-06, 1.1137e-05,\n",
      "        4.4250e-06, 1.9290e-06, 2.1637e-06, 5.1357e-06, 8.6033e-06, 1.3970e-06,\n",
      "        8.7090e-07, 8.5330e-06, 2.1667e-06, 2.2803e-06, 4.1279e-06, 2.3252e-05,\n",
      "        5.8183e-06, 1.7876e-06, 6.6371e-06, 1.4763e-06, 3.0290e-06, 3.8717e-06,\n",
      "        1.8892e-06, 2.3243e-06, 9.4266e-06, 1.5393e-05, 3.8582e-06, 8.1621e-06,\n",
      "        6.2251e-06, 7.2650e-07, 8.8087e-06, 5.0577e-06, 1.3771e-06, 4.6052e-06,\n",
      "        1.0539e-06, 1.0087e-05, 5.4905e-06, 5.5772e-06, 3.7994e-06, 1.4968e-06,\n",
      "        1.1692e-05, 4.0799e-06, 2.7810e-06, 1.1668e-05, 2.0688e-06, 7.1244e-06,\n",
      "        6.0053e-06, 5.1534e-06, 5.4154e-06, 3.5378e-06, 2.5573e-06, 1.8857e-05,\n",
      "        2.5670e-06, 8.7366e-07, 5.5208e-06, 2.4741e-06, 1.0784e-06, 2.0632e-06,\n",
      "        9.1256e-06, 1.0976e-06, 1.6429e-05, 3.9331e-06, 3.1488e-06, 6.1074e-07,\n",
      "        2.2753e-06, 3.8675e-06, 6.4043e-07, 9.4090e-06, 1.0233e-05, 1.2961e-05,\n",
      "        1.4249e-05, 7.8467e-06, 4.6585e-06, 4.2470e-06, 2.5995e-06, 6.4592e-06,\n",
      "        2.7278e-06, 1.0460e-05, 9.2010e-06, 2.0913e-06, 4.1721e-06, 2.4286e-06,\n",
      "        3.9535e-06, 1.0636e-05, 2.9448e-06, 4.4375e-06, 2.6788e-06, 3.9646e-06,\n",
      "        3.2411e-06, 1.1046e-06, 1.1219e-05, 4.4938e-06, 6.2325e-06, 9.9241e-06,\n",
      "        7.5223e-06, 3.3221e-06, 6.2126e-06, 4.3739e-06, 4.9572e-06, 1.4225e-06,\n",
      "        5.3018e-06, 1.6280e-06, 1.7039e-06, 2.7459e-06, 1.1291e-05, 5.2286e-06,\n",
      "        1.0910e-05, 4.7542e-06, 8.3125e-06, 2.7719e-06, 9.3485e-07, 1.2628e-05,\n",
      "        5.5215e-06, 4.1396e-06, 9.4630e-07, 2.7571e-06, 4.6070e-06, 4.6317e-06,\n",
      "        1.7754e-06, 1.2990e-06, 5.4905e-06, 1.0561e-06, 7.3300e-06, 1.3426e-05,\n",
      "        2.6934e-06, 4.3127e-06, 2.6105e-06, 2.3885e-06, 1.0650e-05, 4.1865e-06,\n",
      "        3.0499e-06, 2.7862e-06, 6.2245e-06, 4.7073e-06])}, 121150449136: {'step': 800, 'exp_avg': tensor([[[-8.4832e-05, -3.7500e-05, -4.4164e-05],\n",
      "         [ 2.6261e-05,  1.5853e-05, -8.7243e-06],\n",
      "         [-5.1002e-05, -2.4163e-05, -2.9582e-05],\n",
      "         ...,\n",
      "         [ 3.6036e-05,  1.3545e-05,  1.6089e-06],\n",
      "         [ 1.5497e-05,  7.3633e-06,  1.6661e-05],\n",
      "         [ 6.6738e-06, -1.6513e-05, -4.2521e-06]],\n",
      "\n",
      "        [[ 2.6731e-05,  7.0489e-07,  2.3092e-05],\n",
      "         [-4.1312e-05,  1.4695e-05, -3.8682e-06],\n",
      "         [ 2.5350e-05, -2.1263e-05,  8.0956e-06],\n",
      "         ...,\n",
      "         [-2.6831e-05, -2.0768e-05, -2.3092e-05],\n",
      "         [ 2.1143e-05,  1.9498e-05,  4.2159e-06],\n",
      "         [-1.9830e-06, -1.2885e-05, -4.7824e-05]],\n",
      "\n",
      "        [[-3.2811e-06,  1.3842e-06,  1.0514e-05],\n",
      "         [ 4.6617e-07,  8.5207e-07, -1.5256e-06],\n",
      "         [-1.6840e-06,  6.8329e-06,  7.8187e-06],\n",
      "         ...,\n",
      "         [-1.3719e-06, -4.6017e-07, -1.3350e-06],\n",
      "         [ 4.3082e-06, -5.2861e-07, -3.8679e-06],\n",
      "         [-6.9489e-07, -3.8878e-06, -5.0743e-06]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9952e-06,  1.1309e-05,  2.3652e-05],\n",
      "         [ 3.0815e-05,  3.2867e-05,  2.5444e-05],\n",
      "         [-1.7706e-06,  9.3173e-06,  1.5990e-05],\n",
      "         ...,\n",
      "         [ 2.1928e-05,  2.7219e-05,  1.6612e-05],\n",
      "         [-2.1302e-05, -3.2139e-05, -3.6578e-05],\n",
      "         [-1.6680e-05, -2.2026e-05, -2.3101e-05]],\n",
      "\n",
      "        [[-1.4080e-04, -2.2961e-05, -2.1755e-05],\n",
      "         [ 3.1932e-05,  1.7757e-05, -1.6200e-05],\n",
      "         [-8.6376e-05, -4.7870e-05, -1.5292e-05],\n",
      "         ...,\n",
      "         [ 8.3533e-06,  1.1896e-05,  6.5736e-08],\n",
      "         [-2.2851e-05, -1.9250e-05, -8.7307e-06],\n",
      "         [-1.4779e-05, -3.5693e-05, -4.6350e-05]],\n",
      "\n",
      "        [[ 3.6118e-06,  2.2898e-08,  2.2437e-05],\n",
      "         [ 1.6858e-05,  1.9557e-05, -4.3248e-06],\n",
      "         [ 9.7505e-06, -4.5900e-06,  2.0923e-05],\n",
      "         ...,\n",
      "         [ 1.6290e-06,  1.7253e-06, -1.4539e-06],\n",
      "         [-6.9086e-06, -8.9011e-06, -3.8993e-06],\n",
      "         [-3.1907e-06, -1.0996e-05, -6.0729e-06]]]), 'exp_avg_sq': tensor([[[5.3368e-08, 5.0287e-08, 2.0267e-08],\n",
      "         [6.6895e-08, 7.7071e-08, 7.1069e-08],\n",
      "         [1.4675e-08, 1.2807e-08, 1.1226e-08],\n",
      "         ...,\n",
      "         [8.1943e-08, 9.1935e-08, 8.2167e-08],\n",
      "         [3.3846e-08, 3.7984e-08, 2.8088e-08],\n",
      "         [2.0996e-08, 2.1280e-08, 1.8897e-08]],\n",
      "\n",
      "        [[4.3009e-08, 5.5281e-08, 5.5458e-08],\n",
      "         [6.2243e-08, 5.2857e-08, 5.8306e-08],\n",
      "         [1.9258e-08, 2.7445e-08, 2.2317e-08],\n",
      "         ...,\n",
      "         [6.0670e-08, 5.1165e-08, 6.0122e-08],\n",
      "         [5.6227e-08, 4.0187e-08, 5.1777e-08],\n",
      "         [1.2294e-08, 1.2242e-08, 1.2339e-08]],\n",
      "\n",
      "        [[6.8973e-08, 8.6075e-08, 3.5835e-08],\n",
      "         [1.2977e-07, 8.9208e-08, 5.7397e-08],\n",
      "         [1.5545e-08, 1.9710e-08, 1.4308e-08],\n",
      "         ...,\n",
      "         [1.2983e-07, 7.6968e-08, 6.9139e-08],\n",
      "         [1.6838e-08, 1.1249e-08, 1.3686e-08],\n",
      "         [2.7387e-08, 1.4229e-08, 1.2928e-08]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.8083e-08, 4.3968e-08, 2.4738e-08],\n",
      "         [8.8548e-09, 1.5398e-08, 1.5085e-08],\n",
      "         [7.6852e-09, 1.4949e-08, 1.1686e-08],\n",
      "         ...,\n",
      "         [1.9790e-08, 2.8844e-08, 1.6440e-08],\n",
      "         [1.0166e-08, 9.4093e-09, 1.3438e-08],\n",
      "         [2.2206e-09, 7.1027e-09, 5.2501e-09]],\n",
      "\n",
      "        [[8.3110e-08, 1.5717e-07, 1.0578e-07],\n",
      "         [1.3007e-07, 1.3372e-07, 7.8502e-08],\n",
      "         [1.9005e-08, 2.7753e-08, 3.3602e-08],\n",
      "         ...,\n",
      "         [1.6219e-07, 1.3125e-07, 8.5273e-08],\n",
      "         [1.7389e-07, 1.6233e-07, 1.6394e-07],\n",
      "         [4.5458e-08, 2.8153e-08, 1.6308e-08]],\n",
      "\n",
      "        [[1.9663e-08, 2.7696e-08, 2.0577e-08],\n",
      "         [2.3017e-08, 1.7356e-08, 1.1316e-08],\n",
      "         [4.8252e-09, 1.0618e-08, 1.0125e-08],\n",
      "         ...,\n",
      "         [4.1682e-08, 1.6873e-08, 9.1379e-09],\n",
      "         [1.1872e-08, 1.3052e-08, 7.8409e-09],\n",
      "         [6.4498e-09, 1.0407e-08, 1.4692e-08]]])}, 121150449216: {'step': 800, 'exp_avg': tensor([-4.3513e-11,  6.1724e-11, -1.9567e-11,  7.2719e-11, -3.0264e-11,\n",
      "        -2.3126e-12,  5.9879e-11, -1.3986e-10,  6.7655e-11, -7.9920e-11,\n",
      "         1.1592e-11,  6.8985e-11, -1.2570e-10,  7.6291e-12,  5.2181e-11,\n",
      "         7.6126e-12,  6.3032e-11, -1.6143e-10, -4.7792e-11, -2.1586e-10,\n",
      "        -6.1133e-12, -6.0154e-12, -6.7599e-11,  1.0447e-10,  8.2178e-12,\n",
      "        -2.2075e-11,  1.3630e-11, -1.0832e-10,  1.1863e-10, -3.3300e-11,\n",
      "        -8.9936e-11,  1.4033e-10, -3.7008e-11,  2.0451e-10, -1.6009e-10,\n",
      "         4.1081e-12,  8.0144e-12,  5.5246e-11, -2.4892e-12,  2.9496e-12,\n",
      "         8.1247e-12, -7.4639e-11, -3.5537e-11,  5.6667e-11, -1.7095e-11,\n",
      "         1.9019e-10, -1.3381e-11,  2.6944e-12,  8.2620e-11, -6.1521e-11,\n",
      "        -1.8045e-11, -7.5881e-12,  5.3886e-11,  2.2656e-11,  4.3689e-11,\n",
      "         1.7103e-10,  1.3352e-10,  1.0598e-11, -3.1155e-11, -9.0341e-13,\n",
      "         6.1947e-12,  1.1071e-10,  5.5179e-11, -3.8708e-11,  9.9780e-11,\n",
      "        -1.6132e-13,  1.5497e-10, -1.1665e-10,  4.7104e-11,  3.0924e-11,\n",
      "         4.3329e-11,  9.1351e-11,  1.0707e-11, -8.3095e-11,  2.3445e-11,\n",
      "         6.5179e-11, -1.5796e-10,  3.1309e-11, -2.4308e-11, -1.5783e-12,\n",
      "        -1.7007e-10,  7.3261e-11, -1.0669e-10,  3.5639e-11, -3.8543e-11,\n",
      "         1.3572e-11, -3.1917e-11,  8.9779e-12, -1.4210e-10, -9.4374e-11,\n",
      "        -4.4758e-11, -2.6759e-11, -2.4197e-11, -3.4762e-11, -4.0125e-11,\n",
      "        -1.9842e-10, -3.3551e-11,  6.8984e-11, -2.8189e-11, -1.0515e-10,\n",
      "         3.2435e-10,  9.0141e-11, -4.4005e-11, -1.5389e-11,  2.6654e-11,\n",
      "        -1.3005e-12, -2.7881e-10, -1.4684e-10,  1.0437e-10,  2.4035e-11,\n",
      "        -1.1713e-10,  5.1170e-11,  2.2495e-11, -6.7382e-11,  2.1115e-10,\n",
      "         4.0709e-11, -1.2763e-11,  4.5471e-11,  2.3630e-10, -5.3226e-11,\n",
      "         9.7090e-12,  9.5428e-12,  1.1001e-12,  2.6261e-12, -4.5618e-11,\n",
      "        -2.8321e-11,  6.8593e-12,  2.9085e-11, -3.4876e-11, -2.6386e-11,\n",
      "         8.0407e-11, -3.0888e-11,  1.5366e-10,  2.3464e-11, -5.4982e-12,\n",
      "        -2.0989e-12,  3.7421e-10, -2.3936e-10, -5.4376e-11,  1.6878e-11,\n",
      "         7.8934e-12,  2.3323e-11, -2.6633e-11, -1.3144e-11, -1.5695e-10,\n",
      "         2.7725e-11, -1.0716e-10, -4.5193e-11, -8.2057e-12,  2.3235e-11,\n",
      "        -3.1496e-12, -8.4612e-11, -6.3178e-11,  3.9833e-11,  9.1321e-11,\n",
      "         2.8130e-11, -1.1245e-11, -4.7963e-11,  2.8854e-11, -2.7408e-11,\n",
      "        -6.2262e-11, -1.5347e-11,  4.9741e-11,  1.0331e-10, -2.0660e-13,\n",
      "         5.2329e-11, -5.3678e-11,  2.0700e-10,  2.8917e-12, -3.9189e-11,\n",
      "        -8.6898e-11, -6.4358e-11,  1.9264e-10, -4.8637e-11,  1.1098e-10,\n",
      "         4.4320e-11, -6.4232e-11, -2.6114e-12, -2.7722e-12,  1.1415e-11,\n",
      "         1.1845e-10,  8.8818e-12, -2.2047e-10, -1.0784e-11, -5.8915e-12,\n",
      "         1.2655e-10,  1.7435e-11,  7.8957e-11,  5.3632e-11, -2.3192e-11,\n",
      "        -3.5461e-10, -6.1086e-11, -4.3257e-11, -1.0458e-10, -2.1508e-10,\n",
      "        -8.1205e-11,  6.4045e-11, -1.1086e-10,  9.4508e-11, -1.0162e-10,\n",
      "        -1.4794e-10,  7.5406e-11,  2.4644e-10,  3.5157e-13, -5.1925e-11,\n",
      "        -6.8667e-11,  5.6908e-11, -2.7985e-11,  2.6554e-12, -3.0057e-11,\n",
      "         1.6455e-10,  8.2325e-11, -5.3132e-11, -7.9470e-11,  3.2907e-11,\n",
      "         2.7495e-11, -2.1381e-11,  1.7898e-12, -6.7429e-10,  1.4919e-11,\n",
      "        -6.1980e-11,  4.9518e-11, -7.8107e-12,  1.0926e-12,  2.9639e-12,\n",
      "         1.0729e-11,  7.9366e-11, -5.7866e-11,  1.0799e-10,  1.0920e-11,\n",
      "        -1.9645e-10,  9.8443e-11, -5.1747e-11, -7.2508e-11, -1.5755e-10,\n",
      "        -2.2554e-10,  1.7303e-11, -4.0950e-12, -6.4337e-11, -7.5991e-11,\n",
      "        -9.3361e-11,  1.2330e-10,  6.3409e-11,  1.3680e-10, -8.2469e-11,\n",
      "         1.8192e-11,  7.7176e-11,  1.0011e-11,  3.8492e-11,  1.3064e-10,\n",
      "         2.0113e-11, -8.7196e-11, -5.6479e-12, -6.3159e-11, -3.9175e-11,\n",
      "         3.0934e-11,  1.7013e-10,  4.4743e-11, -4.4542e-11,  8.5188e-11,\n",
      "         2.2380e-11,  7.9102e-11,  1.4554e-12,  1.6475e-10, -9.3658e-11,\n",
      "         1.2563e-10, -1.1242e-10, -3.3512e-13,  1.5247e-11,  3.6390e-11,\n",
      "        -1.0103e-10, -5.9232e-12,  4.6760e-12, -3.8072e-10, -1.1897e-10,\n",
      "         8.9223e-11,  3.4706e-11, -4.6488e-11,  1.2454e-10,  4.6241e-10,\n",
      "         2.1077e-11, -4.0494e-12,  1.6093e-12, -2.5695e-11, -1.0910e-11,\n",
      "         4.4061e-11, -9.9770e-11,  3.1609e-11,  1.6481e-11, -7.0582e-12,\n",
      "         6.0236e-11, -6.7047e-11,  6.5029e-11, -1.9445e-11, -1.2996e-10,\n",
      "         1.8914e-11,  2.9607e-11,  5.6353e-11, -1.1010e-10,  2.3583e-10,\n",
      "         4.6056e-11,  2.1233e-11, -7.5242e-11,  5.7834e-11,  4.7566e-11,\n",
      "         4.8983e-11,  7.7264e-12,  7.2226e-11,  4.4652e-10, -7.6449e-11,\n",
      "         3.0099e-12,  5.0469e-11, -2.9801e-11, -7.1472e-11, -3.9880e-12,\n",
      "        -1.2894e-10,  5.4343e-12,  9.9391e-13, -2.0441e-11,  4.2896e-11,\n",
      "         1.5928e-11, -5.0957e-12,  1.3670e-11,  3.2145e-10,  1.3485e-10,\n",
      "         3.6522e-13,  1.0125e-11, -3.5287e-11,  2.1779e-12, -8.0989e-12,\n",
      "        -1.7807e-11, -5.9299e-11,  3.7431e-11, -1.3822e-11, -5.8829e-11,\n",
      "         5.4495e-12, -1.7848e-11, -1.7952e-10,  2.5491e-11, -8.8879e-12,\n",
      "         4.5977e-11,  1.7488e-11,  2.0313e-11,  2.7529e-10,  1.4784e-11,\n",
      "        -1.4595e-10, -4.2787e-12,  3.7013e-11, -2.7874e-10,  1.1495e-11,\n",
      "        -9.6259e-14, -1.2452e-11,  6.6815e-11,  4.1030e-12,  7.2905e-11,\n",
      "        -4.4769e-11, -1.3931e-10,  4.9325e-11,  7.9765e-11, -1.5587e-10,\n",
      "         3.9139e-11, -7.7364e-11,  9.2239e-11,  5.4068e-11,  1.5438e-11,\n",
      "        -1.0352e-10,  1.4334e-11, -2.3889e-12,  3.3421e-12,  9.3080e-11,\n",
      "         3.4220e-12, -2.2641e-11, -2.0898e-11,  1.6716e-11,  3.4513e-13,\n",
      "         1.0530e-11, -7.2321e-11,  1.8384e-11, -1.8496e-11, -2.5309e-10,\n",
      "         3.4281e-11,  6.6316e-11, -1.1937e-10,  3.1093e-11, -3.6849e-12,\n",
      "        -8.3655e-11,  1.3642e-11, -4.9766e-11, -6.8791e-11,  2.1817e-11,\n",
      "         7.7664e-11, -5.0659e-11, -8.8212e-11, -5.6414e-11,  3.9063e-11,\n",
      "         9.4108e-11, -5.1552e-11,  1.5108e-10, -1.9240e-12, -7.2704e-11,\n",
      "        -3.0259e-11,  1.0679e-11,  6.3519e-11, -2.4539e-10, -4.5233e-12,\n",
      "        -1.0519e-10, -4.0412e-11, -7.6425e-11, -3.6405e-14, -4.6077e-11,\n",
      "         2.2610e-10, -1.4842e-11, -2.6082e-13,  3.9135e-11, -2.1017e-11,\n",
      "        -5.4197e-11, -1.3942e-14,  3.0590e-12,  7.7538e-12,  7.6553e-12,\n",
      "         8.2969e-12, -1.0399e-10, -1.8811e-11, -1.9958e-11, -1.3467e-11,\n",
      "         1.6659e-10, -6.4915e-11, -1.0289e-10,  1.6233e-11, -6.2704e-11,\n",
      "        -1.8085e-11,  1.7929e-11,  2.6163e-12,  7.3784e-11, -1.8285e-10,\n",
      "         4.3776e-11, -3.8899e-12, -2.6250e-12,  2.4486e-11,  5.0235e-12,\n",
      "        -1.0224e-10,  1.2081e-11, -5.3671e-11,  3.6434e-11, -1.8249e-10,\n",
      "        -6.6770e-12,  3.3789e-11,  4.4282e-11, -1.6969e-11,  2.3358e-11,\n",
      "        -4.2613e-11,  1.0035e-10,  5.6389e-11, -1.9595e-11, -2.9275e-11,\n",
      "        -2.2831e-12, -2.8135e-11,  2.4299e-11, -2.3182e-10, -1.4586e-10,\n",
      "         1.3395e-10,  4.3575e-11,  3.6092e-11, -1.1708e-10, -3.8404e-12,\n",
      "        -1.5980e-11,  1.8247e-10, -1.8444e-11,  9.5797e-11,  3.8194e-11,\n",
      "         1.4647e-10,  7.2798e-11,  5.1702e-11,  2.5113e-11,  4.1867e-11,\n",
      "        -2.1370e-10, -1.2345e-10,  2.0539e-11, -5.6453e-11, -2.0407e-11,\n",
      "        -2.2521e-10, -3.5712e-11,  9.3582e-11, -4.6318e-12, -9.2629e-11,\n",
      "        -6.3534e-12, -5.5005e-13,  7.6458e-11, -1.1334e-11, -1.0051e-11,\n",
      "         4.0349e-11,  8.5386e-12, -6.0033e-12, -2.1366e-11, -5.0508e-11,\n",
      "         1.5584e-11,  4.1305e-12, -4.8221e-13,  2.1771e-11, -3.1584e-11,\n",
      "        -1.0131e-10, -2.6211e-10, -9.0690e-11,  1.3769e-11,  2.2624e-12,\n",
      "        -1.3477e-10, -1.3217e-11,  1.7118e-10,  7.3655e-11, -1.1855e-11,\n",
      "         6.4690e-11, -1.2784e-11]), 'exp_avg_sq': tensor([3.3256e-15, 7.7495e-16, 7.5027e-15, 8.3880e-15, 7.1345e-15, 6.8130e-16,\n",
      "        1.9130e-15, 8.8205e-16, 1.5451e-14, 5.3432e-15, 5.5757e-15, 2.3406e-15,\n",
      "        8.6704e-15, 7.3218e-15, 9.8915e-16, 1.3846e-15, 1.8330e-14, 2.4771e-15,\n",
      "        6.1334e-15, 5.4237e-15, 4.0740e-16, 4.9346e-15, 1.9422e-14, 2.0827e-15,\n",
      "        8.4409e-16, 2.0023e-14, 8.7904e-16, 1.4821e-14, 1.0466e-14, 1.8616e-15,\n",
      "        9.2319e-16, 6.1559e-15, 9.2891e-15, 1.5748e-14, 2.0597e-15, 1.5621e-14,\n",
      "        6.0597e-16, 6.7015e-16, 9.7478e-15, 1.4844e-14, 8.2178e-16, 3.7823e-15,\n",
      "        6.8096e-16, 7.8860e-15, 1.3299e-14, 5.1443e-15, 9.2756e-15, 7.2151e-15,\n",
      "        6.2577e-15, 1.3469e-14, 1.6073e-14, 6.6017e-16, 1.8977e-15, 1.1704e-14,\n",
      "        1.4047e-14, 1.7609e-15, 6.9611e-16, 1.7052e-14, 6.6922e-16, 7.3454e-15,\n",
      "        2.3052e-15, 6.9000e-16, 1.5652e-14, 7.6253e-15, 3.1049e-15, 7.6746e-15,\n",
      "        1.4542e-14, 4.6060e-15, 8.8856e-16, 3.5455e-15, 9.8425e-16, 6.8059e-16,\n",
      "        3.8607e-15, 8.1413e-15, 1.9003e-14, 7.4725e-16, 5.8902e-15, 1.5721e-15,\n",
      "        8.3456e-15, 1.0440e-15, 5.2486e-15, 7.8640e-16, 1.8521e-14, 7.1671e-15,\n",
      "        1.6491e-14, 1.2698e-14, 3.7889e-15, 9.0613e-15, 1.4364e-14, 1.3347e-14,\n",
      "        1.3960e-14, 1.1053e-15, 3.5157e-15, 1.8231e-14, 4.4279e-15, 1.9115e-14,\n",
      "        7.0685e-15, 2.0757e-15, 5.9992e-15, 1.8373e-14, 1.1608e-14, 1.1647e-14,\n",
      "        9.7059e-16, 5.2424e-15, 7.3654e-15, 4.4455e-15, 1.0589e-14, 3.7705e-15,\n",
      "        8.9553e-15, 7.8595e-16, 2.0106e-14, 3.9632e-15, 1.2777e-14, 1.3041e-15,\n",
      "        6.3255e-15, 1.2422e-15, 9.6840e-16, 8.1657e-16, 9.3841e-15, 9.5231e-16,\n",
      "        2.9888e-15, 7.9473e-15, 1.9341e-15, 2.7543e-15, 7.3152e-16, 9.6588e-15,\n",
      "        1.2153e-14, 7.7948e-15, 7.8515e-16, 8.9246e-15, 1.1663e-14, 1.5594e-15,\n",
      "        4.9687e-15, 1.0773e-14, 1.2548e-15, 2.0210e-15, 1.7018e-14, 1.6548e-14,\n",
      "        9.0570e-16, 8.4868e-16, 7.3848e-16, 1.2525e-15, 1.5676e-14, 2.4016e-15,\n",
      "        1.9274e-14, 1.6947e-14, 2.4960e-15, 7.7861e-15, 7.9318e-16, 1.0327e-15,\n",
      "        6.7483e-16, 7.9532e-16, 2.3797e-15, 2.4696e-15, 7.9248e-15, 4.2339e-15,\n",
      "        3.6008e-15, 1.2636e-15, 1.5796e-14, 1.2657e-15, 4.0641e-15, 1.5026e-14,\n",
      "        9.3329e-15, 1.7319e-14, 9.1368e-15, 1.2152e-15, 3.9181e-15, 1.1462e-14,\n",
      "        1.1797e-14, 2.5085e-15, 1.5244e-14, 3.2919e-15, 1.1784e-14, 7.6108e-15,\n",
      "        9.4768e-16, 6.4634e-15, 6.3920e-15, 9.7765e-15, 9.7170e-16, 9.6087e-15,\n",
      "        1.3867e-14, 7.0415e-16, 1.1642e-15, 7.2186e-16, 7.3873e-16, 1.0016e-14,\n",
      "        6.2225e-15, 7.0968e-15, 2.6125e-15, 8.0198e-15, 3.1995e-15, 6.1625e-15,\n",
      "        1.2251e-15, 8.0338e-15, 9.2190e-15, 1.0779e-15, 7.3950e-16, 1.3940e-15,\n",
      "        3.7471e-15, 1.2105e-15, 6.7190e-15, 1.2651e-15, 2.9879e-15, 5.0921e-15,\n",
      "        6.1269e-15, 1.1171e-14, 9.6273e-15, 6.6117e-16, 2.7205e-15, 6.6606e-16,\n",
      "        1.1371e-14, 8.6987e-16, 1.1400e-14, 1.8265e-14, 1.0161e-14, 1.0599e-15,\n",
      "        1.1360e-14, 8.4014e-15, 1.0451e-14, 6.7105e-16, 4.2163e-15, 1.1818e-15,\n",
      "        8.1074e-16, 1.2570e-15, 8.7704e-15, 2.5522e-15, 5.0542e-15, 1.5768e-14,\n",
      "        7.2373e-16, 1.0046e-15, 1.8443e-14, 9.2952e-15, 7.4982e-15, 2.1591e-15,\n",
      "        1.4064e-14, 2.8166e-15, 8.0792e-16, 9.5319e-15, 4.6622e-15, 5.0590e-15,\n",
      "        6.0444e-15, 1.6108e-14, 3.8914e-15, 6.7957e-16, 5.6664e-15, 8.4249e-16,\n",
      "        1.6468e-15, 1.6574e-14, 8.9526e-15, 2.5294e-15, 6.7473e-15, 6.9819e-16,\n",
      "        1.0956e-14, 5.2496e-15, 2.0186e-14, 7.3202e-16, 1.6356e-15, 2.1945e-15,\n",
      "        6.7430e-16, 3.2731e-15, 9.5126e-15, 4.5176e-15, 7.6847e-15, 6.1285e-15,\n",
      "        1.0807e-14, 3.7331e-15, 1.9404e-15, 1.6336e-14, 1.2372e-15, 8.5680e-15,\n",
      "        3.9459e-15, 5.8103e-15, 1.4187e-14, 5.1501e-15, 1.9653e-14, 1.0774e-15,\n",
      "        8.9111e-15, 1.3698e-14, 2.0150e-14, 1.1520e-14, 1.8812e-14, 1.0727e-15,\n",
      "        6.0374e-15, 3.0687e-15, 5.8518e-15, 7.4617e-16, 1.8289e-14, 2.3871e-15,\n",
      "        7.6805e-16, 1.3048e-14, 8.0614e-15, 1.2293e-14, 8.0882e-15, 1.6103e-14,\n",
      "        1.5691e-14, 1.4783e-14, 2.0048e-14, 6.8292e-16, 4.0414e-15, 1.7308e-15,\n",
      "        8.9423e-16, 6.6934e-16, 2.8253e-15, 9.0488e-15, 7.0123e-15, 1.8104e-15,\n",
      "        1.7125e-14, 6.1865e-15, 2.3098e-15, 1.9631e-15, 8.8266e-16, 1.1691e-14,\n",
      "        3.5417e-15, 1.1526e-14, 1.2457e-14, 1.2060e-14, 1.2680e-14, 6.1176e-15,\n",
      "        9.8349e-16, 9.3547e-16, 1.4986e-14, 1.4038e-14, 5.2409e-15, 2.4482e-15,\n",
      "        7.5218e-15, 1.7162e-14, 1.4753e-14, 1.9891e-14, 1.6397e-14, 2.0703e-15,\n",
      "        3.7799e-15, 1.6038e-14, 9.8636e-16, 1.1782e-14, 1.4260e-14, 5.7057e-15,\n",
      "        6.6140e-16, 4.4105e-15, 2.5253e-15, 7.5340e-15, 1.5236e-14, 5.7091e-15,\n",
      "        1.4692e-14, 8.0500e-15, 1.2373e-15, 1.0757e-14, 1.3530e-14, 1.9485e-14,\n",
      "        7.9522e-15, 8.7867e-15, 9.5502e-15, 1.8263e-15, 2.1210e-15, 6.2542e-15,\n",
      "        8.7671e-16, 6.3286e-15, 1.5830e-14, 8.7322e-16, 1.3670e-15, 1.8007e-14,\n",
      "        1.5690e-14, 1.7194e-14, 6.5110e-16, 3.9415e-15, 1.1729e-14, 3.8459e-15,\n",
      "        1.1454e-15, 1.0284e-15, 1.3357e-14, 1.1921e-14, 1.1528e-14, 1.0062e-15,\n",
      "        4.4941e-15, 1.4196e-15, 9.5465e-16, 3.8219e-15, 1.0417e-14, 7.6220e-15,\n",
      "        7.1536e-16, 1.0745e-15, 4.0080e-15, 6.4059e-15, 8.3935e-15, 7.5734e-16,\n",
      "        1.7849e-14, 1.2381e-14, 7.3220e-15, 1.6866e-14, 1.0039e-14, 9.7253e-15,\n",
      "        1.3907e-14, 1.4510e-14, 5.9324e-15, 2.1198e-15, 8.9643e-16, 5.7332e-15,\n",
      "        1.1404e-15, 4.1090e-15, 1.3195e-15, 6.4513e-15, 4.2188e-15, 1.1920e-14,\n",
      "        9.4902e-16, 7.0999e-15, 3.2192e-15, 9.2175e-16, 1.5760e-14, 9.9995e-15,\n",
      "        7.4512e-16, 4.8769e-15, 1.9123e-14, 1.4558e-15, 2.6590e-15, 1.0578e-14,\n",
      "        3.5800e-15, 1.2158e-15, 1.9283e-15, 5.5850e-15, 1.0548e-14, 1.9700e-14,\n",
      "        6.9761e-16, 1.1258e-14, 1.7855e-14, 7.1265e-15, 1.6731e-15, 6.4983e-15,\n",
      "        1.9462e-15, 9.8435e-15, 1.3749e-14, 7.3974e-15, 4.7737e-15, 4.6130e-15,\n",
      "        5.2273e-15, 8.6383e-16, 5.6919e-15, 1.8703e-15, 7.9260e-16, 1.5323e-14,\n",
      "        7.8507e-16, 6.8631e-16, 1.0002e-14, 6.7655e-15, 1.9317e-14, 6.7884e-15,\n",
      "        1.2455e-14, 2.0055e-14, 1.6254e-15, 1.8209e-14, 1.0787e-15, 5.2263e-15,\n",
      "        1.8112e-14, 6.8544e-15, 2.5712e-15, 7.2873e-15, 3.3872e-15, 1.2308e-15,\n",
      "        8.1193e-15, 1.2908e-14, 1.2020e-14, 1.8145e-15, 1.6022e-15, 7.0421e-16,\n",
      "        6.7141e-15, 4.2310e-15, 9.2516e-15, 6.9740e-15, 5.1954e-15, 1.4700e-14,\n",
      "        3.1326e-15, 1.4689e-14, 1.5947e-15, 9.4872e-16, 1.2238e-15, 9.4584e-16,\n",
      "        9.4443e-16, 1.6413e-15, 8.6181e-16, 9.9768e-15, 5.4335e-15, 1.3016e-14,\n",
      "        1.8924e-14, 1.0076e-14, 1.3008e-14, 8.6719e-16, 2.0474e-15, 6.7043e-16,\n",
      "        1.8340e-14, 1.6707e-14, 1.9868e-15, 7.2602e-15, 3.4291e-15, 7.0711e-15,\n",
      "        7.1493e-16, 5.7949e-15, 1.0409e-14, 1.9745e-14, 1.3318e-14, 1.2831e-14,\n",
      "        2.3507e-15, 9.3266e-16, 5.1418e-15, 7.7448e-15, 1.8685e-15, 6.5774e-16,\n",
      "        8.1291e-15, 7.3796e-15, 1.4091e-15, 1.8232e-15, 6.7760e-15, 1.5582e-14,\n",
      "        7.8086e-15, 5.4386e-15])}, 121150449296: {'step': 800, 'exp_avg': tensor([-2.9948e-03, -3.6950e-05,  1.4987e-04, -1.4854e-03,  7.7706e-04,\n",
      "         1.0393e-04, -2.2505e-03,  1.2391e-03,  6.9667e-04, -1.0516e-03,\n",
      "        -4.2755e-04, -1.4189e-03, -2.6687e-04, -2.7784e-04, -1.3811e-03,\n",
      "        -1.2591e-03,  1.7087e-03,  2.7426e-03, -5.0211e-04, -9.0153e-04,\n",
      "        -7.9362e-04, -7.9442e-06,  9.4633e-04, -6.5184e-04, -8.1611e-04,\n",
      "        -3.5667e-03, -2.2098e-04, -8.1897e-04, -1.0906e-03, -8.8769e-04,\n",
      "         7.2318e-04,  8.7862e-04, -1.7742e-03,  3.2208e-04,  6.2198e-04,\n",
      "         2.3895e-04,  7.6276e-04, -2.9227e-04,  4.2649e-04,  5.1682e-05,\n",
      "         2.2508e-04, -8.4743e-04, -4.0374e-03, -2.3244e-03,  3.9616e-04,\n",
      "        -1.8144e-03,  5.3050e-04, -5.7159e-04, -1.2940e-04, -1.2900e-03,\n",
      "        -3.2255e-04, -1.5487e-04,  8.1398e-04, -2.0456e-03,  2.2732e-04,\n",
      "         5.5391e-05,  8.2954e-04,  2.6197e-04,  5.0613e-04, -5.3983e-04,\n",
      "         4.8924e-04, -4.2005e-03,  2.0245e-04, -9.1889e-04, -3.4917e-04,\n",
      "         1.5259e-05, -3.0969e-03, -2.9373e-03, -2.6367e-03, -8.4698e-04,\n",
      "        -6.0960e-04, -1.5292e-03, -7.5237e-05, -1.6361e-03,  5.1393e-04,\n",
      "         9.5197e-04, -1.2680e-03,  9.0158e-04,  2.5927e-04,  1.0811e-04,\n",
      "        -2.2840e-03, -1.5958e-03, -6.9021e-04,  9.4292e-04, -3.2149e-04,\n",
      "        -1.0505e-04, -1.4256e-03, -1.3600e-03, -2.1280e-03, -5.2453e-04,\n",
      "        -1.2639e-03, -2.0613e-03, -1.2075e-03,  2.3748e-04, -6.0422e-04,\n",
      "         5.3191e-04, -2.2685e-03,  1.3186e-03, -1.4479e-03, -1.4446e-03,\n",
      "        -3.1901e-03, -8.2126e-04, -2.6055e-04,  7.7293e-06, -9.0610e-04,\n",
      "        -1.5744e-03, -3.5405e-03, -1.8548e-04, -3.6788e-04, -3.0253e-04,\n",
      "        -1.6262e-05, -1.5176e-03, -9.9973e-04, -3.3226e-03,  5.0784e-04,\n",
      "        -1.6326e-03,  3.9119e-04,  5.2756e-04, -1.5949e-03, -1.3115e-03,\n",
      "        -1.7264e-03, -2.8294e-03, -6.7915e-05,  3.0977e-04,  5.4841e-04,\n",
      "         2.9819e-04,  1.0082e-04, -1.1862e-03,  1.0123e-03, -4.2749e-04,\n",
      "        -7.3517e-04,  1.2484e-04,  2.0226e-04,  2.9590e-05, -2.1647e-04,\n",
      "        -1.0232e-04, -1.6031e-03, -1.1784e-03, -1.0630e-04,  6.6022e-04,\n",
      "         3.1972e-05, -2.6978e-03, -1.7194e-03,  1.3245e-04, -3.0762e-04,\n",
      "         2.2808e-04, -2.9255e-04, -3.6884e-04,  5.0769e-04, -6.9322e-05,\n",
      "        -4.3481e-04, -1.0706e-03,  8.7214e-05, -3.6402e-05, -8.0957e-04,\n",
      "        -8.3947e-04, -7.9370e-04,  5.2333e-04,  1.4861e-04,  2.4685e-04,\n",
      "        -4.9921e-05,  7.2449e-04, -1.8053e-04, -1.1220e-04,  5.9305e-05,\n",
      "        -7.5511e-04, -8.8027e-04, -2.0088e-04,  1.3397e-04, -1.5550e-03,\n",
      "         2.2712e-04, -5.7684e-04, -2.2059e-03,  9.1326e-04, -1.0917e-03,\n",
      "         9.9808e-04, -5.0636e-03,  1.5746e-04, -2.0351e-03, -6.1884e-04,\n",
      "        -1.8962e-04, -8.4294e-05, -2.9819e-03, -9.4514e-04,  9.7340e-05,\n",
      "        -8.8369e-04, -6.8210e-04, -2.3896e-03, -9.1328e-04, -3.0889e-04,\n",
      "         3.1659e-04, -3.4130e-04, -4.6108e-04, -2.2890e-03,  1.3493e-03,\n",
      "        -1.5315e-03, -4.1142e-03, -1.1070e-03, -2.0734e-03,  1.5527e-03,\n",
      "         1.1057e-03, -2.0229e-03,  1.3048e-04,  2.9835e-04, -8.2983e-04,\n",
      "        -3.2800e-04,  5.5890e-04,  6.1122e-05,  3.2725e-05, -5.8931e-07,\n",
      "        -1.1816e-03,  1.2484e-04, -1.2938e-04,  1.0723e-03, -1.1446e-03,\n",
      "         1.1562e-04, -2.2758e-03, -3.6773e-04, -1.1857e-03,  1.4768e-04,\n",
      "        -3.8751e-04,  5.9384e-04,  6.7009e-04, -7.6520e-04,  4.8846e-04,\n",
      "        -1.5277e-03, -2.2368e-03,  1.8421e-04,  6.3433e-04, -2.3072e-03,\n",
      "        -7.4805e-04, -2.2103e-03, -1.9068e-03, -2.6139e-04, -2.6992e-03,\n",
      "        -2.7597e-04, -6.3048e-04, -1.4602e-04, -6.2692e-04,  6.9053e-04,\n",
      "         7.7878e-04, -2.8777e-03,  7.3853e-05,  3.8751e-04,  3.2658e-04,\n",
      "        -1.4263e-04, -1.1310e-03, -2.7799e-03, -8.0270e-04,  7.1269e-04,\n",
      "         2.4294e-04, -2.7063e-03,  5.7394e-05, -2.3098e-03, -1.2453e-03,\n",
      "         2.7833e-04, -6.1658e-04,  1.8408e-03,  8.9253e-04, -1.5783e-03,\n",
      "         4.4410e-04,  6.0760e-04,  8.5339e-05, -2.9423e-04, -1.1877e-03,\n",
      "        -1.5192e-03, -3.9610e-03, -2.3440e-07, -4.3756e-04,  5.0402e-04,\n",
      "         7.3297e-04, -2.0593e-04, -1.3671e-03, -2.6117e-03,  6.3428e-04,\n",
      "         1.1652e-03,  5.3791e-05,  1.7024e-04, -3.1474e-03, -1.5626e-04,\n",
      "        -5.6044e-05,  8.1949e-05, -7.1613e-04,  5.0305e-04, -1.7237e-03,\n",
      "        -6.2634e-04,  1.3956e-04,  2.6811e-06,  6.9950e-04,  1.4551e-04,\n",
      "        -1.1228e-03, -2.6301e-03, -2.3695e-03, -1.8846e-04, -1.1224e-03,\n",
      "         2.5246e-04, -2.8102e-03, -2.0429e-03, -4.4001e-04, -2.0960e-03,\n",
      "         4.6733e-04,  4.1723e-04,  1.1918e-03, -1.2347e-03, -1.2752e-03,\n",
      "         3.2271e-04,  6.8100e-05,  2.1389e-03, -4.1166e-03, -7.2043e-04,\n",
      "         7.7996e-05,  9.0803e-06, -7.7960e-04, -1.7440e-03, -4.3274e-04,\n",
      "         6.7721e-04,  3.9834e-04,  8.5319e-04, -4.3408e-04, -4.7599e-04,\n",
      "        -1.0239e-03,  8.4108e-04,  1.4499e-04, -9.4513e-04, -2.2493e-03,\n",
      "        -2.2569e-05,  4.4137e-05,  2.2398e-04, -4.0238e-04, -7.8456e-04,\n",
      "        -8.5483e-04, -9.3714e-04, -1.2750e-03, -1.7078e-03,  4.9049e-04,\n",
      "        -1.9145e-03,  3.4598e-05, -6.3962e-04, -1.0190e-04,  3.1282e-04,\n",
      "        -3.7900e-04, -1.3536e-04, -2.4964e-05, -1.0597e-03, -2.3688e-03,\n",
      "        -5.6799e-04, -1.9590e-03, -6.0600e-04, -1.7745e-03, -8.1629e-04,\n",
      "        -8.3564e-04, -5.9874e-04,  2.8835e-04,  5.5317e-04, -1.4477e-03,\n",
      "         4.8595e-04, -4.5753e-04, -6.0030e-04, -1.3793e-03,  8.8365e-04,\n",
      "         1.4715e-04, -2.2955e-03, -3.5777e-04, -7.4561e-04, -5.1625e-04,\n",
      "        -2.6225e-03,  1.0030e-03,  2.2530e-04, -8.1619e-04, -1.9873e-03,\n",
      "        -3.8567e-04, -1.8779e-03,  1.7404e-03,  1.6949e-04,  4.0321e-05,\n",
      "        -2.3992e-03, -1.7279e-03, -3.8718e-04, -2.0062e-03, -5.0013e-04,\n",
      "        -2.7825e-03, -3.9894e-05, -4.2301e-06,  1.3174e-04, -1.0271e-04,\n",
      "         8.0689e-04, -3.3174e-04, -3.2751e-04, -4.7301e-04, -1.1090e-03,\n",
      "         6.8220e-04, -1.5485e-04, -5.6182e-04,  1.1456e-04,  1.0387e-03,\n",
      "        -6.9050e-04,  4.4567e-04, -1.7918e-03, -2.1620e-04, -3.2852e-04,\n",
      "        -1.0633e-03,  1.1136e-04, -3.8640e-04, -1.6577e-03,  5.2754e-05,\n",
      "        -3.3083e-03, -2.1437e-04, -5.4017e-04,  4.6059e-05,  8.1470e-05,\n",
      "        -2.7831e-03, -4.8941e-05, -1.3798e-04, -1.1294e-03, -8.2549e-04,\n",
      "        -4.8786e-04,  4.8845e-04, -8.0241e-04, -6.6909e-04, -1.0644e-03,\n",
      "        -7.6321e-05,  1.7509e-03,  1.1227e-03, -1.2125e-04, -1.9159e-03,\n",
      "        -1.3747e-03, -5.9744e-04, -8.3949e-04, -1.1394e-03, -6.3147e-04,\n",
      "        -1.8470e-03, -1.5857e-03,  7.9533e-04, -2.8795e-04,  4.6869e-04,\n",
      "         3.1227e-04, -1.1026e-04, -6.0837e-05, -4.6472e-04,  7.7906e-05,\n",
      "         4.1415e-04, -1.0739e-03, -1.4889e-04, -9.3964e-04, -6.6221e-04,\n",
      "         3.1272e-04, -8.2662e-05, -4.9698e-04,  6.7632e-04, -9.9342e-04,\n",
      "         1.6535e-04, -1.3526e-03,  2.9299e-04, -1.3708e-04,  5.6299e-05,\n",
      "         2.7678e-04, -4.3411e-04,  3.3487e-05, -2.8752e-03, -2.8839e-04,\n",
      "         6.4110e-05, -2.5874e-04, -1.2795e-03, -2.6766e-04, -2.9636e-03,\n",
      "        -1.8409e-04,  2.1939e-05, -1.6803e-03, -3.0449e-03, -9.7679e-04,\n",
      "         3.6923e-06, -2.3906e-04,  1.8807e-04,  3.4569e-04,  1.7385e-05,\n",
      "         4.1191e-04, -1.9440e-03, -1.8184e-03,  9.6444e-04, -1.6788e-03,\n",
      "        -2.0996e-03, -1.3789e-05, -1.9608e-03, -1.7205e-04, -4.2409e-04,\n",
      "        -7.9007e-04,  1.8985e-04,  6.5477e-04, -2.9578e-04, -2.7901e-03,\n",
      "         5.4114e-04, -1.2934e-04, -4.3545e-04, -3.3944e-04, -4.9757e-04,\n",
      "        -1.3280e-04,  5.4702e-04,  1.5060e-04, -1.5578e-04, -4.7346e-04,\n",
      "        -2.2387e-03, -2.2150e-03, -1.9940e-03, -1.8016e-03,  3.2172e-04,\n",
      "        -1.0395e-03,  9.0152e-05,  7.6835e-04,  2.9278e-04,  7.1797e-04,\n",
      "        -1.2087e-03, -2.8823e-04]), 'exp_avg_sq': tensor([1.7887e-04, 1.2711e-04, 1.3770e-06, 2.7739e-05, 8.9658e-05, 2.2969e-06,\n",
      "        1.1843e-04, 1.4035e-04, 1.7449e-05, 7.4032e-05, 8.3034e-06, 3.2387e-05,\n",
      "        3.9560e-05, 3.5185e-06, 2.6596e-05, 3.8138e-05, 2.5847e-04, 7.7341e-05,\n",
      "        2.6671e-05, 3.5528e-05, 1.1798e-05, 2.9332e-06, 8.9328e-05, 3.6249e-05,\n",
      "        3.8718e-05, 3.0417e-04, 2.6848e-06, 9.1457e-05, 3.1423e-05, 2.1217e-05,\n",
      "        3.4725e-06, 2.7364e-05, 9.3519e-05, 2.2437e-04, 8.6464e-05, 7.8844e-06,\n",
      "        1.2957e-04, 1.2378e-05, 1.9406e-05, 2.0747e-06, 1.7099e-05, 7.2705e-05,\n",
      "        8.4493e-05, 1.0879e-04, 3.3739e-05, 8.1583e-05, 4.9487e-05, 1.0628e-05,\n",
      "        3.5903e-05, 5.9063e-05, 1.8071e-04, 5.5115e-06, 1.3391e-04, 6.6075e-05,\n",
      "        4.1082e-06, 1.3616e-04, 9.1989e-05, 6.9418e-06, 8.4780e-06, 2.1142e-05,\n",
      "        1.6278e-04, 7.7839e-05, 7.4063e-06, 4.1342e-05, 1.2779e-04, 1.7874e-06,\n",
      "        2.0719e-04, 2.0419e-04, 4.3788e-05, 2.9580e-05, 2.6098e-05, 1.4508e-04,\n",
      "        4.7093e-06, 1.1966e-04, 5.3746e-05, 4.3217e-05, 5.6449e-05, 1.0369e-05,\n",
      "        5.4053e-06, 5.9085e-07, 1.0648e-04, 5.7797e-05, 1.1036e-05, 1.3821e-05,\n",
      "        8.9548e-06, 3.7528e-06, 5.8527e-05, 5.1715e-05, 6.5783e-05, 7.0735e-05,\n",
      "        4.8477e-05, 1.2644e-04, 4.0188e-05, 3.7432e-06, 1.6920e-05, 1.3738e-04,\n",
      "        5.9778e-05, 2.0788e-05, 8.1166e-05, 3.3052e-05, 4.7903e-05, 2.3544e-05,\n",
      "        8.6901e-05, 3.7361e-06, 3.5228e-05, 5.9609e-05, 2.2059e-04, 1.0682e-04,\n",
      "        5.7127e-05, 1.9129e-06, 1.7172e-04, 6.1303e-05, 2.2463e-05, 1.3515e-04,\n",
      "        7.7562e-05, 6.6819e-05, 3.4919e-05, 3.7228e-05, 2.1269e-04, 6.1718e-05,\n",
      "        7.0983e-05, 1.4517e-04, 1.8653e-06, 9.1932e-05, 2.2199e-04, 6.7563e-06,\n",
      "        1.3048e-04, 8.8783e-05, 8.0724e-05, 4.9809e-06, 6.4115e-05, 1.5627e-05,\n",
      "        9.6565e-05, 5.4522e-06, 3.4501e-06, 1.7600e-06, 2.4914e-04, 5.2493e-05,\n",
      "        4.0168e-05, 1.0465e-04, 2.3169e-05, 5.7461e-05, 8.5923e-05, 3.2148e-05,\n",
      "        3.6501e-05, 3.6396e-06, 4.7397e-05, 1.8335e-05, 1.7710e-04, 2.2379e-06,\n",
      "        1.2412e-05, 3.2028e-05, 4.5067e-05, 1.3100e-04, 1.2257e-04, 2.3357e-05,\n",
      "        1.4862e-05, 5.2709e-05, 4.7926e-05, 6.1966e-06, 5.6672e-05, 4.7884e-05,\n",
      "        1.1826e-05, 1.6162e-05, 9.8457e-07, 1.0209e-05, 4.0183e-05, 1.1729e-04,\n",
      "        1.7814e-06, 6.3226e-05, 5.5101e-05, 5.7176e-05, 1.5093e-04, 6.0892e-05,\n",
      "        2.3890e-05, 7.9067e-05, 2.0931e-04, 9.9094e-07, 5.7634e-05, 6.3626e-06,\n",
      "        7.4328e-05, 1.4515e-05, 1.9984e-04, 5.4806e-05, 2.4985e-06, 2.3204e-05,\n",
      "        1.5958e-05, 8.7051e-05, 2.3540e-05, 6.1886e-06, 1.5183e-04, 8.5698e-06,\n",
      "        1.7036e-05, 1.1061e-04, 9.4332e-05, 1.2044e-04, 2.1009e-04, 6.1519e-05,\n",
      "        3.2803e-05, 5.4665e-05, 2.5924e-05, 3.3792e-05, 1.1503e-04, 2.1367e-05,\n",
      "        1.3490e-04, 8.0046e-05, 1.6604e-05, 2.3478e-05, 1.6392e-06, 5.0202e-05,\n",
      "        2.2823e-05, 6.6882e-05, 2.5061e-05, 4.4734e-05, 1.8005e-05, 6.5305e-05,\n",
      "        8.9698e-05, 1.1510e-04, 1.7799e-04, 9.8090e-06, 2.7623e-05, 2.5682e-04,\n",
      "        6.4375e-05, 1.3540e-05, 5.0592e-06, 4.3069e-05, 6.0426e-05, 8.3819e-06,\n",
      "        1.2689e-04, 1.4163e-04, 1.7126e-05, 8.5526e-05, 5.9541e-05, 3.2573e-06,\n",
      "        9.4757e-05, 1.9678e-04, 2.8478e-05, 9.1886e-07, 1.8381e-05, 4.6912e-05,\n",
      "        1.2678e-04, 1.4758e-04, 1.2571e-04, 7.8219e-05, 6.7201e-06, 3.6761e-06,\n",
      "        6.3236e-05, 6.4433e-05, 1.8789e-05, 8.7243e-05, 7.3314e-05, 1.4553e-04,\n",
      "        1.5975e-06, 1.5213e-04, 2.0817e-04, 3.4129e-06, 1.1878e-04, 3.2384e-04,\n",
      "        6.7270e-05, 2.4652e-05, 8.0621e-06, 4.8639e-06, 1.4198e-06, 8.4046e-05,\n",
      "        4.9364e-05, 5.5697e-05, 1.1494e-04, 3.0637e-06, 2.3891e-05, 9.0453e-06,\n",
      "        3.7389e-05, 4.4166e-06, 2.2077e-05, 1.6896e-04, 9.4322e-05, 1.2571e-05,\n",
      "        2.0312e-06, 2.5210e-05, 2.1834e-04, 4.2371e-05, 1.7075e-06, 1.5285e-06,\n",
      "        9.1151e-06, 3.6409e-06, 1.0223e-04, 2.5219e-05, 1.0419e-04, 2.9941e-05,\n",
      "        8.5385e-05, 1.7354e-06, 2.1548e-05, 2.0530e-04, 1.0656e-04, 1.3192e-05,\n",
      "        5.4578e-05, 5.3379e-05, 1.3921e-04, 4.0738e-05, 5.6785e-05, 4.5116e-05,\n",
      "        1.0022e-04, 2.1435e-06, 4.0883e-05, 4.5984e-05, 4.1840e-05, 2.0626e-05,\n",
      "        2.5852e-06, 3.5060e-05, 8.5507e-05, 3.5251e-05, 6.1127e-06, 3.1149e-05,\n",
      "        1.4748e-04, 3.9120e-05, 8.1734e-06, 9.3892e-05, 2.5241e-04, 5.0202e-05,\n",
      "        8.5015e-06, 1.0876e-05, 6.5524e-05, 2.3675e-05, 1.9225e-06, 4.6294e-05,\n",
      "        1.3488e-04, 9.9884e-07, 9.5988e-06, 1.5037e-05, 9.2264e-06, 1.7035e-05,\n",
      "        3.5014e-05, 1.7937e-05, 4.6329e-05, 5.4537e-05, 4.8845e-05, 3.2626e-05,\n",
      "        3.2402e-05, 3.5922e-05, 2.3835e-06, 2.9964e-06, 2.3160e-05, 1.8163e-05,\n",
      "        1.4466e-05, 5.9743e-05, 7.0943e-05, 2.7101e-05, 1.0171e-04, 1.2046e-05,\n",
      "        3.1513e-05, 1.9865e-05, 1.8270e-05, 1.2274e-05, 1.6712e-04, 3.7152e-05,\n",
      "        9.1858e-05, 1.0158e-04, 9.1013e-06, 1.4559e-05, 3.3162e-05, 3.9207e-05,\n",
      "        8.5548e-06, 1.1437e-04, 1.4492e-04, 3.7731e-05, 2.9665e-05, 1.4123e-04,\n",
      "        1.3532e-04, 1.9080e-06, 2.1061e-05, 7.5724e-05, 3.2268e-05, 6.4855e-05,\n",
      "        8.4002e-05, 1.0585e-05, 1.3054e-06, 1.1019e-04, 4.5187e-05, 6.6352e-06,\n",
      "        7.0464e-05, 9.6043e-05, 1.7967e-04, 6.1739e-05, 2.7363e-05, 1.9038e-05,\n",
      "        5.0744e-06, 5.9794e-05, 1.7670e-05, 2.0502e-05, 1.5835e-05, 1.2427e-05,\n",
      "        9.2936e-06, 8.0755e-05, 1.5267e-05, 8.1322e-06, 2.9397e-05, 2.2611e-05,\n",
      "        1.3686e-04, 3.3678e-05, 1.1176e-05, 1.1924e-04, 2.6487e-05, 5.9566e-06,\n",
      "        1.3125e-04, 1.3112e-04, 2.3268e-06, 9.2235e-05, 4.9215e-06, 1.5053e-04,\n",
      "        1.2471e-06, 3.0240e-05, 4.4955e-05, 6.0506e-05, 2.7042e-06, 3.3131e-05,\n",
      "        8.6343e-05, 2.0995e-05, 2.9986e-05, 2.9209e-05, 4.2932e-05, 1.6629e-05,\n",
      "        4.5717e-06, 4.1317e-05, 6.3452e-05, 3.2139e-06, 7.1917e-05, 1.7170e-05,\n",
      "        2.9528e-05, 9.4239e-06, 3.3748e-05, 2.5343e-05, 1.0309e-04, 6.7709e-05,\n",
      "        1.1595e-04, 5.2492e-05, 8.0971e-05, 2.1205e-05, 2.6322e-06, 5.3222e-06,\n",
      "        1.4252e-05, 3.7400e-06, 8.0299e-06, 5.6029e-05, 6.9931e-05, 1.4013e-04,\n",
      "        1.9320e-04, 1.5833e-05, 2.0510e-06, 1.3889e-05, 3.5689e-05, 2.5277e-05,\n",
      "        1.1465e-04, 4.1689e-05, 4.8926e-06, 2.5585e-06, 3.5014e-05, 3.5265e-06,\n",
      "        1.6505e-05, 1.2683e-05, 6.0028e-05, 1.3204e-04, 9.6338e-05, 2.0579e-05,\n",
      "        3.8583e-05, 1.0819e-05, 2.3025e-04, 8.4727e-06, 5.4723e-05, 5.7134e-05,\n",
      "        6.0061e-05, 2.2887e-05, 1.4279e-04, 4.4473e-05, 4.3233e-05, 4.7132e-05,\n",
      "        1.0146e-04, 2.0328e-04, 1.0378e-04, 5.1128e-05, 6.2200e-05, 7.2985e-05,\n",
      "        9.8268e-05, 9.1342e-05, 7.3860e-05, 6.6505e-06, 8.1159e-06, 7.8811e-06,\n",
      "        2.0333e-05, 1.1174e-04, 1.7599e-05, 6.8725e-05, 2.5540e-04, 6.0406e-06,\n",
      "        3.6984e-06, 8.6410e-06, 3.0371e-05, 1.5199e-05, 6.2738e-05, 2.7640e-06,\n",
      "        2.2147e-06, 1.2798e-05, 1.2393e-04, 1.3773e-04, 1.0306e-04, 7.2436e-05,\n",
      "        1.5582e-05, 3.2035e-05, 1.9808e-04, 6.2694e-05, 1.4806e-04, 9.4593e-06,\n",
      "        6.5331e-05, 7.0360e-06])}, 121150449376: {'step': 800, 'exp_avg': tensor([-1.6534e-03,  7.9956e-04,  8.8285e-05, -1.9337e-03,  6.1651e-04,\n",
      "         8.3729e-05, -2.4138e-03,  1.1131e-03,  4.5523e-04, -3.0509e-04,\n",
      "        -4.7578e-04, -7.4986e-04,  1.8181e-04, -4.6260e-04, -2.0351e-03,\n",
      "        -5.7912e-04,  1.7972e-03,  1.8337e-03, -2.6351e-04, -4.6371e-04,\n",
      "        -4.8493e-04, -7.3508e-05,  5.1141e-04, -8.6230e-04, -8.0580e-04,\n",
      "        -3.4970e-03, -2.0038e-04, -9.3253e-04, -1.0104e-03, -1.1031e-03,\n",
      "         5.4514e-04,  6.1652e-04, -6.5480e-04,  7.1748e-05,  5.8074e-04,\n",
      "         2.0711e-04,  7.9302e-04, -1.0632e-04,  4.0938e-04,  3.4491e-05,\n",
      "         2.8307e-04, -4.7163e-04, -4.5086e-03, -9.9517e-04,  3.0478e-04,\n",
      "        -5.6260e-04,  6.7911e-04, -2.8740e-04, -5.4848e-05, -8.7677e-04,\n",
      "        -7.3658e-04, -1.3709e-04,  5.3955e-04, -7.0596e-04,  1.6170e-04,\n",
      "        -2.5644e-04,  4.5485e-04,  2.1055e-04,  5.4977e-04, -6.7958e-04,\n",
      "         6.2673e-04, -4.6519e-03, -7.8327e-06, -5.8927e-04,  3.3005e-04,\n",
      "        -4.6224e-05, -1.4389e-03, -2.2230e-03, -3.0302e-03, -5.0188e-04,\n",
      "        -6.0732e-04, -9.6907e-04, -1.0467e-04, -6.5260e-04,  5.6102e-04,\n",
      "         1.0656e-03, -9.4524e-04,  7.8033e-04,  2.0727e-04,  3.0868e-05,\n",
      "        -2.1617e-03, -1.8765e-03, -4.9999e-04,  4.8026e-04, -1.1239e-04,\n",
      "        -1.9019e-04, -5.4678e-04, -7.5247e-04, -2.2122e-03, -8.8807e-04,\n",
      "        -1.5958e-03, -1.9009e-03, -6.1263e-04,  1.4073e-04, -1.5910e-04,\n",
      "         3.0376e-04, -1.6880e-03,  8.7687e-04, -4.8101e-04, -5.9909e-04,\n",
      "        -3.2535e-03, -5.5812e-04, -4.4304e-04, -8.2675e-05, -5.0555e-04,\n",
      "        -7.6052e-04, -2.7704e-03, -2.8085e-04, -4.0660e-04, -1.4724e-04,\n",
      "         6.9115e-04, -1.2541e-03, -4.1237e-04, -3.1255e-03,  1.7560e-04,\n",
      "        -7.2909e-04,  7.9055e-05,  2.1592e-04, -1.3734e-03, -1.2394e-03,\n",
      "        -1.2417e-03, -1.8171e-03, -1.0720e-04,  2.5378e-04,  7.8044e-04,\n",
      "         2.2947e-04,  6.5852e-04, -1.4291e-03,  8.4576e-04, -7.1556e-04,\n",
      "        -8.9897e-04, -2.7372e-06,  1.7775e-04,  5.2412e-05, -2.9771e-04,\n",
      "        -2.0631e-04, -1.5430e-03, -5.5125e-04,  2.7443e-05,  9.7428e-04,\n",
      "        -1.8949e-05, -3.2956e-03, -4.3799e-04,  1.5107e-04, -8.5485e-04,\n",
      "         1.6546e-04, -3.2746e-04, -3.7659e-04,  5.2001e-04, -2.0634e-04,\n",
      "        -2.3315e-04, -5.4172e-04, -1.5416e-04,  2.3368e-04,  1.0224e-05,\n",
      "        -2.9129e-04, -3.6296e-04,  4.3567e-04,  2.4739e-04,  1.8713e-04,\n",
      "        -1.6180e-04,  7.6681e-04, -5.0316e-06, -6.1097e-05, -2.5293e-05,\n",
      "        -1.0596e-03, -1.6374e-04,  7.2434e-04,  2.7556e-05, -1.2894e-03,\n",
      "        -5.6710e-06, -1.1198e-03, -1.9457e-03,  1.0079e-03, -1.2710e-03,\n",
      "         8.5327e-04, -4.2615e-03,  9.6518e-05, -5.4223e-04, -2.8336e-04,\n",
      "        -2.3574e-04, -2.8847e-04, -1.3161e-03, -1.5378e-04,  4.2639e-05,\n",
      "        -3.1918e-04, -9.9358e-04, -4.1456e-03, -3.9448e-04, -3.0788e-04,\n",
      "         4.2867e-04, -1.1861e-04, -2.1060e-04, -1.5377e-03,  1.8395e-03,\n",
      "        -1.2783e-03, -3.1375e-03, -1.0816e-03, -1.8403e-03,  1.2919e-03,\n",
      "         7.9853e-04, -2.5791e-03, -1.8412e-04,  3.1558e-04,  6.4330e-05,\n",
      "        -3.9158e-04,  5.3277e-04,  3.0800e-05, -4.6394e-05, -1.2810e-04,\n",
      "        -1.2546e-03,  4.2299e-04, -1.9781e-04,  1.0858e-03, -6.4493e-04,\n",
      "         4.4551e-04, -1.9501e-03,  1.7627e-05, -6.0000e-04, -3.6655e-07,\n",
      "        -1.7609e-04,  3.6637e-04, -1.1520e-04, -4.2477e-04,  2.8267e-04,\n",
      "        -6.9396e-04, -3.1260e-03,  1.5183e-04,  4.1869e-04, -1.7106e-03,\n",
      "        -3.3293e-04, -2.1050e-03, -1.9534e-03, -4.5980e-04, -2.0674e-03,\n",
      "         5.7381e-05, -3.0379e-04, -1.4556e-04, -9.4716e-04,  4.5379e-04,\n",
      "         8.4349e-04, -2.6310e-03,  4.2297e-04,  1.9725e-04,  2.9746e-04,\n",
      "        -1.8817e-04, -7.1255e-04, -2.5237e-03, -7.6760e-04,  5.4749e-04,\n",
      "         2.3552e-04, -1.3218e-03, -1.7435e-05, -1.0269e-03, -8.4761e-04,\n",
      "         2.7613e-04, -6.6296e-04,  1.9239e-03,  9.7499e-04, -1.3836e-03,\n",
      "         4.0076e-04,  5.1092e-04,  1.3206e-05, -1.8492e-04, -1.0498e-03,\n",
      "        -6.9528e-04, -3.6308e-03, -6.4581e-05, -4.7606e-04,  3.4737e-04,\n",
      "         3.2183e-04, -8.2464e-05, -6.4493e-04, -1.0121e-03,  5.0821e-04,\n",
      "         7.9836e-04, -4.6122e-05,  2.4446e-04, -2.5522e-03,  7.4598e-04,\n",
      "        -1.9573e-04,  1.3508e-05, -6.0989e-04,  3.0392e-04, -1.4468e-03,\n",
      "        -4.6502e-04,  4.0557e-04, -2.2559e-04,  5.2318e-04,  6.7291e-05,\n",
      "        -9.1291e-04, -1.0373e-03, -1.3158e-03, -1.6881e-04, -1.0545e-03,\n",
      "         2.3403e-04, -1.1836e-03, -3.2270e-03,  2.9034e-04, -1.8923e-03,\n",
      "         7.2763e-04,  2.2473e-04,  6.7269e-04, -1.2027e-03, -5.5043e-04,\n",
      "         3.5903e-04, -2.3503e-05,  1.3579e-03, -4.5908e-03,  1.4559e-05,\n",
      "         3.4284e-05, -7.6270e-05, -1.6457e-03, -2.2834e-03, -6.2758e-04,\n",
      "         5.5453e-04,  7.8034e-04,  7.9594e-04, -3.0824e-04, -2.5852e-04,\n",
      "        -1.0166e-03,  4.6244e-04,  8.8576e-05, -7.9200e-04, -2.3857e-03,\n",
      "        -1.0147e-04, -2.1619e-05,  2.6612e-04, -2.4945e-04, -4.7641e-04,\n",
      "        -3.7117e-04, -5.2075e-04, -5.4609e-04, -5.6884e-04,  4.1041e-04,\n",
      "        -1.9369e-03, -2.5291e-04, -3.9220e-04, -1.1059e-04,  1.0404e-04,\n",
      "         1.0318e-04, -1.6982e-04, -4.2341e-05, -4.0731e-04, -1.5340e-03,\n",
      "        -5.5716e-04, -8.0246e-04, -4.8132e-04, -1.7722e-03, -4.9544e-04,\n",
      "        -2.0489e-04, -6.2267e-04,  5.6345e-04,  5.9152e-04, -3.1724e-04,\n",
      "         8.0728e-04, -7.4034e-04, -4.4303e-04, -7.8717e-04,  7.6177e-04,\n",
      "         1.3914e-04, -2.3265e-03,  2.9902e-04, -1.0771e-03, -5.2431e-04,\n",
      "        -2.0495e-03,  7.6394e-04,  1.1694e-04, -4.6372e-04, -1.9097e-03,\n",
      "        -6.3901e-05, -1.5027e-03,  1.8841e-03,  1.6154e-04, -3.6217e-05,\n",
      "        -1.7189e-03, -1.4363e-03, -2.9333e-04, -9.6549e-04, -1.7650e-04,\n",
      "        -2.8961e-03, -1.7285e-04,  2.0327e-04,  1.7630e-04, -1.4338e-04,\n",
      "         3.9714e-04, -2.5521e-04, -3.4062e-04, -3.8198e-04, -1.1273e-03,\n",
      "         7.1419e-04, -2.0621e-04, -2.6672e-04,  1.2114e-05,  1.0279e-03,\n",
      "        -2.4670e-04,  6.5065e-04, -1.8098e-03, -1.0407e-04, -1.3515e-04,\n",
      "        -5.3351e-04,  9.3321e-05, -6.5398e-04, -1.3894e-03, -9.1764e-05,\n",
      "        -2.9968e-03, -5.4941e-05,  1.8493e-04, -4.0570e-05,  2.3855e-04,\n",
      "        -2.9514e-03, -1.5139e-04, -1.6330e-04, -8.3332e-04, -1.8259e-04,\n",
      "        -5.8139e-04,  4.7822e-04, -4.5866e-04, -8.6118e-04, -1.5312e-03,\n",
      "        -6.7229e-05,  1.3578e-03,  1.1679e-03, -1.8028e-04, -1.9431e-03,\n",
      "        -1.5890e-03, -2.7999e-04, -1.0839e-03, -4.5918e-04, -1.0069e-03,\n",
      "        -9.5519e-04, -7.6975e-04,  1.0315e-04, -2.8509e-04, -7.1718e-05,\n",
      "         3.6855e-04, -1.1257e-04, -1.2117e-04, -2.8092e-04,  1.5591e-07,\n",
      "         3.7826e-04, -1.4822e-03, -3.3930e-04,  1.5643e-04, -1.0540e-03,\n",
      "         3.0664e-04, -1.6851e-04, -3.1701e-04,  7.2428e-04, -5.7047e-04,\n",
      "         2.5342e-04, -9.1015e-04,  2.6013e-04, -1.0688e-04, -9.5228e-05,\n",
      "         1.9568e-04, -4.0124e-04,  4.0261e-05, -3.4451e-03, -3.4116e-06,\n",
      "        -1.2315e-04, -4.2876e-04, -1.1605e-03, -4.3204e-04, -1.2339e-03,\n",
      "        -2.7735e-04, -1.9024e-04, -1.4252e-03, -2.6710e-03, -5.3220e-04,\n",
      "        -1.6473e-04, -7.7697e-05,  1.1905e-04,  3.0674e-04,  4.6641e-05,\n",
      "         8.7574e-05, -1.6806e-03, -1.5724e-03,  1.2163e-03, -6.7083e-04,\n",
      "        -9.3635e-04, -5.8364e-04, -1.2565e-03, -1.1717e-04, -5.7926e-04,\n",
      "        -3.8311e-04,  2.4918e-04,  6.6423e-04, -1.9082e-04, -3.3115e-03,\n",
      "         4.8776e-04, -2.0230e-04, -5.0142e-04, -2.7012e-04, -3.3169e-04,\n",
      "        -1.5444e-04,  4.8951e-04,  2.5213e-05, -3.0754e-04, -3.0654e-04,\n",
      "        -1.4366e-03, -1.6833e-03, -1.2900e-03, -7.8326e-04,  2.0678e-04,\n",
      "        -9.2180e-04,  2.8949e-04,  7.8363e-04,  2.8193e-04,  4.4732e-04,\n",
      "        -1.1630e-03, -2.9613e-04]), 'exp_avg_sq': tensor([6.6657e-05, 3.6169e-05, 2.6627e-06, 6.7463e-05, 3.2630e-05, 5.1972e-06,\n",
      "        8.5896e-05, 5.3972e-05, 1.3905e-05, 4.8347e-05, 1.0290e-05, 1.7585e-05,\n",
      "        8.1202e-06, 7.0877e-06, 5.8433e-05, 2.3446e-05, 9.8087e-05, 7.9313e-05,\n",
      "        1.0213e-05, 2.0806e-05, 5.2156e-06, 9.7757e-07, 3.4231e-05, 5.8833e-05,\n",
      "        3.5055e-05, 2.1431e-04, 5.4225e-06, 7.5551e-05, 3.1381e-05, 3.8400e-05,\n",
      "        5.3028e-06, 1.1117e-05, 7.0060e-05, 3.1514e-04, 3.3447e-05, 1.1353e-05,\n",
      "        6.3634e-05, 1.3349e-05, 1.7194e-05, 6.1337e-06, 1.5094e-05, 7.4864e-05,\n",
      "        1.4302e-04, 4.9154e-05, 4.0081e-05, 6.2304e-05, 3.7782e-05, 1.8519e-06,\n",
      "        2.6653e-05, 3.8476e-05, 1.4983e-04, 1.6307e-06, 6.1182e-05, 1.6023e-05,\n",
      "        1.0132e-05, 9.2893e-05, 3.8416e-05, 7.8818e-06, 1.4100e-05, 4.0216e-05,\n",
      "        1.0279e-04, 1.4313e-04, 9.7640e-06, 1.4069e-05, 1.2531e-04, 5.3575e-07,\n",
      "        1.3905e-04, 1.5949e-04, 1.1060e-04, 7.7363e-06, 2.9720e-05, 1.6149e-04,\n",
      "        6.1057e-06, 1.4713e-04, 5.2324e-05, 6.0946e-05, 5.4831e-05, 1.9776e-05,\n",
      "        4.9374e-06, 1.5097e-06, 8.4294e-05, 1.0077e-04, 8.1560e-06, 7.7069e-06,\n",
      "        5.1826e-06, 4.9307e-06, 3.0884e-05, 2.1207e-05, 8.7073e-05, 1.5470e-04,\n",
      "        8.5932e-05, 1.1638e-04, 1.2081e-05, 6.7624e-06, 6.7961e-06, 2.0088e-04,\n",
      "        5.4045e-05, 2.6591e-05, 3.5419e-05, 8.1974e-06, 7.3727e-05, 1.3343e-05,\n",
      "        7.0540e-05, 1.0062e-05, 1.2484e-05, 5.8806e-05, 2.6143e-04, 8.1277e-05,\n",
      "        6.3843e-05, 2.7110e-06, 6.1116e-05, 4.2967e-05, 1.4759e-05, 1.5186e-04,\n",
      "        8.4769e-05, 2.1786e-05, 3.3299e-05, 6.8823e-05, 1.9051e-04, 9.1406e-05,\n",
      "        4.9118e-05, 7.3152e-05, 5.5333e-07, 2.9641e-05, 1.2309e-04, 8.4307e-06,\n",
      "        3.8554e-05, 4.5602e-05, 2.8144e-05, 1.0301e-05, 8.3850e-05, 1.0404e-05,\n",
      "        1.1030e-04, 1.3098e-05, 8.5573e-06, 4.6845e-06, 2.1347e-04, 2.8135e-05,\n",
      "        1.6296e-05, 3.5006e-05, 8.4794e-06, 1.4109e-04, 3.5440e-05, 3.7587e-05,\n",
      "        7.5950e-05, 8.3170e-06, 4.3194e-05, 1.5400e-05, 7.0479e-05, 6.6036e-06,\n",
      "        2.8438e-06, 1.5632e-05, 3.8892e-05, 3.9803e-05, 1.5273e-04, 3.6750e-05,\n",
      "        3.2634e-06, 1.4847e-05, 4.6345e-05, 9.6492e-06, 3.3574e-05, 3.8326e-05,\n",
      "        1.1433e-05, 8.2587e-06, 2.1414e-06, 2.3952e-05, 5.4377e-05, 3.0813e-05,\n",
      "        3.9716e-06, 6.2543e-05, 6.8966e-05, 9.6639e-05, 1.3039e-04, 8.6648e-05,\n",
      "        5.6366e-05, 1.0907e-04, 2.7249e-04, 2.4449e-06, 1.0335e-05, 1.0927e-06,\n",
      "        4.3767e-05, 1.6405e-05, 1.6409e-04, 2.3156e-05, 8.4054e-06, 1.8265e-05,\n",
      "        3.6980e-05, 1.6764e-04, 1.9193e-05, 2.7041e-06, 1.2944e-04, 2.8061e-06,\n",
      "        3.3484e-05, 8.5383e-05, 1.3421e-04, 1.6087e-04, 1.6442e-04, 6.0473e-05,\n",
      "        4.5789e-05, 7.3691e-05, 1.2156e-05, 6.3181e-05, 2.0025e-04, 1.7560e-05,\n",
      "        4.6980e-05, 7.1582e-05, 2.0638e-05, 1.2030e-05, 2.7833e-06, 7.0692e-05,\n",
      "        4.6481e-05, 5.7057e-05, 5.5250e-06, 4.5709e-05, 8.5275e-06, 1.8334e-05,\n",
      "        1.3716e-04, 8.4879e-05, 2.0937e-04, 1.0314e-05, 4.9023e-05, 1.9818e-04,\n",
      "        1.0842e-04, 7.5197e-06, 9.7938e-06, 1.3036e-05, 1.3230e-04, 3.0018e-06,\n",
      "        8.7938e-05, 1.4910e-04, 9.6587e-06, 1.1622e-04, 9.0927e-05, 9.7404e-06,\n",
      "        7.5940e-05, 1.3616e-04, 7.0464e-06, 2.2436e-06, 5.3090e-05, 1.3497e-05,\n",
      "        5.1295e-05, 1.4580e-04, 3.5171e-05, 8.0979e-05, 1.8432e-05, 7.2324e-06,\n",
      "        3.6197e-05, 9.1562e-05, 2.0489e-05, 3.6512e-05, 2.7561e-05, 8.4113e-05,\n",
      "        5.0660e-06, 1.0667e-04, 2.4606e-04, 1.1248e-05, 8.7800e-05, 1.2426e-04,\n",
      "        5.6728e-05, 3.4020e-05, 1.2640e-05, 9.0839e-06, 4.3737e-06, 4.7263e-05,\n",
      "        4.2823e-05, 3.9601e-05, 1.5455e-04, 9.4321e-07, 2.3583e-05, 1.0557e-05,\n",
      "        2.6347e-05, 2.4558e-06, 4.6833e-06, 1.2557e-04, 3.6252e-05, 2.1185e-05,\n",
      "        2.8783e-06, 1.3319e-05, 1.7647e-04, 4.3391e-05, 6.3507e-06, 2.4293e-06,\n",
      "        5.3236e-06, 5.7404e-06, 8.3642e-05, 1.4094e-05, 5.2702e-05, 3.2440e-05,\n",
      "        4.3688e-05, 3.5469e-06, 1.3100e-05, 1.3165e-04, 9.0463e-05, 4.1875e-05,\n",
      "        6.7567e-05, 4.9193e-05, 4.8570e-05, 1.1399e-04, 6.1056e-05, 9.2754e-05,\n",
      "        9.4911e-05, 4.0022e-06, 3.6020e-05, 6.8160e-05, 1.5584e-05, 2.2271e-05,\n",
      "        8.6439e-06, 4.3540e-05, 1.4638e-04, 1.1824e-05, 1.3522e-05, 3.7645e-05,\n",
      "        1.7900e-04, 9.4845e-05, 1.8015e-05, 1.6733e-04, 1.4674e-04, 3.2766e-05,\n",
      "        3.3926e-06, 5.6220e-06, 6.6689e-05, 1.6890e-05, 3.7656e-06, 6.7143e-05,\n",
      "        8.1589e-05, 3.4737e-06, 6.2585e-06, 1.4680e-05, 2.0352e-06, 8.3272e-06,\n",
      "        2.4554e-05, 2.5824e-05, 1.1875e-05, 1.6013e-05, 2.5072e-05, 5.2751e-05,\n",
      "        5.2872e-05, 4.2042e-05, 2.0653e-06, 1.0812e-05, 3.3033e-05, 7.8399e-06,\n",
      "        1.9381e-05, 6.9354e-05, 7.3269e-05, 3.2541e-05, 7.2004e-05, 7.9546e-06,\n",
      "        6.3091e-05, 4.6685e-06, 3.1133e-06, 5.2222e-06, 1.5553e-04, 3.2610e-05,\n",
      "        3.8053e-05, 2.9850e-05, 2.1684e-05, 1.2869e-05, 1.6970e-05, 3.0976e-05,\n",
      "        9.9073e-06, 8.6952e-05, 4.6354e-05, 6.0417e-05, 2.0462e-05, 1.1038e-04,\n",
      "        7.1842e-05, 4.1962e-06, 1.0056e-05, 5.0159e-05, 7.9703e-06, 4.5261e-05,\n",
      "        7.7383e-05, 1.8599e-05, 2.0697e-06, 7.5046e-05, 3.1214e-05, 4.5199e-06,\n",
      "        4.2920e-05, 1.2424e-04, 1.3951e-04, 6.8695e-05, 3.3604e-05, 2.3375e-05,\n",
      "        6.2917e-06, 6.7192e-05, 3.7567e-06, 2.0036e-05, 2.5644e-05, 1.9745e-05,\n",
      "        1.5276e-05, 4.8051e-05, 7.8643e-06, 1.3945e-05, 4.0955e-05, 7.9311e-06,\n",
      "        5.1822e-05, 6.3225e-05, 3.5043e-06, 1.2240e-04, 1.3183e-05, 1.4094e-05,\n",
      "        9.6615e-05, 1.2036e-04, 3.3901e-06, 1.1654e-04, 3.9025e-06, 5.0447e-05,\n",
      "        2.0313e-06, 3.0946e-05, 7.0554e-05, 6.7607e-05, 5.2120e-07, 1.9375e-05,\n",
      "        9.2998e-05, 2.3593e-05, 2.5837e-05, 1.5612e-05, 2.2542e-05, 3.7642e-05,\n",
      "        1.0493e-06, 4.6244e-05, 5.9634e-05, 6.1701e-06, 9.9304e-05, 3.5281e-05,\n",
      "        1.0304e-05, 1.9810e-05, 1.2110e-05, 5.4001e-05, 3.8140e-05, 2.0422e-05,\n",
      "        9.0081e-05, 5.6603e-05, 8.9981e-05, 2.1463e-05, 3.3047e-06, 2.1495e-06,\n",
      "        5.8836e-06, 1.0817e-05, 8.7919e-06, 8.4617e-05, 1.2631e-04, 4.3505e-05,\n",
      "        1.6046e-04, 1.7123e-05, 2.5549e-06, 1.2480e-05, 4.7391e-05, 6.4473e-06,\n",
      "        4.3901e-05, 3.6971e-05, 9.3194e-06, 1.8613e-06, 3.5504e-05, 2.0797e-06,\n",
      "        6.2254e-06, 7.5659e-06, 1.2095e-04, 8.8523e-05, 9.7242e-05, 1.9205e-05,\n",
      "        3.8209e-05, 1.5953e-05, 1.6430e-04, 1.9525e-05, 7.8347e-05, 3.6988e-05,\n",
      "        9.0245e-05, 1.0321e-05, 1.2314e-04, 1.7524e-05, 4.3297e-05, 4.0657e-05,\n",
      "        6.2947e-05, 2.2751e-04, 1.2055e-04, 7.2225e-05, 7.8715e-05, 4.6236e-05,\n",
      "        5.6984e-05, 1.2999e-04, 4.2678e-05, 1.3237e-06, 2.3200e-05, 7.8415e-06,\n",
      "        1.6689e-05, 3.8963e-05, 7.5235e-06, 1.2855e-04, 1.3862e-04, 1.7357e-05,\n",
      "        6.0317e-06, 4.0780e-06, 1.4162e-05, 1.2860e-05, 2.1307e-05, 5.2353e-06,\n",
      "        6.2078e-06, 5.9652e-06, 1.5420e-04, 1.3350e-04, 7.9364e-05, 2.2417e-05,\n",
      "        1.3727e-05, 2.7416e-05, 9.1890e-05, 8.3566e-05, 8.2925e-05, 1.2369e-05,\n",
      "        6.5171e-05, 1.2445e-05])}, 121150449696: {'step': 800, 'exp_avg': tensor([[ 6.4829e-03,  1.8347e-03,  9.9621e-04,  ...,  2.3398e-03,\n",
      "          6.0772e-03,  3.3936e-03],\n",
      "        [ 1.6333e-03,  2.1934e-03, -2.1438e-04,  ...,  9.1733e-04,\n",
      "          8.1884e-04,  4.0662e-04],\n",
      "        [ 1.6935e-03,  4.6340e-03,  2.4440e-04,  ...,  1.4166e-03,\n",
      "          4.2839e-03,  1.5630e-03],\n",
      "        [-7.8857e-03, -1.6527e-03, -1.2284e-03,  ..., -3.6453e-03,\n",
      "         -7.2666e-03, -4.1445e-03],\n",
      "        [-1.4052e-03, -7.5681e-03,  1.8560e-04,  ..., -1.1934e-03,\n",
      "         -4.3124e-03, -1.3578e-03],\n",
      "        [-5.2572e-04,  5.5597e-04,  1.8710e-05,  ...,  1.5085e-04,\n",
      "          3.7639e-04,  1.4746e-04]]), 'exp_avg_sq': tensor([[1.3048e-03, 1.5670e-03, 6.7113e-05,  ..., 8.7464e-05, 3.3456e-04,\n",
      "         1.6922e-04],\n",
      "        [5.9865e-04, 4.3190e-04, 1.5881e-04,  ..., 2.5299e-04, 6.9800e-04,\n",
      "         2.7456e-04],\n",
      "        [1.8724e-04, 7.1661e-04, 2.0812e-05,  ..., 3.0608e-05, 3.6416e-04,\n",
      "         5.6719e-05],\n",
      "        [2.3081e-03, 2.6246e-03, 2.5470e-04,  ..., 3.3533e-04, 1.2513e-03,\n",
      "         4.5627e-04],\n",
      "        [9.6261e-04, 1.8199e-03, 5.1291e-05,  ..., 1.1092e-04, 4.3704e-04,\n",
      "         1.0684e-04],\n",
      "        [2.4925e-04, 1.8184e-04, 1.7999e-05,  ..., 2.5576e-05, 1.1332e-04,\n",
      "         2.4623e-05]])}, 121150449776: {'step': 800, 'exp_avg': tensor([ 0.0083,  0.0052,  0.0089, -0.0166, -0.0106,  0.0048]), 'exp_avg_sq': tensor([0.0081, 0.0088, 0.0023, 0.0193, 0.0092, 0.0019])}}\n",
      "param_groups \t [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'initial_lr': 0.01, 'params': [121150054224, 121150447696, 121150447776, 121150447856, 121150448096, 121150448176, 121150448256, 121150448016, 121150448576, 121150448656, 121150448736, 121150448816, 121150449136, 121150449216, 121150449296, 121150449376, 121150449696, 121150449776]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "torch.save(model.state_dict(), 'dataset_model_james.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
