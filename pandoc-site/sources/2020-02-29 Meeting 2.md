# Week 2 Meeting 2/29

## Agenda

|               |                    |
| -             | -                  | 
| 10:10 - 10:30 | Discuss Seq2Seq    |
| 10:30 - 11:30 | Seq2Seq tutorial   |
| 11:30 - 12:30 | ToneNet            |
| 12:30 - 1:00  | Discuss UMTN paper |

## [Seq2Seq](https://arxiv.org/pdf/1409.3215.pdf) Overview

### [Autoregressive models](https://www.investopedia.com/terms/a/autoregressive.asp)

- For time series data $f(x)$, predicting $f(x + 1)$ using $f(1)$ ... $f(x)$.

### Why learn Seq2Seq?

- It's a (relatively) simple model using RNNs.
- It's a good case study for sequence to sequence problems like machine translation.
- ToneNet uses Seq2Seq!

### RNNs

Essentially, a recurrent neural network takes in an input and past state. Then it emits an output and a new state. So it's able to carry "memory" of previous inputs via the state variable.

LSTMs are a sophisticated type of RNN that are designed to have better gradient backpropagation.

### How Seq2Seq works

It takes in a sentence in one language, which is passed through a series of RNN cells that update a state. Then, at the end of the sentence, the state is used to generate a translation of the sentence. Its "input" is just the last word, and it continues until hitting an end-of-sentence.

For some reason, it worked better when translating a sentence input backwards.

### Attention

Yea I don't know much about attention.

## [Seq2Seq tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)

This is just to get started with Pytorch. It should be able to train and run on your local computer.

## [ToneNet](https://towardsdatascience.com/tonenet-a-musical-style-transfer-c0a18903c910)

This is a bit more involved. We won't try their GAN based approaches and will just focus on seq2seq for now. However, there are a lot of different components to their seq2seq network:

- Converting MIDIs to tensors
- Converting tensors to MIDIs
- Building the Seq2Seq network in Pytorch
- [Adding Luong attention](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

## Universal Music Translation Network

### WaveNet Basics

- Model audio as a time series
- Predict the probability distribution of the next point using the previous points and a conditioning signal
- Uses stacked convolutions to incorporate information from recent and much earlier points
- NVIDIA has created some [GPU optimized code](https://github.com/NVIDIA/nv-wavenet) for WaveNet related things.

![](https://lh3.googleusercontent.com/Zy5xK_i2F8sNH5tFtRa0SjbLp_CU7QwzS2iB5nf2ijIf_OYm-Q5D0SgoW9SmfbDF97tNEF7CmxaL-o6oLC8sGIrJ5HxWNk79dL1r7Rc=w2048){.invert}

Learn more about WaveNet:

- DeepMind [blog post](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio)
- [Paper](https://arxiv.org/pdf/1609.03499.pdf)

### UMTN Overview

![](https://github.com/facebookresearch/music-translation/blob/master/img/fig.png?raw=true){.invert}

- Inputs are audio files (e.g. WAV) which can be considered a [time series](https://en.wikipedia.org/wiki/Pulse-code_modulation)
- Encoder network encodes inputs into a representation that, theoretically, doesn't include any instrumentation details ("domain specific information")
- A decoder can convert the encoder output into an audio file with a specific instrumentation. Each instrumentation ("domain") has its own decoder.
- The whole network is really computationally expensive!

### Data Augmentation

- Detune the audio beforehand, to prevent overfitting.

### Losses

- Train a classifier to predict the domain from the encoded representation.
- Remember, the encoder is supposed to remove domain specific information!
- So, the loss for the encoder and decoders includes a reward (negative loss) for confusing the classifier!
- The other component of the encoder/decoder loss is that inputting a file and decoding it to the same domain should yield the same file.
- At runtime the decoder is conditioned on its previous output. But to help it learn at training time, it's conditioned on the previous ground truth output instead. This is called [teacher forcing](https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c).
